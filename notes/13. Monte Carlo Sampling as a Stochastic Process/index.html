
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="Course Notes and Code (Erwin Frey, LMU Munich, 2025)">
      
      
        <meta name="author" content="Zhihang Liu">
      
      
        <link rel="canonical" href="https://liu-zhihang.github.io/Nonequilibrium-Field-Theories-and-Stochastic-Dynamics/notes/13.%20Monte%20Carlo%20Sampling%20as%20a%20Stochastic%20Process/">
      
      
        <link rel="prev" href="../12.%20Brownian%20Motion%20and%20the%20Ornstein%E2%80%93Uhlenbeck%20Process/">
      
      
        <link rel="next" href="../14.%20Hamiltonian%20Monte%20Carlo%20Sampling/">
      
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.22">
    
    
      
        <title>13. Monte Carlo Sampling as a Stochastic Process - Nonequilibrium Field Theories and Stochastic Dynamics</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.84d31ad4.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#introduction-from-analytical-theory-to-a-computational-tool" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="Nonequilibrium Field Theories and Stochastic Dynamics" class="md-header__button md-logo" aria-label="Nonequilibrium Field Theories and Stochastic Dynamics" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Nonequilibrium Field Theories and Stochastic Dynamics
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              13. Monte Carlo Sampling as a Stochastic Process
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m17.75 4.09-2.53 1.94.91 3.06-2.63-1.81-2.63 1.81.91-3.06-2.53-1.94L12.44 4l1.06-3 1.06 3zm3.5 6.91-1.64 1.25.59 1.98-1.7-1.17-1.7 1.17.59-1.98L15.75 11l2.06-.05L18.5 9l.69 1.95zm-2.28 4.95c.83-.08 1.72 1.1 1.19 1.85-.32.45-.66.87-1.08 1.27C15.17 23 8.84 23 4.94 19.07c-3.91-3.9-3.91-10.24 0-14.14.4-.4.82-.76 1.27-1.08.75-.53 1.93.36 1.85 1.19-.27 2.86.69 5.83 2.89 8.02a9.96 9.96 0 0 0 8.02 2.89m-1.64 2.02a12.08 12.08 0 0 1-7.8-3.47c-2.17-2.19-3.33-5-3.49-7.82-2.81 3.14-2.7 7.96.31 10.98 3.02 3.01 7.84 3.12 10.98.31"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 7a5 5 0 0 1 5 5 5 5 0 0 1-5 5 5 5 0 0 1-5-5 5 5 0 0 1 5-5m0 2a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0-7 2.39 3.42C13.65 5.15 12.84 5 12 5s-1.65.15-2.39.42zM3.34 7l4.16-.35A7.2 7.2 0 0 0 5.94 8.5c-.44.74-.69 1.5-.83 2.29zm.02 10 1.76-3.77a7.131 7.131 0 0 0 2.38 4.14zM20.65 7l-1.77 3.79a7.02 7.02 0 0 0-2.38-4.15zm-.01 10-4.14.36c.59-.51 1.12-1.14 1.54-1.86.42-.73.69-1.5.83-2.29zM12 22l-2.41-3.44c.74.27 1.55.44 2.41.44.82 0 1.63-.17 2.37-.44z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
      <div class="md-header__option">
  <div class="md-select">
    
    <button class="md-header__button md-icon" aria-label="Select language">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m12.87 15.07-2.54-2.51.03-.03A17.5 17.5 0 0 0 14.07 6H17V4h-7V2H8v2H1v2h11.17C11.5 7.92 10.44 9.75 9 11.35 8.07 10.32 7.3 9.19 6.69 8h-2c.73 1.63 1.73 3.17 2.98 4.56l-5.09 5.02L4 19l5-5 3.11 3.11zM18.5 10h-2L12 22h2l1.12-3h4.75L21 22h2zm-2.62 7 1.62-4.33L19.12 17z"/></svg>
    </button>
    <div class="md-select__inner">
      <ul class="md-select__list">
        
          <li class="md-select__item">
            <a href="/Nonequilibrium-Field-Theories-and-Stochastic-Dynamics/" hreflang="en" class="md-select__link">
              English
            </a>
          </li>
        
          <li class="md-select__item">
            <a href="/Nonequilibrium-Field-Theories-and-Stochastic-Dynamics/zh/" hreflang="zh" class="md-select__link">
              简体中文
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</div>
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
      <div class="md-header__source">
        <a href="https://github.com/Liu-Zhihang/Nonequilibrium-Field-Theories-and-Stochastic-Dynamics" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



  

<nav class="md-nav md-nav--primary md-nav--integrated" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="Nonequilibrium Field Theories and Stochastic Dynamics" class="md-nav__button md-logo" aria-label="Nonequilibrium Field Theories and Stochastic Dynamics" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    Nonequilibrium Field Theories and Stochastic Dynamics
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/Liu-Zhihang/Nonequilibrium-Field-Theories-and-Stochastic-Dynamics" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Home
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
    
      
        
        
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" checked>
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    Course Notes
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            Course Notes
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../1.%20Course%20Introduction/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    1. Course Introduction
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../2.%20Simple%20Random%20Walk/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    2. Simple Random Walk
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../3.%20Gaussian%20Random%20Walk%20and%20Poisson%20Process/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    3. Gaussian Random Walk and Poisson Process
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../4.%20Gillespie%20Algorithm%2C%20Master%20Equation%2C%20Generating%20Functions%20and%20Population%20Dynamics/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    4. Gillespie Algorithm, Master Equation, Generating Functions and Population Dynamics
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../5.%20Population%20Dynamics%20-%20Linear%20Death%20Process%20and%20Lotka-Volterra%20System/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    5. Population Dynamics - Linear Death Process and Lotka-Volterra System
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../6.%20Fundamental%20Equations%20of%20Markov%20Processes%20%E2%80%94%20Chapman%E2%80%93Kolmogorov%20Equation/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    6. Fundamental Equations of Markov Processes — Chapman–Kolmogorov Equation
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../7.%20Forward%20Master%20Equation%20and%20the%20Q%20Matrix/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    7. Forward Master Equation and the Q Matrix
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../8.%20Perron%E2%80%93Frobenius%20Theorem%2C%20Steady%20States%2C%20and%20Detailed%20Balance/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    8. Perron–Frobenius Theorem, Steady States, and Detailed Balance
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../9.%20Nonequilibrium%20States%20%E2%80%94%20Irreversibility%20and%20Entropy%20Production/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    9. Nonequilibrium States — Irreversibility and Entropy Production
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../10.%20Ehrenfest%20Model%2C%20Entropy%2C%20and%20KL%20Divergence/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    10. Ehrenfest Model, Entropy, and KL Divergence
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../11.%20Continuous%20Markov%20Processes%20and%20the%20Fokker%E2%80%93Planck%20Equation/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    11. Continuous Markov Processes and the Fokker–Planck Equation
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../12.%20Brownian%20Motion%20and%20the%20Ornstein%E2%80%93Uhlenbeck%20Process/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    12. Brownian Motion and the Ornstein–Uhlenbeck Process
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    13. Monte Carlo Sampling as a Stochastic Process
    
  </span>
  

      </a>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../14.%20Hamiltonian%20Monte%20Carlo%20Sampling/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    14. Hamiltonian Monte Carlo Sampling
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../15.%20Chemotaxis%2C%20Run-and-Tumble%20Motion%2C%20and%20the%20Keller%E2%80%93Segel%20Model/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    15. Chemotaxis, Run-and-Tumble Motion, and the Keller–Segel Model
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../16.%20The%20Schnitzer%20Model%2C%20Anomalous%20Diffusion%2C%20and%20Motility%E2%80%91Induced%20Phase%20Separation/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    16. The Schnitzer Model, Anomalous Diffusion, and Motility‑Induced Phase Separation
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../17.%20Langevin%20Equation%2C%20Brownian%20Particle%2C%20and%20the%20Fluctuation%E2%80%93Dissipation%20Theorem/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    17. Langevin Equation, Brownian Particle, and the Fluctuation–Dissipation Theorem
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../18.%20Fokker%E2%80%93Planck%20Equation%20and%20the%20Smoluchowski%20Equation%20%E2%80%94%20From%20Random%20Trajectories%20to%20Probability%20Dynamics/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    18. Fokker–Planck Equation and the Smoluchowski Equation — From Random Trajectories to Probability Dynamics
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../19.%20Path%20Integral%20Formulation%20of%20Stochastic%20Processes/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    19. Path Integral Formulation of Stochastic Processes
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../20.%20Stochastic%20Differential%20Equations/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    20. Stochastic Differential Equations
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
      
        
        
      
    
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_3" >
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    中文笔记
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            中文笔记
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../zh/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    首页
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../zh/notes/1.%20%E8%AF%BE%E7%A8%8B%E5%AF%BC%E8%AE%BA/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    1. 课程导论
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../zh/notes/2.%20%E7%AE%80%E5%8D%95%E9%9A%8F%E6%9C%BA%E6%B8%B8%E8%B5%B0/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    2. 简单随机游走
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../zh/notes/3.%20%E9%AB%98%E6%96%AF%E9%9A%8F%E6%9C%BA%E6%B8%B8%E8%B5%B0%E4%B8%8E%E6%B3%8A%E6%9D%BE%E8%BF%87%E7%A8%8B/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    3. 高斯随机游走与泊松过程
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../zh/notes/4.%20Gillespie%20%E7%AE%97%E6%B3%95%E3%80%81%E4%B8%BB%E6%96%B9%E7%A8%8B%E3%80%81%E7%94%9F%E6%88%90%E5%87%BD%E6%95%B0%E4%B8%8E%E7%A7%8D%E7%BE%A4%E5%8A%A8%E5%8A%9B%E5%AD%A6/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    4. Gillespie 算法、主方程、生成函数与种群动力学
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../zh/notes/5.%20%E7%A7%8D%E7%BE%A4%E5%8A%A8%E6%80%81%E5%AD%A6%EF%BC%9A%E7%BA%BF%E6%80%A7%E6%AD%BB%E4%BA%A1%E8%BF%87%E7%A8%8B%E4%B8%8ELotka-Volterra%20%E7%B3%BB%E7%BB%9F/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    5. 种群动态学：线性死亡过程与Lotka-Volterra 系统
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../zh/notes/6.%20%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E8%BF%87%E7%A8%8B%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%96%B9%E7%A8%8B%EF%BC%9A%E6%9F%A5%E6%99%AE%E6%9B%BC-%E7%A7%91%E5%B0%94%E8%8E%AB%E6%88%88%E7%BD%97%E5%A4%AB%E6%96%B9%E7%A8%8B/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    6. 马尔可夫过程的基本方程：查普曼-科尔莫戈罗夫方程
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../zh/notes/7.%20%E5%89%8D%E5%90%91%E4%B8%BB%E6%96%B9%E7%A8%8B%E4%B8%8EQ%E7%9F%A9%E9%98%B5/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    7. 前向主方程与Q矩阵
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../zh/notes/8.%20%E4%BD%A9%E9%BE%99-%E5%BC%97%E7%BD%97%E8%B4%9D%E5%B0%BC%E4%B9%8C%E6%96%AF%E5%AE%9A%E7%90%86%E3%80%81%E7%A8%B3%E6%80%81%E4%B8%8E%E7%BB%86%E8%87%B4%E5%B9%B3%E8%A1%A1/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    8. 佩龙-弗罗贝尼乌斯定理、稳态与细致平衡
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../zh/notes/9.%20%E9%9D%9E%E5%B9%B3%E8%A1%A1%E6%80%81%EF%BC%9A%E4%B8%8D%E5%8F%AF%E9%80%86%E6%80%A7%E4%B8%8E%E7%86%B5%E4%BA%A7%E7%94%9F%E7%9A%84%E6%8E%A8%E8%AE%BA/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    9. 非平衡态：不可逆性与熵产生的推论
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../zh/notes/10.%20%E5%9F%83%E4%BC%A6%E8%B4%B9%E6%96%AF%E7%89%B9%E6%A8%A1%E5%9E%8B%E3%80%81%E7%86%B5%E4%B8%8EKL%E6%95%A3%E5%BA%A6/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    10. 埃伦费斯特模型、熵与KL散度
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../zh/notes/11.%20%E8%BF%9E%E7%BB%AD%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E8%BF%87%E7%A8%8B%E4%B8%8E%E7%A6%8F%E5%85%8B-%E6%99%AE%E6%9C%97%E5%85%8B%E6%96%B9%E7%A8%8B/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    11. 连续马尔可夫过程与福克-普朗克方程
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../zh/notes/12.%20%E5%B8%83%E6%9C%97%E8%BF%90%E5%8A%A8%E4%B8%8E%E5%A5%A5%E6%81%A9%E6%96%AF%E5%9D%A6-%E4%B9%8C%E4%BC%A6%E8%B4%9D%E5%85%8B%E8%BF%87%E7%A8%8B/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    12. 布朗运动与奥恩斯坦-乌伦贝克过程
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../zh/notes/13.%20%E4%BD%9C%E4%B8%BA%E9%9A%8F%E6%9C%BA%E8%BF%87%E7%A8%8B%E7%9A%84%E8%92%99%E7%89%B9%E5%8D%A1%E6%B4%9B%E9%87%87%E6%A0%B7/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    13. 作为随机过程的蒙特卡洛采样
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../zh/notes/14.%20%E5%93%88%E5%AF%86%E5%B0%94%E9%A1%BF%E8%92%99%E7%89%B9%E5%8D%A1%E6%B4%9B%E9%87%87%E6%A0%B7/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    14. 哈密尔顿蒙特卡洛采样
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../zh/notes/15.%20%E8%B6%8B%E5%8C%96%E6%80%A7%E3%80%81%E8%B7%91%E5%8A%A8-%E7%BF%BB%E6%BB%9A%E8%BF%90%E5%8A%A8%E4%B8%8EKeller-Segel%E6%A8%A1%E5%9E%8B/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    15. 趋化性、跑动-翻滚运动与Keller-Segel模型
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../zh/notes/16.%20Schnitzer%E6%A8%A1%E5%9E%8B%E3%80%81%E5%8F%8D%E5%B8%B8%E6%89%A9%E6%95%A3%E4%B8%8E%E8%BF%90%E5%8A%A8%E8%AF%B1%E5%AF%BC%E7%9B%B8%E5%88%86%E7%A6%BB/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    16. Schnitzer模型、反常扩散与运动诱导相分离
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../zh/notes/17.%20%E6%9C%97%E4%B9%8B%E4%B8%87%E6%96%B9%E7%A8%8B%E3%80%81%E5%B8%83%E6%9C%97%E7%B2%92%E5%AD%90%E4%B8%8E%E6%B6%A8%E8%90%BD-%E8%80%97%E6%95%A3%E5%AE%9A%E7%90%86/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    17. 朗之万方程、布朗粒子与涨落-耗散定理
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../zh/notes/18.%20%E7%A6%8F%E5%85%8B-%E6%99%AE%E6%9C%97%E5%85%8B%E6%96%B9%E7%A8%8B%E4%B8%8E%E6%96%AF%E6%91%A9%E6%A3%B1%E9%9C%8D%E5%A4%AB%E6%96%AF%E5%9F%BA%E6%96%B9%E7%A8%8B%EF%BC%9A%E4%BB%8E%E9%9A%8F%E6%9C%BA%E8%BD%A8%E8%BF%B9%E5%88%B0%E6%A6%82%E7%8E%87%E5%8A%A8%E5%8A%9B%E5%AD%A6/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    18. 福克-普朗克方程与斯摩棱霍夫斯基方程：从随机轨迹到概率动力学
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../zh/notes/19.%20%E9%9A%8F%E6%9C%BA%E8%BF%87%E7%A8%8B%E7%9A%84%E8%B7%AF%E5%BE%84%E7%A7%AF%E5%88%86%E8%A1%A8%E8%BF%B0/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    19. 随机过程的路径积分表述
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../zh/notes/20.%20%E9%9A%8F%E6%9C%BA%E5%BE%AE%E5%88%86%E6%96%B9%E7%A8%8B/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    20. 随机微分方程
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../zh/notes/21.%20%E4%BC%8A%E8%97%A4%E7%A7%AF%E5%88%86%E4%B8%8E%E7%BB%9F%E4%B8%80%E7%9A%84%E9%9A%8F%E6%9C%BA%E8%BF%87%E7%A8%8B%E6%A1%86%E6%9E%B6/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    21. 伊藤积分与统一的随机过程框架
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../zh/notes/22.%20%E5%90%AB%E4%B9%98%E6%80%A7%E5%99%AA%E5%A3%B0%E7%B3%BB%E7%BB%9F%E7%9A%84%E8%B7%AF%E5%BE%84%E7%A7%AF%E5%88%86/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    22. 含乘性噪声系统的路径积分
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../zh/notes/23.%20%E4%BB%8E%E7%B2%97%E7%B2%92%E5%8C%96%E5%88%B0%E8%BF%9E%E7%BB%AD%E5%9C%BA%E8%AE%BA%E6%B6%A8%E8%90%BD%E5%8A%A8%E5%8A%9B%E5%AD%A6/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    23. 从粗粒化到连续场论涨落动力学
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../zh/notes/24.%20%E6%98%82%E8%90%A8%E6%A0%BC%E7%B3%BB%E6%95%B0%E3%80%81%E5%80%92%E6%98%93%E5%85%B3%E7%B3%BB%E4%B8%8E%E5%8A%A8%E6%80%81%E6%B6%A8%E8%90%BD-%E8%80%97%E6%95%A3%E5%AE%9A%E7%90%86/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    24. 昂萨格系数、倒易关系与动态涨落-耗散定理
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../zh/notes/25.%20%E6%A2%AF%E5%BA%A6%E5%8A%A8%E5%8A%9B%E5%AD%A6%E3%80%81%E7%9B%B8%E5%8F%98%E4%B8%8E%E5%BC%9B%E8%B1%AB/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    25. 梯度动力学、相变与弛豫
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../zh/notes/26.%20%E4%B8%B4%E7%95%8C%E6%85%A2%E5%8C%96%E3%80%81%E5%8A%A8%E6%80%81%E5%93%8D%E5%BA%94%E4%B8%8E%E5%AE%88%E6%81%92%E5%BE%8B/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    26. 临界慢化、动态响应与守恒律
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../zh/notes/27.%20%E7%AE%80%E5%8D%95%E6%B5%81%E4%BD%93%E3%80%81%E6%97%A0%E6%91%A9%E6%93%A6%E6%B5%81%E4%BD%93%E4%B8%8E%E6%AC%A7%E6%8B%89%E6%96%B9%E7%A8%8B%E7%9A%84%E6%B5%81%E4%BD%93%E5%8A%A8%E5%8A%9B%E5%AD%A6/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    27. 简单流体、无摩擦流体与欧拉方程的流体动力学
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../zh/notes/28.%20%E7%B2%98%E6%80%A7%E6%B5%81%E4%BD%93%E3%80%81%E7%BA%B3%E7%BB%B4-%E6%96%AF%E6%89%98%E5%85%8B%E6%96%AF%E6%96%B9%E7%A8%8B%E3%80%81%E7%86%B5%E5%B9%B3%E8%A1%A1%E4%B8%8E%E7%83%AD%E4%BC%A0%E5%AF%BC/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    28. 粘性流体、纳维-斯托克斯方程、熵平衡与热传导
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../zh/notes/29.%20%E4%B8%8D%E5%8F%AF%E9%80%86%E7%BA%BF%E6%80%A7%E7%83%AD%E5%8A%9B%E5%AD%A6%E4%B8%8E%E5%B9%B2%E6%80%A7%E6%89%A9%E6%95%A3%E7%B2%92%E5%AD%90%E7%B3%BB%E7%BB%9F/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    29. 不可逆线性热力学与干性扩散粒子系统
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../zh/notes/30.%20%E6%82%AC%E6%B5%AE%E5%9C%A8%E6%B5%81%E4%BD%93%E4%B8%AD%E7%9A%84%E5%B8%83%E6%9C%97%E7%B2%92%E5%AD%90%20%E2%80%94%20H%E6%A8%A1%E5%9E%8B/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    30. 悬浮在流体中的布朗粒子 — H模型
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../zh/notes/31.%20%E5%8A%A8%E6%80%81%E6%B3%9B%E5%87%BD%E3%80%81%E5%8A%A0%E6%80%A7%E5%99%AA%E5%A3%B0%E5%9C%BA%E8%AE%BA%E4%B8%8EOnsager-Machlup%E6%B3%9B%E5%87%BD/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    31. 动态泛函、加性噪声场论与Onsager-Machlup泛函
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../zh/notes/32.%20Janssen-De%20Dominicis%20%E5%93%8D%E5%BA%94%E6%B3%9B%E5%87%BD%E4%B8%8E%E6%B6%A8%E8%90%BD-%E8%80%97%E6%95%A3%E5%85%B3%E7%B3%BB/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    32. Janssen-De Dominicis 响应泛函与涨落-耗散关系
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../zh/notes/33.%20%E9%9D%9E%E5%B9%B3%E8%A1%A1%E5%8A%9F%E4%B8%8E%E6%B6%A8%E8%90%BD%E5%AE%9A%E7%90%86/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    33. 非平衡功与涨落定理
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../zh/notes/34.%20%E6%9C%89%E5%90%91%E6%B8%97%E6%B5%81%E3%80%81%E5%90%B8%E6%94%B6%E6%80%81%E4%B8%8E%E8%B0%B1%E6%96%B9%E6%B3%95/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    34. 有向渗流、吸收态与谱方法
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../zh/notes/35.%20%E4%B8%BB%E6%96%B9%E7%A8%8B%E7%9A%84%E8%B7%AF%E5%BE%84%E7%A7%AF%E5%88%86%E8%A1%A8%E7%A4%BA/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    35. 主方程的路径积分表示
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../zh/notes/36.%20%E7%9B%B8%E5%B9%B2%E6%80%81%E8%B7%AF%E5%BE%84%E7%A7%AF%E5%88%86%E3%80%81%E7%AE%97%E7%AC%A6%E4%BB%A3%E6%95%B0%E4%B8%8E%E8%99%9A%E5%99%AA%E5%A3%B0/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    36. 相干态路径积分、算符代数与虚噪声
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../zh/notes/37.%20Kramers-Moyal%20%E5%B1%95%E5%BC%80%E4%B8%8E%E8%B7%AF%E5%BE%84%E7%A7%AF%E5%88%86%E7%9A%84%E4%BD%8E%E5%99%AA%E5%A3%B0%E6%9E%81%E9%99%90/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    37. Kramers-Moyal 展开与路径积分的低噪声极限
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../zh/notes/38.%20%E5%A4%9A%E7%89%A9%E7%A7%8D%E8%B7%AF%E5%BE%84%E7%A7%AF%E5%88%86%E4%B8%8E%E5%BE%AA%E7%8E%AF%E7%AB%9E%E4%BA%89%E5%8A%A8%E5%8A%9B%E5%AD%A6/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    38. 多物种路径积分与循环竞争动力学
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../zh/notes/39.%20%E4%BB%8E%E7%B2%92%E5%AD%90%E8%B7%B3%E8%B7%83%E5%88%B0%E8%BF%9E%E7%BB%AD%E5%9C%BA%E8%AE%BA/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    39. 从粒子跳跃到连续场论
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../zh/notes/40.%20%E7%BB%9F%E4%B8%80%E7%9A%84%E5%9C%BA%E8%AE%BA%E6%A1%86%E6%9E%B6/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    40. 统一的场论框架
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


  
  


<h1 id="introduction-from-analytical-theory-to-a-computational-tool">Introduction: From Analytical Theory to a Computational Tool<a class="headerlink" href="#introduction-from-analytical-theory-to-a-computational-tool" title="Permanent link">&para;</a></h1>
<p><img alt="Lecture board" src="../../assets/images/remote/8991dfc8-9e11-4011-a9e6-84f1507556da-ed64b1d80a.jpg" /></p>
<p>This lecture is TA-led. In the past several sessions, Prof. Erwin Frey has built a powerful theoretical framework for understanding and describing stochastic processes. Starting from the basics of Markov processes, we derived the Chapman-Kolmogorov equation, and then obtained the master equation and the Fokker-Planck equation. We also discussed steady states, the detailed-balance condition, and the Perron-Frobenius theorem, which provide deep insight into how systems reach and maintain equilibrium.</p>
<p>So far our perspective has been analytical: given a stochastic process (defined by its transition rates), we analyze its behavior, e.g., what the steady-state distribution is. In this lecture, we shift from analysis to synthesis and application. We show how the Markov-process framework - especially Markov chains - can be turned into a practical computational tool to solve a fundamental problem across the sciences: statistical inference, i.e., learning model parameters from data.</p>
<p>By cleverly designing a Markov process whose stationary distribution is exactly a target distribution, we can generate samples from that distribution and thereby solve otherwise intractable integrals. This approach is called Markov chain Monte Carlo (MCMC). It has transformed Bayesian statistics and many scientific fields that rely on computational modeling.</p>
<h1 id="1-problem-statement-inferring-models-from-real-world-data">1. Problem Statement: Inferring Models from Real-World Data<a class="headerlink" href="#1-problem-statement-inferring-models-from-real-world-data" title="Permanent link">&para;</a></h1>
<p>A core task in science is to build and validate mathematical models from observations. A good model not only explains existing data but also predicts the future. The predictive power of a model depends entirely on its parameters. How do we determine unknown parameters from experimental or observational data?</p>
<h2 id="11-a-classic-ecosystem-lynx-and-hare">1.1 A Classic Ecosystem: Lynx and Hare<a class="headerlink" href="#11-a-classic-ecosystem-lynx-and-hare" title="Permanent link">&para;</a></h2>
<p>To make it concrete, consider a classic ecological example: the predator-prey dynamics of Canadian lynx (predator) and snowshoe hare (prey). The Hudson's Bay Company recorded pelts from 1900 to 1920; these counts are regarded as reliable proxies for population sizes.</p>
<p><img alt="Lecture slide" src="../../assets/images/remote/d8a6f6e7-4ac0-4fd3-8c00-720a1ca45ea7-a946bb2c01.jpg" /></p>
<p><img alt="Lecture slide" src="../../assets/images/remote/bbd18f78-ebf7-462a-923a-e58b7d4eda23-ea96baa5f4.jpg" /></p>
<p>Plotting the data reveals periodic oscillations in both species, with the predator peak lagging behind the prey peak.</p>
<p><img alt="Lecture slide" src="../../assets/images/remote/510942e3-5a73-482e-8509-9ffe66e18509-55827117d3.png" /></p>
<p>A natural question is: can we find a mathematical model that explains and predicts this periodic behavior? More specifically, can we infer the "laws" (parameters) that govern the dynamics from the data?</p>
<h2 id="12-lotka-volterra-model-a-mathematical-description">1.2 Lotka-Volterra Model: A Mathematical Description<a class="headerlink" href="#12-lotka-volterra-model-a-mathematical-description" title="Permanent link">&para;</a></h2>
<p>A famous model for predator-prey systems is the Lotka-Volterra equations, a pair of coupled ODEs describing changes in two populations. Let <span class="arithmatex">\(x\)</span> be the hare (prey) population and <span class="arithmatex">\(y\)</span> the lynx (predator) population:</p>
<div class="arithmatex">\[
\frac{dx}{dt} = \alpha x - \beta xy \quad \text{(hares)}
\]</div>
<div class="arithmatex">\[
\frac{dy}{dt} = -\gamma y + \delta xy \quad \text{(lynx)}
\]</div>
<p>Interpretation of each term:</p>
<ul>
<li><span class="arithmatex">\(\alpha x\)</span>: natural exponential growth of hares in the absence of predators (<span class="arithmatex">\(y=0\)</span>); <span class="arithmatex">\(\alpha\)</span> is the hare birth rate.</li>
<li><span class="arithmatex">\(-\beta xy\)</span>: loss of hares due to predation; encounter frequency <span class="arithmatex">\(\propto xy\)</span>; <span class="arithmatex">\(\beta\)</span> is predation efficiency.</li>
<li><span class="arithmatex">\(-\gamma y\)</span>: natural death of lynx in the absence of food (<span class="arithmatex">\(x=0\)</span>); <span class="arithmatex">\(\gamma\)</span> is the lynx death rate.</li>
<li><span class="arithmatex">\(+\delta xy\)</span>: lynx reproduction thanks to predation; proportional to <span class="arithmatex">\(xy\)</span>; <span class="arithmatex">\(\delta\)</span> is the conversion efficiency from prey to predator growth.</li>
</ul>
<p>The "laws" are encoded in <span class="arithmatex">\(\theta=\{\alpha,\beta,\gamma,\delta\}\)</span>. Given observations <span class="arithmatex">\(D\)</span> (the time series), parameter inference asks for the most plausible <span class="arithmatex">\(\theta\)</span>.</p>
<h1 id="2-bayesian-framework-a-systematic-approach">2. Bayesian Framework: A Systematic Approach<a class="headerlink" href="#2-bayesian-framework-a-systematic-approach" title="Permanent link">&para;</a></h1>
<p>How can we systematically learn parameters <span class="arithmatex">\(\theta\)</span> from data <span class="arithmatex">\(D\)</span>? Bayesian inference provides a probability-based, logically coherent framework: it is fundamentally a rule for updating degrees of belief in light of new evidence.</p>
<h2 id="21-introducing-bayes-theorem">2.1 Introducing Bayes' Theorem<a class="headerlink" href="#21-introducing-bayes-theorem" title="Permanent link">&para;</a></h2>
<p>Bayesian inference formalizes learning from data via</p>
<div class="arithmatex">\[
\underbrace{p(\theta\mid D)}_{\text{posterior}} = \frac{\underbrace{p(D\mid\theta)}_{\text{likelihood}}\, \underbrace{p(\theta)}_{\text{prior}}}{\underbrace{p(D)}_{\text{evidence}}}.
\]</div>
<h2 id="22-decomposing-bayes-theorem">2.2 Decomposing Bayes' Theorem<a class="headerlink" href="#22-decomposing-bayes-theorem" title="Permanent link">&para;</a></h2>
<ul>
<li>Prior <span class="arithmatex">\(p(\theta)\)</span>: knowledge/belief before seeing data.</li>
<li>Likelihood <span class="arithmatex">\(p(D\mid\theta)\)</span>: plausibility of data under parameters.</li>
<li>Evidence <span class="arithmatex">\(p(D)\)</span>: normalization; often intractable.</li>
<li>Posterior <span class="arithmatex">\(p(\theta\mid D)\)</span>: what we want to characterize/sample.</li>
</ul>
<p>Bayesian thinking differs from traditional "best-fit" approaches (e.g., least squares). Classical methods may return a single best parameter set. In contrast, Bayesian methods say: there is no single "correct" <span class="arithmatex">\(\theta\)</span> - instead there is a landscape of plausibilities over parameter space. One region may be very plausible while another is unlikely.</p>
<p>This probabilistic perspective is powerful. It lets us ask deeper questions such as: "What is the probability that the hare birth rate <span class="arithmatex">\(\alpha\)</span> lies between 0.5 and 0.6?" or "Are the predation rate <span class="arithmatex">\(\beta\)</span> and the lynx death rate <span class="arithmatex">\(\gamma\)</span> correlated?" This represents a shift from deterministic to probabilistic thinking that honestly reflects our uncertainty given finite data.</p>
<h1 id="3-computational-bottleneck-high-dimensional-integrals">3. Computational Bottleneck: High-Dimensional Integrals<a class="headerlink" href="#3-computational-bottleneck-high-dimensional-integrals" title="Permanent link">&para;</a></h1>
<p>Having a posterior <span class="arithmatex">\(p(\theta\mid D)\)</span> solves inference in principle, but in practice we often need summaries such as expectations and variances.</p>
<h2 id="31-from-distributions-to-expectations">3.1 From Distributions to Expectations<a class="headerlink" href="#31-from-distributions-to-expectations" title="Permanent link">&para;</a></h2>
<p>Model comparison, prediction, and uncertainty quantification are often expectations under the posterior. For a function <span class="arithmatex">\(f(\theta)\)</span> (e.g., <span class="arithmatex">\(f(\theta)=\alpha\)</span> to compute the mean of <span class="arithmatex">\(\alpha\)</span>), we need to evaluate</p>
<div class="arithmatex">\[
\langle f(\theta) \rangle = \int f(\theta)\, p(\theta\mid D)\, d\theta^n,
\]</div>
<p>an integral over the full <span class="arithmatex">\(n\)</span>-dimensional parameter space (here <span class="arithmatex">\(n=4\)</span>). We also encounter the evidence (normalization) itself,</p>
<div class="arithmatex">\[
p(D) = \int p(D\mid\theta)\, p(\theta)\, d\theta,
\]</div>
<p>which is frequently the hardest quantity in Bayesian inference.</p>
<h2 id="32-the-curse-of-dimensionality">3.2 The Curse of Dimensionality<a class="headerlink" href="#32-the-curse-of-dimensionality" title="Permanent link">&para;</a></h2>
<p>Why are these integrals so hard? Direct gridding explodes with dimension. Suppose we take 10 grid points per parameter:</p>
<ul>
<li>1D: <span class="arithmatex">\(10^1=10\)</span> evaluations.</li>
<li>2D: <span class="arithmatex">\(10^2=100\)</span> evaluations.</li>
<li>4D (our Lotka-Volterra case): <span class="arithmatex">\(10^4=10{,}000\)</span> evaluations.</li>
<li>20D: <span class="arithmatex">\(10^{20}\)</span> evaluations - utterly infeasible.</li>
</ul>
<p>Worse, high-dimensional geometry defeats low-dimensional intuition: the posterior mass typically concentrates in a tiny, irregular region, while most of the space has near-zero density.</p>
<p><img alt="Lecture board" src="../../assets/images/remote/3d4c0c96-092b-4d24-838f-fca8fa077a21-25de69215c.png" /></p>
<p>Uniform grids are blind; they waste almost all effort evaluating points where <span class="arithmatex">\(p(\theta\mid D)\approx 0\)</span>. The "curse of dimensionality" is not just slowness, but a fundamental scaling barrier. The problem is search efficiency: in an exponentially large space, we must find a small, unknown "important" region. We need a different strategy that focuses effort where it matters.</p>
<h1 id="4-a-new-strategy-monte-carlo-integration">4. A New Strategy: Monte Carlo Integration<a class="headerlink" href="#4-a-new-strategy-monte-carlo-integration" title="Permanent link">&para;</a></h1>
<p>Facing high-dimensional integrals, we turn to a smarter approach: Monte Carlo integration replaces deterministic grids with random sampling.</p>
<h2 id="41-power-of-the-law-of-large-numbers">4.1 Power of the Law of Large Numbers<a class="headerlink" href="#41-power-of-the-law-of-large-numbers" title="Permanent link">&para;</a></h2>
<p>Monte Carlo integration uses the law of large numbers to approximate integrals by sample averages:</p>
<div class="arithmatex">\[
\langle f(\theta) \rangle = \int f(\theta)\, p(\theta\mid D)\, d\theta \;\approx\; \frac{1}{N} \sum_{i=1}^{N} f\big(\theta^{(i)}\big).
\]</div>
<p>The "magic" lies in how we generate the samples <span class="arithmatex">\(\{\theta^{(i)}\}\)</span>.</p>
<h2 id="42-importance-sampling-the-key-insight">4.2 Importance Sampling: The Key Insight<a class="headerlink" href="#42-importance-sampling-the-key-insight" title="Permanent link">&para;</a></h2>
<p>To make the approximation accurate and efficient, the samples should be drawn from the target itself, <span class="arithmatex">\(p(\theta\mid D)\)</span>. This is the essence of importance sampling: by drawing from the target, computation automatically focuses on high-probability regions - the very regions that dominate the integral - rather than wasting effort in probability "deserts".</p>
<p>This reframes the problem: instead of integrating, we "just" need to sample from a complex, high-dimensional, and even unnormalized distribution <span class="arithmatex">\(p(\theta\mid D)\)</span> (since <span class="arithmatex">\(p(D)\)</span> is unknown). Embracing randomness becomes the way to overcome the curse of dimensionality. What we need is not an integrator, but a sampler.</p>
<h1 id="5-generating-samples-via-stochastic-processes-mcmc">5. Generating Samples via Stochastic Processes: MCMC<a class="headerlink" href="#5-generating-samples-via-stochastic-processes-mcmc" title="Permanent link">&para;</a></h1>
<p>How do we build a machine that samples from an arbitrary <span class="arithmatex">\(p(\theta\mid D)\)</span>? The answer returns to Markov chains.</p>
<h2 id="51-toolbox-recap-markov-chains-and-stationary-distributions">5.1 Toolbox Recap: Markov Chains and Stationary Distributions<a class="headerlink" href="#51-toolbox-recap-markov-chains-and-stationary-distributions" title="Permanent link">&para;</a></h2>
<p>Recall key ideas (Lectures 6-8):</p>
<ul>
<li>Markov chain: a memoryless stochastic process; the future depends only on the present.</li>
<li>Stationary distribution <span class="arithmatex">\(\pi\)</span>: under conditions such as ergodicity, the chain converges to a limiting distribution <span class="arithmatex">\(\pi\)</span>.</li>
<li>Perron-Frobenius theorem: provides existence/uniqueness guarantees for broad classes.</li>
<li>Detailed balance (sufficient condition): <span class="arithmatex">\(\pi(\theta)\, W(\theta'\mid\theta) = \pi(\theta')\, W(\theta\mid\theta')\)</span>, where <span class="arithmatex">\(W\)</span> is the transition rule.</li>
</ul>
<h2 id="52-core-idea-of-mcmc">5.2 Core Idea of MCMC<a class="headerlink" href="#52-core-idea-of-mcmc" title="Permanent link">&para;</a></h2>
<p>Design a Markov chain whose unique stationary distribution equals the target posterior <span class="arithmatex">\(\pi(\theta)=p(\theta\mid D)\)</span>. Then:</p>
<p>1) Pick any initial point <span class="arithmatex">\(\theta^{(0)}\)</span>.
2) Evolve the chain according to its transition rule.
3) Run long enough to "forget" the initial condition (burn-in).
4) Record the subsequent states <span class="arithmatex">\(\{\theta^{(i)}\}\)</span>.</p>
<p>By the definition of stationarity, <span class="arithmatex">\(\{\theta^{(i)}\}\)</span> are samples from <span class="arithmatex">\(p(\theta\mid D)\)</span>. This inverts the usual direction of analysis: earlier we learned "given <span class="arithmatex">\(W\)</span>, find <span class="arithmatex">\(\pi\)</span>"; now we ask "given desired <span class="arithmatex">\(\pi\)</span>, construct <span class="arithmatex">\(W\)</span>" - and detailed balance provides the blueprint.</p>
<h1 id="6-metropolis-hastings-algorithm-a-practical-recipe">6. Metropolis-Hastings Algorithm: A Practical Recipe<a class="headerlink" href="#6-metropolis-hastings-algorithm-a-practical-recipe" title="Permanent link">&para;</a></h1>
<p>How do we construct a suitable <span class="arithmatex">\(W\)</span> in practice? The Metropolis-Hastings (MH) algorithm provides a general and powerful recipe for building a Markov chain with any target distribution.</p>
<p>Historically, Metropolis et al. (1953) introduced the symmetric-proposal version to tackle high-dimensional problems in physics; Hastings (1970) generalized it to asymmetric proposals. Today MH is central across Bayesian computation and many other fields.</p>
<h2 id="61-algorithm-metropolis-hastings-mh">6.1 Algorithm: Metropolis-Hastings (MH)<a class="headerlink" href="#61-algorithm-metropolis-hastings-mh" title="Permanent link">&para;</a></h2>
<p>Metropolis (1953) introduced the symmetric-proposal version; Hastings (1970) generalized to asymmetric proposals. MH is ubiquitous in Bayesian computation and beyond.</p>
<p>Steps:</p>
<p>1) Initialize with any <span class="arithmatex">\(\theta^{(0)}\)</span>.
2) For <span class="arithmatex">\(i=1,2,\dots,N\)</span>:
- Propose <span class="arithmatex">\(\theta' \sim q(\theta'\mid \theta^{(i-1)})\)</span> (e.g., Gaussian random walk).
- Compute acceptance probability
  $$
  A(\theta'\mid\theta) = \min\Bigl(1, \frac{p(\theta')\, q(\theta\mid\theta')}{p(\theta)\, q(\theta'\mid\theta)}\Bigr),
  $$
  where <span class="arithmatex">\(p(\theta)\)</span> denotes the (unnormalized) target <span class="arithmatex">\(p(\theta\mid D)\)</span>.
- Draw <span class="arithmatex">\(u\sim\mathrm{Unif}(0,1)\)</span>. If <span class="arithmatex">\(u&lt;A\)</span>, accept (<span class="arithmatex">\(\theta^{(i)}=\theta'\)</span>); else reject (<span class="arithmatex">\(\theta^{(i)}=\theta^{(i-1)}\)</span>).</p>
<h2 id="62-why-it-works-enforcing-detailed-balance">6.2 Why It Works: Enforcing Detailed Balance<a class="headerlink" href="#62-why-it-works-enforcing-detailed-balance" title="Permanent link">&para;</a></h2>
<p>The MH acceptance rule ensures detailed balance and thus the target stationary distribution. Two key ratios appear in <span class="arithmatex">\(A(\theta'\mid\theta)\)</span>:</p>
<ul>
<li>Target ratio <span class="arithmatex">\(\dfrac{p(\theta')}{p(\theta)}\)</span>: if the proposal moves to a higher-probability region, this ratio exceeds 1 and the move is always accepted; if lower, the move is accepted with some probability, enabling exploration beyond just the peaks.</li>
<li>Proposal correction <span class="arithmatex">\(\dfrac{q(\theta\mid\theta')}{q(\theta'\mid\theta)}\)</span>: compensates for any asymmetry or bias in proposals. With a symmetric proposal (e.g., Gaussian random walk), this factor is 1 and we recover the original Metropolis rule <span class="arithmatex">\(A=\min\bigl(1, p(\theta')/p(\theta)\bigr)\)</span>.</li>
</ul>
<p>Crucially, the evidence <span class="arithmatex">\(p(D)\)</span> cancels in ratios:</p>
<div class="arithmatex">\[
\frac{p(\theta\mid D)}{p(\theta'\mid D)} = \frac{p(D\mid\theta)\,p(\theta)}{p(D\mid\theta')\,p(\theta')}.
\]</div>
<p>Hence we only need likelihood and prior up to constants. This neatly sidesteps the hardest normalization in Bayesian inference while retaining correctness via detailed balance.</p>
<h1 id="7-using-mcmc-for-lotka-volterra-parameter-inference">7. Using MCMC for Lotka-Volterra Parameter Inference<a class="headerlink" href="#7-using-mcmc-for-lotka-volterra-parameter-inference" title="Permanent link">&para;</a></h1>
<p>We now apply MH to infer <span class="arithmatex">\((\alpha,\beta,\gamma,\delta)\)</span> from the Hudson's Bay data. The ODE model lacks a simple closed-form solution; for each parameter set we integrate numerically, making the posterior highly nontrivial - an ideal use case for MCMC. This case illustrates an end-to-end workflow: start from data, posit a mechanistic model, define a Bayesian posterior, and sample it via a carefully designed stochastic process.</p>
<h2 id="71-modeling-plan">7.1 Modeling Plan<a class="headerlink" href="#71-modeling-plan" title="Permanent link">&para;</a></h2>
<p>1) Model: Lotka-Volterra ODEs.
2) Data: 1900-1920 hare (H) and lynx (L) counts.
3) Target: posterior <span class="arithmatex">\(p(\alpha,\beta,\gamma,\delta\mid\text{data})\)</span>.
4) Method: MH sampler in 4D parameter space.
- Posterior <span class="arithmatex">\(\propto\)</span> likelihood <span class="arithmatex">\(\times\)</span> prior.
  - Likelihood: compare model predictions with data, e.g., log-normal errors.
  - Prior: weakly informative (wide normals or uniforms).
- Proposal: Gaussian random walk.</p>
<h2 id="72-python-implementation">7.2 Python Implementation<a class="headerlink" href="#72-python-implementation" title="Permanent link">&para;</a></h2>
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">scipy.integrate</span><span class="w"> </span><span class="kn">import</span> <span class="n">odeint</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">scipy.stats</span><span class="w"> </span><span class="kn">import</span> <span class="n">norm</span>

<span class="c1"># 1. Load data</span>
<span class="c1"># Data source: https://github.com/stan-dev/example-models</span>
<span class="c1"># Year, Lynx (x1000), Hare (x1000)</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span>
    <span class="p">[</span><span class="mi">1900</span><span class="p">,</span> <span class="mf">4.0</span><span class="p">,</span> <span class="mf">30.0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1901</span><span class="p">,</span> <span class="mf">6.1</span><span class="p">,</span> <span class="mf">47.2</span><span class="p">],</span> <span class="p">[</span><span class="mi">1902</span><span class="p">,</span> <span class="mf">9.8</span><span class="p">,</span> <span class="mf">70.2</span><span class="p">],</span>
    <span class="p">[</span><span class="mi">1903</span><span class="p">,</span> <span class="mf">35.2</span><span class="p">,</span> <span class="mf">77.4</span><span class="p">],</span> <span class="p">[</span><span class="mi">1904</span><span class="p">,</span> <span class="mf">59.4</span><span class="p">,</span> <span class="mf">36.3</span><span class="p">],</span> <span class="p">[</span><span class="mi">1905</span><span class="p">,</span> <span class="mf">41.7</span><span class="p">,</span> <span class="mf">20.6</span><span class="p">],</span>
    <span class="p">[</span><span class="mi">1906</span><span class="p">,</span> <span class="mf">19.0</span><span class="p">,</span> <span class="mf">18.1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1907</span><span class="p">,</span> <span class="mf">13.0</span><span class="p">,</span> <span class="mf">21.4</span><span class="p">],</span> <span class="p">[</span><span class="mi">1908</span><span class="p">,</span> <span class="mf">8.3</span><span class="p">,</span> <span class="mf">22.0</span><span class="p">],</span>
    <span class="p">[</span><span class="mi">1909</span><span class="p">,</span> <span class="mf">9.1</span><span class="p">,</span> <span class="mf">25.4</span><span class="p">],</span> <span class="p">[</span><span class="mi">1910</span><span class="p">,</span> <span class="mf">7.4</span><span class="p">,</span> <span class="mf">27.1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1911</span><span class="p">,</span> <span class="mf">8.0</span><span class="p">,</span> <span class="mf">40.3</span><span class="p">],</span>
    <span class="p">[</span><span class="mi">1912</span><span class="p">,</span> <span class="mf">12.3</span><span class="p">,</span> <span class="mf">57.0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1913</span><span class="p">,</span> <span class="mf">19.5</span><span class="p">,</span> <span class="mf">76.6</span><span class="p">],</span> <span class="p">[</span><span class="mi">1914</span><span class="p">,</span> <span class="mf">45.7</span><span class="p">,</span> <span class="mf">52.3</span><span class="p">],</span>
    <span class="p">[</span><span class="mi">1915</span><span class="p">,</span> <span class="mf">51.1</span><span class="p">,</span> <span class="mf">19.5</span><span class="p">],</span> <span class="p">[</span><span class="mi">1916</span><span class="p">,</span> <span class="mf">29.7</span><span class="p">,</span> <span class="mf">11.2</span><span class="p">],</span> <span class="p">[</span><span class="mi">1917</span><span class="p">,</span> <span class="mf">15.8</span><span class="p">,</span> <span class="mf">7.6</span><span class="p">],</span>
    <span class="p">[</span><span class="mi">1918</span><span class="p">,</span> <span class="mf">9.7</span><span class="p">,</span> <span class="mf">14.6</span><span class="p">],</span> <span class="p">[</span><span class="mi">1919</span><span class="p">,</span> <span class="mf">10.1</span><span class="p">,</span> <span class="mf">16.2</span><span class="p">],</span> <span class="p">[</span><span class="mi">1920</span><span class="p">,</span> <span class="mf">8.6</span><span class="p">,</span> <span class="mf">24.7</span><span class="p">]</span>
<span class="p">])</span>
<span class="n">years</span> <span class="o">=</span> <span class="n">data</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span>
<span class="n">lynx_data</span> <span class="o">=</span> <span class="n">data</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span>
<span class="n">hare_data</span> <span class="o">=</span> <span class="n">data</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">]</span>
<span class="n">y_obs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">((</span><span class="n">hare_data</span><span class="p">,</span> <span class="n">lynx_data</span><span class="p">))</span><span class="o">.</span><span class="n">T</span> <span class="c1"># Observed data [H, L]</span>

<span class="c1"># 2. Define Lotka-Volterra model</span>
<span class="k">def</span><span class="w"> </span><span class="nf">lotka_volterra</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">gamma</span><span class="p">,</span> <span class="n">delta</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Lotka-Volterra differential equations</span>
<span class="sd">    y: [H, L] population array</span>
<span class="sd">    t: time</span>
<span class="sd">    alpha, beta, gamma, delta: model parameters</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">H</span><span class="p">,</span> <span class="n">L</span> <span class="o">=</span> <span class="n">y</span>
    <span class="n">dH_dt</span> <span class="o">=</span> <span class="n">alpha</span> <span class="o">*</span> <span class="n">H</span> <span class="o">-</span> <span class="n">beta</span> <span class="o">*</span> <span class="n">H</span> <span class="o">*</span> <span class="n">L</span>
    <span class="n">dL_dt</span> <span class="o">=</span> <span class="n">delta</span> <span class="o">*</span> <span class="n">H</span> <span class="o">*</span> <span class="n">L</span> <span class="o">-</span> <span class="n">gamma</span> <span class="o">*</span> <span class="n">L</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">dH_dt</span><span class="p">,</span> <span class="n">dL_dt</span><span class="p">]</span>

<span class="c1"># 3. Define log posterior probability function</span>
<span class="k">def</span><span class="w"> </span><span class="nf">log_posterior</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">y_obs</span><span class="p">,</span> <span class="n">t_obs</span><span class="p">):</span>
    <span class="n">alpha</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">gamma</span><span class="p">,</span> <span class="n">delta</span> <span class="o">=</span> <span class="n">theta</span>

    <span class="c1"># a. Log-Prior</span>
    <span class="c1"># Assume parameters follow wide normal distributions, and must be positive</span>
    <span class="k">if</span> <span class="nb">any</span><span class="p">(</span><span class="n">p</span> <span class="o">&lt;=</span> <span class="mi">0</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">theta</span><span class="p">):</span>
        <span class="k">return</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span>
    <span class="n">log_prior_alpha</span> <span class="o">=</span> <span class="n">norm</span><span class="o">.</span><span class="n">logpdf</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">log_prior_beta</span> <span class="o">=</span> <span class="n">norm</span><span class="o">.</span><span class="n">logpdf</span><span class="p">(</span><span class="n">beta</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mf">0.05</span><span class="p">)</span>
    <span class="n">log_prior_gamma</span> <span class="o">=</span> <span class="n">norm</span><span class="o">.</span><span class="n">logpdf</span><span class="p">(</span><span class="n">gamma</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">log_prior_delta</span> <span class="o">=</span> <span class="n">norm</span><span class="o">.</span><span class="n">logpdf</span><span class="p">(</span><span class="n">delta</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="mf">0.02</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mf">0.02</span><span class="p">)</span>
    <span class="n">log_p</span> <span class="o">=</span> <span class="n">log_prior_alpha</span> <span class="o">+</span> <span class="n">log_prior_beta</span> <span class="o">+</span> <span class="n">log_prior_gamma</span> <span class="o">+</span> <span class="n">log_prior_delta</span>

    <span class="c1"># b. Log-Likelihood</span>
    <span class="c1"># Initial conditions use the first point of data</span>
    <span class="n">y0</span> <span class="o">=</span> <span class="n">y_obs</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:]</span>
    <span class="c1"># Numerically solve differential equations using odeint</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">odeint</span><span class="p">(</span><span class="n">lotka_volterra</span><span class="p">,</span> <span class="n">y0</span><span class="p">,</span> <span class="n">t_obs</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">gamma</span><span class="p">,</span> <span class="n">delta</span><span class="p">))</span>

    <span class="c1"># Assume errors follow a log-normal distribution, equivalent to log-transformed data following a normal distribution</span>
    <span class="c1"># We also need to estimate a standard deviation sigma for the error</span>
    <span class="c1"># For simplicity, we fix a reasonable sigma value here</span>
    <span class="n">sigma</span> <span class="o">=</span> <span class="mf">0.5</span> 
    <span class="n">log_likelihood</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">norm</span><span class="o">.</span><span class="n">logpdf</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">y_obs</span><span class="p">),</span> <span class="n">loc</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">y_pred</span><span class="p">),</span> <span class="n">scale</span><span class="o">=</span><span class="n">sigma</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">log_p</span> <span class="o">+</span> <span class="n">log_likelihood</span>

<span class="c1"># 4. Implement Metropolis-Hastings MCMC</span>
<span class="k">def</span><span class="w"> </span><span class="nf">metropolis_hastings</span><span class="p">(</span><span class="n">log_posterior_func</span><span class="p">,</span> <span class="n">n_iter</span><span class="p">,</span> <span class="n">initial_theta</span><span class="p">,</span> <span class="n">proposal_std</span><span class="p">,</span> <span class="n">y_obs</span><span class="p">,</span> <span class="n">t_obs</span><span class="p">):</span>
    <span class="c1"># Initialization</span>
    <span class="n">n_params</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">initial_theta</span><span class="p">)</span>
    <span class="n">chain</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n_iter</span><span class="p">,</span> <span class="n">n_params</span><span class="p">))</span>
    <span class="n">chain</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">initial_theta</span>

    <span class="n">current_log_post</span> <span class="o">=</span> <span class="n">log_posterior_func</span><span class="p">(</span><span class="n">initial_theta</span><span class="p">,</span> <span class="n">y_obs</span><span class="p">,</span> <span class="n">t_obs</span><span class="p">)</span>

    <span class="n">accepted_count</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_iter</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">i</span> <span class="o">%</span> <span class="mi">1000</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Iteration </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">n_iter</span><span class="si">}</span><span class="s2">...&quot;</span><span class="p">)</span>

        <span class="c1"># a. Propose new point</span>
        <span class="n">proposal_theta</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="n">chain</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:],</span> <span class="n">scale</span><span class="o">=</span><span class="n">proposal_std</span><span class="p">)</span>

        <span class="c1"># b. Calculate acceptance probability</span>
        <span class="n">proposal_log_post</span> <span class="o">=</span> <span class="n">log_posterior_func</span><span class="p">(</span><span class="n">proposal_theta</span><span class="p">,</span> <span class="n">y_obs</span><span class="p">,</span> <span class="n">t_obs</span><span class="p">)</span>

        <span class="n">log_alpha</span> <span class="o">=</span> <span class="n">proposal_log_post</span> <span class="o">-</span> <span class="n">current_log_post</span>

        <span class="c1"># c. Accept or reject</span>
        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">())</span> <span class="o">&lt;</span> <span class="n">log_alpha</span><span class="p">:</span>
            <span class="n">chain</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">proposal_theta</span>
            <span class="n">current_log_post</span> <span class="o">=</span> <span class="n">proposal_log_post</span>
            <span class="n">accepted_count</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">chain</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">chain</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Acceptance rate: </span><span class="si">{</span><span class="n">accepted_count</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">n_iter</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">chain</span>

<span class="c1"># 5. Run MCMC</span>
<span class="n">n_iterations</span> <span class="o">=</span> <span class="mi">50000</span>
<span class="n">burn_in</span> <span class="o">=</span> <span class="mi">10000</span> <span class="c1"># Discard early unstable samples</span>
<span class="n">initial_params</span> <span class="o">=</span> <span class="p">[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.02</span><span class="p">]</span> <span class="c1"># Initial guess</span>
<span class="n">proposal_widths</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.001</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.001</span><span class="p">]</span> <span class="c1"># Proposal distribution standard deviation, needs tuning</span>
<span class="n">t_span</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">years</span><span class="p">))</span> <span class="c1"># Time points (0, 1, 2, ...)</span>

<span class="n">chain</span> <span class="o">=</span> <span class="n">metropolis_hastings</span><span class="p">(</span><span class="n">log_posterior</span><span class="p">,</span> <span class="n">n_iterations</span><span class="p">,</span> <span class="n">initial_params</span><span class="p">,</span> <span class="n">proposal_widths</span><span class="p">,</span> <span class="n">y_obs</span><span class="p">,</span> <span class="n">t_span</span><span class="p">)</span>

<span class="c1"># Discard burn-in and thin if desired</span>
<span class="n">posterior_samples</span> <span class="o">=</span> <span class="n">chain</span><span class="p">[</span><span class="n">burn_in</span><span class="p">:,</span> <span class="p">:]</span>

<span class="c1"># 6. Diagnostics and visualization</span>
<span class="n">param_names</span> <span class="o">=</span> <span class="p">[</span><span class="sa">r</span><span class="s2">&quot;alpha (hares)&quot;</span><span class="p">,</span> <span class="sa">r</span><span class="s2">&quot;beta (predation)&quot;</span><span class="p">,</span> <span class="sa">r</span><span class="s2">&quot;gamma (lynx)&quot;</span><span class="p">,</span> <span class="sa">r</span><span class="s2">&quot;delta (conversion)&quot;</span><span class="p">]</span>

<span class="c1"># a. Trace plots</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">4</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">posterior_samples</span><span class="p">[:,</span> <span class="n">i</span><span class="p">])</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Trace of </span><span class="si">{</span><span class="n">param_names</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Iteration&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Parameter Value&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># b. Plot posterior distributions</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">4</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">posterior_samples</span><span class="p">[:,</span> <span class="n">i</span><span class="p">],</span> <span class="n">bins</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">density</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Posterior of </span><span class="si">{</span><span class="n">param_names</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Parameter Value&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Density&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># c. Plot model predictions vs. real data</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="c1"># Randomly sample some parameter combinations from the posterior distribution for simulation</span>
<span class="n">n_samples_plot</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">sample_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">posterior_samples</span><span class="p">),</span> <span class="n">n_samples_plot</span><span class="p">)</span>

<span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">sample_indices</span><span class="p">:</span>
    <span class="n">params</span> <span class="o">=</span> <span class="n">posterior_samples</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="p">:]</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">odeint</span><span class="p">(</span><span class="n">lotka_volterra</span><span class="p">,</span> <span class="n">y_obs</span><span class="p">[</span><span class="mi">0</span><span class="p">,:],</span> <span class="n">t_span</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="nb">tuple</span><span class="p">(</span><span class="n">params</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">years</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;skyblue&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span> <span class="c1"># Predicted hares</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">years</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;lightcoral&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span> <span class="c1"># Predicted lynx</span>

<span class="c1"># Plot original data points</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">years</span><span class="p">,</span> <span class="n">hare_data</span><span class="p">,</span> <span class="s1">&#39;o-&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;blue&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Observed Hares&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">years</span><span class="p">,</span> <span class="n">lynx_data</span><span class="p">,</span> <span class="s1">&#39;o-&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Observed Lynx&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Year&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Population (x1000)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Lotka-Volterra Model Fit to Hudson Bay Data&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div>
<p><img alt="Run output" src="../../assets/images/remote/92bf7793-2723-4dd5-b016-7005ec48e792-28a1133f5b.png" /></p>
<p>Trace plots: show sampled values per parameter across iterations. Ideally we see "caterpillar-like" fluctuations around a stable region (the chain has forgotten its initial state and explores the typical set). Strong trends suggest insufficient burn-in or poor proposals (slow mixing).</p>
<p><img alt="Run output" src="../../assets/images/remote/763ed380-ac8b-4e8c-a26c-a71f1bddf16d-1203017672.png" /></p>
<p>Posterior distributions: histograms visualize uncertainty; tall-narrow peaks indicate strong constraints, wide-flat shapes indicate weak information.</p>
<p><img alt="Run output" src="../../assets/images/remote/75e9b1b2-4ff7-4b3f-aa6c-7a7c1988bb4d-43bd03f19f.png" /></p>
<p>Model predictions vs data: thin translucent lines are trajectories from 100 posterior samples, forming a credible band. Observed points lie mostly within, indicating the Lotka-Volterra model with inferred parameters captures the historical predator-prey cycles.</p>
<h1 id="conclusion">Conclusion<a class="headerlink" href="#conclusion" title="Permanent link">&para;</a></h1>
<p>This lecture turns stochastic-process theory from a purely analytical tool into a practical computational engine. Starting from a real scientific problem - inferring model parameters from data - we saw how the Bayesian framework defines the target posterior, but direct computation is blocked by the curse of dimensionality.</p>
<p>MCMC, especially Metropolis-Hastings, provides an elegant way out: by reframing sampling as the steady state of a constructed Markov chain and enforcing detailed balance, we both avoid the evidence and gain an efficient exploration strategy for complex high-dimensional spaces.</p>
<p>This bridges the theoretical first half of the course with applied methods, showing how deep theory becomes an immediately useful tool. MCMC and its variants are cornerstones of modern computational statistics, machine learning, and many quantitative sciences; mastering their core ideas opens the door to much more complex models.</p>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      <script id="__config" type="application/json">{"base": "../..", "features": ["content.code.copy", "navigation.sections", "navigation.expand", "navigation.top", "toc.integrate", "search.highlight"], "search": "../../assets/javascripts/workers/search.973d3a69.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../../assets/javascripts/bundle.f55a23d4.min.js"></script>
      
        <script src="../../assets/javascripts/mathjax.js"></script>
      
        <script src="../../assets/javascripts/language-nav.js"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
      
    
  </body>
</html>