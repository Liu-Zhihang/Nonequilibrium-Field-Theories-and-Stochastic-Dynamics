
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="Course Notes and Code (Erwin Frey, LMU Munich, 2025)">
      
      
        <meta name="author" content="Zhihang Liu">
      
      
        <link rel="canonical" href="https://liu-zhihang.github.io/Nonequilibrium-Field-Theories-and-Stochastic-Dynamics/notes/13.%20Monte%20Carlo%20Sampling%20as%20a%20Stochastic%20Process/">
      
      
        <link rel="prev" href="../12.%20Brownian%20Motion%20and%20the%20Ornstein%E2%80%93Uhlenbeck%20Process/">
      
      
        <link rel="next" href="../14.%20Hamiltonian%20Monte%20Carlo%20Sampling/">
      
      
        
          <link rel="alternate" href="/Nonequilibrium-Field-Theories-and-Stochastic-Dynamics/" hreflang="en">
        
          <link rel="alternate" href="/Nonequilibrium-Field-Theories-and-Stochastic-Dynamics/zh/" hreflang="zh">
        
      
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.7.0">
    
    
      
        <title>13. Monte Carlo Sampling as a Stochastic Process - Nonequilibrium Field Theories and Stochastic Dynamics</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.618322db.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.ab4e12ef.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/video.css">
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#introduction-from-analytical-theory-to-a-computational-tool" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="Nonequilibrium Field Theories and Stochastic Dynamics" class="md-header__button md-logo" aria-label="Nonequilibrium Field Theories and Stochastic Dynamics" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Nonequilibrium Field Theories and Stochastic Dynamics
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              13. Monte Carlo Sampling as a Stochastic Process
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m17.75 4.09-2.53 1.94.91 3.06-2.63-1.81-2.63 1.81.91-3.06-2.53-1.94L12.44 4l1.06-3 1.06 3zm3.5 6.91-1.64 1.25.59 1.98-1.7-1.17-1.7 1.17.59-1.98L15.75 11l2.06-.05L18.5 9l.69 1.95zm-2.28 4.95c.83-.08 1.72 1.1 1.19 1.85-.32.45-.66.87-1.08 1.27C15.17 23 8.84 23 4.94 19.07c-3.91-3.9-3.91-10.24 0-14.14.4-.4.82-.76 1.27-1.08.75-.53 1.93.36 1.85 1.19-.27 2.86.69 5.83 2.89 8.02a9.96 9.96 0 0 0 8.02 2.89m-1.64 2.02a12.08 12.08 0 0 1-7.8-3.47c-2.17-2.19-3.33-5-3.49-7.82-2.81 3.14-2.7 7.96.31 10.98 3.02 3.01 7.84 3.12 10.98.31"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 7a5 5 0 0 1 5 5 5 5 0 0 1-5 5 5 5 0 0 1-5-5 5 5 0 0 1 5-5m0 2a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0-7 2.39 3.42C13.65 5.15 12.84 5 12 5s-1.65.15-2.39.42zM3.34 7l4.16-.35A7.2 7.2 0 0 0 5.94 8.5c-.44.74-.69 1.5-.83 2.29zm.02 10 1.76-3.77a7.131 7.131 0 0 0 2.38 4.14zM20.65 7l-1.77 3.79a7.02 7.02 0 0 0-2.38-4.15zm-.01 10-4.14.36c.59-.51 1.12-1.14 1.54-1.86.42-.73.69-1.5.83-2.29zM12 22l-2.41-3.44c.74.27 1.55.44 2.41.44.82 0 1.63-.17 2.37-.44z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
      <div class="md-header__option">
  <div class="md-select">
    
    <button class="md-header__button md-icon" aria-label="Select language">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m12.87 15.07-2.54-2.51.03-.03A17.5 17.5 0 0 0 14.07 6H17V4h-7V2H8v2H1v2h11.17C11.5 7.92 10.44 9.75 9 11.35 8.07 10.32 7.3 9.19 6.69 8h-2c.73 1.63 1.73 3.17 2.98 4.56l-5.09 5.02L4 19l5-5 3.11 3.11zM18.5 10h-2L12 22h2l1.12-3h4.75L21 22h2zm-2.62 7 1.62-4.33L19.12 17z"/></svg>
    </button>
    <div class="md-select__inner">
      <ul class="md-select__list">
        
          <li class="md-select__item">
            <a href="/Nonequilibrium-Field-Theories-and-Stochastic-Dynamics/" hreflang="en" class="md-select__link">
              English
            </a>
          </li>
        
          <li class="md-select__item">
            <a href="/Nonequilibrium-Field-Theories-and-Stochastic-Dynamics/zh/" hreflang="zh" class="md-select__link">
              简体中文
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</div>
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
      <div class="md-header__source">
        <a href="https://github.com/Liu-Zhihang/Nonequilibrium-Field-Theories-and-Stochastic-Dynamics" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



  

<nav class="md-nav md-nav--primary md-nav--integrated" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="Nonequilibrium Field Theories and Stochastic Dynamics" class="md-nav__button md-logo" aria-label="Nonequilibrium Field Theories and Stochastic Dynamics" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    Nonequilibrium Field Theories and Stochastic Dynamics
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/Liu-Zhihang/Nonequilibrium-Field-Theories-and-Stochastic-Dynamics" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Home
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
    
      
        
        
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" checked>
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    
  
    Course Notes
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            
  
    Course Notes
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../1.%20Course%20Introduction/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    1. Course Introduction
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../2.%20Simple%20Random%20Walk/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    2. Simple Random Walk
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../3.%20Gaussian%20Random%20Walk%20and%20Poisson%20Process/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    3. Gaussian Random Walk and Poisson Process
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../4.%20Gillespie%20Algorithm%2C%20Master%20Equation%2C%20Generating%20Functions%20and%20Population%20Dynamics/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    4. Gillespie Algorithm, Master Equation, Generating Functions and Population Dynamics
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../5.%20Population%20Dynamics%20-%20Linear%20Death%20Process%20and%20Lotka-Volterra%20System/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    5. Population Dynamics - Linear Death Process and Lotka-Volterra System
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../6.%20Fundamental%20Equations%20of%20Markov%20Processes%20%E2%80%94%20Chapman%E2%80%93Kolmogorov%20Equation/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    6. Fundamental Equations of Markov Processes — Chapman–Kolmogorov Equation
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../7.%20Forward%20Master%20Equation%20and%20the%20Q%20Matrix/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    7. Forward Master Equation and the Q Matrix
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../8.%20Perron%E2%80%93Frobenius%20Theorem%2C%20Steady%20States%2C%20and%20Detailed%20Balance/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    8. Perron–Frobenius Theorem, Steady States, and Detailed Balance
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../9.%20Nonequilibrium%20States%20%E2%80%94%20Irreversibility%20and%20Entropy%20Production/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    9. Nonequilibrium States — Irreversibility and Entropy Production
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../10.%20Ehrenfest%20Model%2C%20Entropy%2C%20and%20KL%20Divergence/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    10. Ehrenfest Model, Entropy, and KL Divergence
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../11.%20Continuous%20Markov%20Processes%20and%20the%20Fokker%E2%80%93Planck%20Equation/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    11. Continuous Markov Processes and the Fokker–Planck Equation
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../12.%20Brownian%20Motion%20and%20the%20Ornstein%E2%80%93Uhlenbeck%20Process/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    12. Brownian Motion and the Ornstein–Uhlenbeck Process
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    
  
    13. Monte Carlo Sampling as a Stochastic Process
  

    
  </span>
  
  

      </a>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../14.%20Hamiltonian%20Monte%20Carlo%20Sampling/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    14. Hamiltonian Monte Carlo Sampling
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../15.%20Chemotaxis%2C%20Run-and-Tumble%20Motion%2C%20and%20the%20Keller%E2%80%93Segel%20Model/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    15. Chemotaxis, Run-and-Tumble Motion, and the Keller–Segel Model
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../16.%20The%20Schnitzer%20Model%2C%20Anomalous%20Diffusion%2C%20and%20Motility%E2%80%91Induced%20Phase%20Separation/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    16. The Schnitzer Model, Anomalous Diffusion, and Motility‑Induced Phase Separation
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../17.%20Langevin%20Equation%2C%20Brownian%20Particle%2C%20and%20the%20Fluctuation%E2%80%93Dissipation%20Theorem/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    17. Langevin Equation, Brownian Particle, and the Fluctuation–Dissipation Theorem
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../18.%20Fokker%E2%80%93Planck%20Equation%20and%20the%20Smoluchowski%20Equation%20%E2%80%94%20From%20Random%20Trajectories%20to%20Probability%20Dynamics/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    18. Fokker–Planck Equation and the Smoluchowski Equation — From Random Trajectories to Probability Dynamics
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../19.%20Path%20Integral%20Formulation%20of%20Stochastic%20Processes/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    19. Path Integral Formulation of Stochastic Processes
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../20.%20Stochastic%20Differential%20Equations/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    20. Stochastic Differential Equations
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../21.%20Ito%20Integral%20and%20Unified%20Stochastic%20Process%20Framework/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    21. Ito Integral and Unified Stochastic Process Framework
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../22.%20Path%20Integrals%20for%20Systems%20with%20Multiplicative%20Noise/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    22. Path Integrals for Systems with Multiplicative Noise
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../23.%20From%20Coarse-Graining%20to%20Fluctuation%20Dynamics%20of%20Continuous%20Field%20Theories/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    23. From Coarse-Graining to Fluctuation Dynamics of Continuous Field Theories
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../24.%20Onsager%20Coefficients%2C%20Reciprocity%2C%20and%20the%20Dynamic%20Fluctuation%E2%80%93Dissipation%20Theorem/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    24. Onsager Coefficients, Reciprocity, and the Dynamic Fluctuation–Dissipation Theorem
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../25.%20Gradient%20Dynamics%2C%20Phase%20Transitions%2C%20and%20Relaxation/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    25. Gradient Dynamics, Phase Transitions, and Relaxation
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../26.%20Critical%20Slowing%20Down%2C%20Dynamic%20Response%2C%20and%20Conservation%20Laws/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    26. Critical Slowing Down, Dynamic Response, and Conservation Laws
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../27.%20Hydrodynamics%20of%20Simple%20Fluids%2C%20Inviscid%20Flow%2C%20and%20the%20Euler%20Equation/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    27. Hydrodynamics of Simple Fluids, Inviscid Flow, and the Euler Equation
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../28.%20Viscous%20Fluids%2C%20the%20Navier%E2%80%93Stokes%20Equation%2C%20Entropy%20Balance%2C%20and%20Heat%20Conduction/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    28. Viscous Fluids, the Navier–Stokes Equation, Entropy Balance, and Heat Conduction
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../29.%20Irreversible%20Linear%20Thermodynamics%20and%20Dry%20Diffusive%20Particle%20Systems/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    29. Irreversible Linear Thermodynamics and Dry Diffusive Particle Systems
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../30.%20Brownian%20Particles%20Suspended%20in%20a%20Fluid%20%E2%80%94%20Model%20H/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    30. Brownian Particles Suspended in a Fluid — Model H
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../31.%20Dynamical%20Functionals%2C%20Additive%E2%80%91Noise%20Field%20Theory%2C%20and%20the%20Onsager%E2%80%93Machlup%20Functional/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    31. Dynamical Functionals, Additive‑Noise Field Theory, and the Onsager–Machlup Functional
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../32.%20Janssen%E2%80%93De%20Dominicis%20Response%20Functional%20and%20the%20Fluctuation%E2%80%93Dissipation%20Relation/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    32. Janssen–De Dominicis Response Functional and the Fluctuation–Dissipation Relation
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../33.%20Nonequilibrium%20Work%20and%20Fluctuation%20Theorems/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    33. Nonequilibrium Work and Fluctuation Theorems
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../34.%20Directed%20Percolation%2C%20Absorbing%20States%2C%20and%20Spectral%20Methods/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    34. Directed Percolation, Absorbing States, and Spectral Methods
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../35.%20Path-Integral%20Representation%20of%20the%20Master%20Equation/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    35. Path-Integral Representation of the Master Equation
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../36.%20Coherent-State%20Path%20Integrals%2C%20Operator%20Algebra%2C%20and%20Imaginary%20Noise/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    36. Coherent-State Path Integrals, Operator Algebra, and Imaginary Noise
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../37.%20Kramers-Moyal%20Expansion%20and%20the%20Low-Noise%20Limit%20of%20Path%20Integrals/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    37. Kramers-Moyal Expansion and the Low-Noise Limit of Path Integrals
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../38.%20Multi-Species%20Path%20Integrals%20and%20Cyclic%20Competition%20Dynamics/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    38. Multi-Species Path Integrals and Cyclic Competition Dynamics
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../39.%20From%20Particle%20Jumps%20to%20Continuous%20Field%20Theory/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    39. From Particle Jumps to Continuous Field Theory
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../40.%20Unified%20Field%20Theory%20Framework/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    40. Unified Field Theory Framework
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
      
        
        
      
    
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_3" >
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    
  
    中文笔记
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            
  
    中文笔记
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../zh/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    首页
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../zh/notes/1.%20%E8%AF%BE%E7%A8%8B%E5%AF%BC%E8%AE%BA/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    1. 课程导论
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../zh/notes/2.%20%E7%AE%80%E5%8D%95%E9%9A%8F%E6%9C%BA%E6%B8%B8%E8%B5%B0/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    2. 简单随机游走
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../zh/notes/3.%20%E9%AB%98%E6%96%AF%E9%9A%8F%E6%9C%BA%E6%B8%B8%E8%B5%B0%E4%B8%8E%E6%B3%8A%E6%9D%BE%E8%BF%87%E7%A8%8B/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    3. 高斯随机游走与泊松过程
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../zh/notes/4.%20Gillespie%20%E7%AE%97%E6%B3%95%E3%80%81%E4%B8%BB%E6%96%B9%E7%A8%8B%E3%80%81%E7%94%9F%E6%88%90%E5%87%BD%E6%95%B0%E4%B8%8E%E7%A7%8D%E7%BE%A4%E5%8A%A8%E5%8A%9B%E5%AD%A6/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    4. Gillespie 算法、主方程、生成函数与种群动力学
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../zh/notes/5.%20%E7%A7%8D%E7%BE%A4%E5%8A%A8%E6%80%81%E5%AD%A6%EF%BC%9A%E7%BA%BF%E6%80%A7%E6%AD%BB%E4%BA%A1%E8%BF%87%E7%A8%8B%E4%B8%8ELotka-Volterra%20%E7%B3%BB%E7%BB%9F/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    5. 种群动态学：线性死亡过程与Lotka-Volterra 系统
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../zh/notes/6.%20%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E8%BF%87%E7%A8%8B%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%96%B9%E7%A8%8B%EF%BC%9A%E6%9F%A5%E6%99%AE%E6%9B%BC-%E7%A7%91%E5%B0%94%E8%8E%AB%E6%88%88%E7%BD%97%E5%A4%AB%E6%96%B9%E7%A8%8B/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    6. 马尔可夫过程的基本方程：查普曼-科尔莫戈罗夫方程
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../zh/notes/7.%20%E5%89%8D%E5%90%91%E4%B8%BB%E6%96%B9%E7%A8%8B%E4%B8%8EQ%E7%9F%A9%E9%98%B5/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    7. 前向主方程与Q矩阵
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../zh/notes/8.%20%E4%BD%A9%E9%BE%99-%E5%BC%97%E7%BD%97%E8%B4%9D%E5%B0%BC%E4%B9%8C%E6%96%AF%E5%AE%9A%E7%90%86%E3%80%81%E7%A8%B3%E6%80%81%E4%B8%8E%E7%BB%86%E8%87%B4%E5%B9%B3%E8%A1%A1/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    8. 佩龙-弗罗贝尼乌斯定理、稳态与细致平衡
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../zh/notes/9.%20%E9%9D%9E%E5%B9%B3%E8%A1%A1%E6%80%81%EF%BC%9A%E4%B8%8D%E5%8F%AF%E9%80%86%E6%80%A7%E4%B8%8E%E7%86%B5%E4%BA%A7%E7%94%9F%E7%9A%84%E6%8E%A8%E8%AE%BA/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    9. 非平衡态：不可逆性与熵产生的推论
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../zh/notes/10.%20%E5%9F%83%E4%BC%A6%E8%B4%B9%E6%96%AF%E7%89%B9%E6%A8%A1%E5%9E%8B%E3%80%81%E7%86%B5%E4%B8%8EKL%E6%95%A3%E5%BA%A6/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    10. 埃伦费斯特模型、熵与KL散度
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../zh/notes/11.%20%E8%BF%9E%E7%BB%AD%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E8%BF%87%E7%A8%8B%E4%B8%8E%E7%A6%8F%E5%85%8B-%E6%99%AE%E6%9C%97%E5%85%8B%E6%96%B9%E7%A8%8B/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    11. 连续马尔可夫过程与福克-普朗克方程
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../zh/notes/12.%20%E5%B8%83%E6%9C%97%E8%BF%90%E5%8A%A8%E4%B8%8E%E5%A5%A5%E6%81%A9%E6%96%AF%E5%9D%A6-%E4%B9%8C%E4%BC%A6%E8%B4%9D%E5%85%8B%E8%BF%87%E7%A8%8B/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    12. 布朗运动与奥恩斯坦-乌伦贝克过程
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../zh/notes/13.%20%E4%BD%9C%E4%B8%BA%E9%9A%8F%E6%9C%BA%E8%BF%87%E7%A8%8B%E7%9A%84%E8%92%99%E7%89%B9%E5%8D%A1%E6%B4%9B%E9%87%87%E6%A0%B7/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    13. 作为随机过程的蒙特卡洛采样
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../zh/notes/14.%20%E5%93%88%E5%AF%86%E5%B0%94%E9%A1%BF%E8%92%99%E7%89%B9%E5%8D%A1%E6%B4%9B%E9%87%87%E6%A0%B7/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    14. 哈密尔顿蒙特卡洛采样
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../zh/notes/15.%20%E8%B6%8B%E5%8C%96%E6%80%A7%E3%80%81%E8%B7%91%E5%8A%A8-%E7%BF%BB%E6%BB%9A%E8%BF%90%E5%8A%A8%E4%B8%8EKeller-Segel%E6%A8%A1%E5%9E%8B/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    15. 趋化性、跑动-翻滚运动与Keller-Segel模型
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../zh/notes/16.%20Schnitzer%E6%A8%A1%E5%9E%8B%E3%80%81%E5%8F%8D%E5%B8%B8%E6%89%A9%E6%95%A3%E4%B8%8E%E8%BF%90%E5%8A%A8%E8%AF%B1%E5%AF%BC%E7%9B%B8%E5%88%86%E7%A6%BB/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    16. Schnitzer模型、反常扩散与运动诱导相分离
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../zh/notes/17.%20%E6%9C%97%E4%B9%8B%E4%B8%87%E6%96%B9%E7%A8%8B%E3%80%81%E5%B8%83%E6%9C%97%E7%B2%92%E5%AD%90%E4%B8%8E%E6%B6%A8%E8%90%BD-%E8%80%97%E6%95%A3%E5%AE%9A%E7%90%86/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    17. 朗之万方程、布朗粒子与涨落-耗散定理
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../zh/notes/18.%20%E7%A6%8F%E5%85%8B-%E6%99%AE%E6%9C%97%E5%85%8B%E6%96%B9%E7%A8%8B%E4%B8%8E%E6%96%AF%E6%91%A9%E6%A3%B1%E9%9C%8D%E5%A4%AB%E6%96%AF%E5%9F%BA%E6%96%B9%E7%A8%8B%EF%BC%9A%E4%BB%8E%E9%9A%8F%E6%9C%BA%E8%BD%A8%E8%BF%B9%E5%88%B0%E6%A6%82%E7%8E%87%E5%8A%A8%E5%8A%9B%E5%AD%A6/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    18. 福克-普朗克方程与斯摩棱霍夫斯基方程：从随机轨迹到概率动力学
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../zh/notes/19.%20%E9%9A%8F%E6%9C%BA%E8%BF%87%E7%A8%8B%E7%9A%84%E8%B7%AF%E5%BE%84%E7%A7%AF%E5%88%86%E8%A1%A8%E8%BF%B0/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    19. 随机过程的路径积分表述
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../zh/notes/20.%20%E9%9A%8F%E6%9C%BA%E5%BE%AE%E5%88%86%E6%96%B9%E7%A8%8B/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    20. 随机微分方程
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../zh/notes/21.%20%E4%BC%8A%E8%97%A4%E7%A7%AF%E5%88%86%E4%B8%8E%E7%BB%9F%E4%B8%80%E7%9A%84%E9%9A%8F%E6%9C%BA%E8%BF%87%E7%A8%8B%E6%A1%86%E6%9E%B6/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    21. 伊藤积分与统一的随机过程框架
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../zh/notes/22.%20%E5%90%AB%E4%B9%98%E6%80%A7%E5%99%AA%E5%A3%B0%E7%B3%BB%E7%BB%9F%E7%9A%84%E8%B7%AF%E5%BE%84%E7%A7%AF%E5%88%86/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    22. 含乘性噪声系统的路径积分
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../zh/notes/23.%20%E4%BB%8E%E7%B2%97%E7%B2%92%E5%8C%96%E5%88%B0%E8%BF%9E%E7%BB%AD%E5%9C%BA%E8%AE%BA%E6%B6%A8%E8%90%BD%E5%8A%A8%E5%8A%9B%E5%AD%A6/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    23. 从粗粒化到连续场论涨落动力学
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../zh/notes/24.%20%E6%98%82%E8%90%A8%E6%A0%BC%E7%B3%BB%E6%95%B0%E3%80%81%E5%80%92%E6%98%93%E5%85%B3%E7%B3%BB%E4%B8%8E%E5%8A%A8%E6%80%81%E6%B6%A8%E8%90%BD-%E8%80%97%E6%95%A3%E5%AE%9A%E7%90%86/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    24. 昂萨格系数、倒易关系与动态涨落-耗散定理
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../zh/notes/25.%20%E6%A2%AF%E5%BA%A6%E5%8A%A8%E5%8A%9B%E5%AD%A6%E3%80%81%E7%9B%B8%E5%8F%98%E4%B8%8E%E5%BC%9B%E8%B1%AB/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    25. 梯度动力学、相变与弛豫
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../zh/notes/26.%20%E4%B8%B4%E7%95%8C%E6%85%A2%E5%8C%96%E3%80%81%E5%8A%A8%E6%80%81%E5%93%8D%E5%BA%94%E4%B8%8E%E5%AE%88%E6%81%92%E5%BE%8B/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    26. 临界慢化、动态响应与守恒律
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../zh/notes/27.%20%E7%AE%80%E5%8D%95%E6%B5%81%E4%BD%93%E3%80%81%E6%97%A0%E6%91%A9%E6%93%A6%E6%B5%81%E4%BD%93%E4%B8%8E%E6%AC%A7%E6%8B%89%E6%96%B9%E7%A8%8B%E7%9A%84%E6%B5%81%E4%BD%93%E5%8A%A8%E5%8A%9B%E5%AD%A6/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    27. 简单流体、无摩擦流体与欧拉方程的流体动力学
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../zh/notes/28.%20%E7%B2%98%E6%80%A7%E6%B5%81%E4%BD%93%E3%80%81%E7%BA%B3%E7%BB%B4-%E6%96%AF%E6%89%98%E5%85%8B%E6%96%AF%E6%96%B9%E7%A8%8B%E3%80%81%E7%86%B5%E5%B9%B3%E8%A1%A1%E4%B8%8E%E7%83%AD%E4%BC%A0%E5%AF%BC/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    28. 粘性流体、纳维-斯托克斯方程、熵平衡与热传导
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../zh/notes/29.%20%E4%B8%8D%E5%8F%AF%E9%80%86%E7%BA%BF%E6%80%A7%E7%83%AD%E5%8A%9B%E5%AD%A6%E4%B8%8E%E5%B9%B2%E6%80%A7%E6%89%A9%E6%95%A3%E7%B2%92%E5%AD%90%E7%B3%BB%E7%BB%9F/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    29. 不可逆线性热力学与干性扩散粒子系统
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../zh/notes/30.%20%E6%82%AC%E6%B5%AE%E5%9C%A8%E6%B5%81%E4%BD%93%E4%B8%AD%E7%9A%84%E5%B8%83%E6%9C%97%E7%B2%92%E5%AD%90%20%E2%80%94%20H%E6%A8%A1%E5%9E%8B/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    30. 悬浮在流体中的布朗粒子 — H模型
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../zh/notes/31.%20%E5%8A%A8%E6%80%81%E6%B3%9B%E5%87%BD%E3%80%81%E5%8A%A0%E6%80%A7%E5%99%AA%E5%A3%B0%E5%9C%BA%E8%AE%BA%E4%B8%8EOnsager-Machlup%E6%B3%9B%E5%87%BD/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    31. 动态泛函、加性噪声场论与Onsager-Machlup泛函
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../zh/notes/32.%20Janssen-De%20Dominicis%20%E5%93%8D%E5%BA%94%E6%B3%9B%E5%87%BD%E4%B8%8E%E6%B6%A8%E8%90%BD-%E8%80%97%E6%95%A3%E5%85%B3%E7%B3%BB/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    32. Janssen-De Dominicis 响应泛函与涨落-耗散关系
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../zh/notes/33.%20%E9%9D%9E%E5%B9%B3%E8%A1%A1%E5%8A%9F%E4%B8%8E%E6%B6%A8%E8%90%BD%E5%AE%9A%E7%90%86/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    33. 非平衡功与涨落定理
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../zh/notes/34.%20%E6%9C%89%E5%90%91%E6%B8%97%E6%B5%81%E3%80%81%E5%90%B8%E6%94%B6%E6%80%81%E4%B8%8E%E8%B0%B1%E6%96%B9%E6%B3%95/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    34. 有向渗流、吸收态与谱方法
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../zh/notes/35.%20%E4%B8%BB%E6%96%B9%E7%A8%8B%E7%9A%84%E8%B7%AF%E5%BE%84%E7%A7%AF%E5%88%86%E8%A1%A8%E7%A4%BA/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    35. 主方程的路径积分表示
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../zh/notes/36.%20%E7%9B%B8%E5%B9%B2%E6%80%81%E8%B7%AF%E5%BE%84%E7%A7%AF%E5%88%86%E3%80%81%E7%AE%97%E7%AC%A6%E4%BB%A3%E6%95%B0%E4%B8%8E%E8%99%9A%E5%99%AA%E5%A3%B0/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    36. 相干态路径积分、算符代数与虚噪声
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../zh/notes/37.%20Kramers-Moyal%20%E5%B1%95%E5%BC%80%E4%B8%8E%E8%B7%AF%E5%BE%84%E7%A7%AF%E5%88%86%E7%9A%84%E4%BD%8E%E5%99%AA%E5%A3%B0%E6%9E%81%E9%99%90/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    37. Kramers-Moyal 展开与路径积分的低噪声极限
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../zh/notes/38.%20%E5%A4%9A%E7%89%A9%E7%A7%8D%E8%B7%AF%E5%BE%84%E7%A7%AF%E5%88%86%E4%B8%8E%E5%BE%AA%E7%8E%AF%E7%AB%9E%E4%BA%89%E5%8A%A8%E5%8A%9B%E5%AD%A6/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    38. 多物种路径积分与循环竞争动力学
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../zh/notes/39.%20%E4%BB%8E%E7%B2%92%E5%AD%90%E8%B7%B3%E8%B7%83%E5%88%B0%E8%BF%9E%E7%BB%AD%E5%9C%BA%E8%AE%BA/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    39. 从粒子跳跃到连续场论
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../zh/notes/40.%20%E7%BB%9F%E4%B8%80%E7%9A%84%E5%9C%BA%E8%AE%BA%E6%A1%86%E6%9E%B6/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    40. 统一的场论框架
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
          
          
            <div class="md-content" data-md-component="content">
              
              <article class="md-content__inner md-typeset">
                
                  


  
  


<h1 id="introduction-from-analytical-theory-to-a-computational-tool">Introduction: From Analytical Theory to a Computational Tool<a class="headerlink" href="#introduction-from-analytical-theory-to-a-computational-tool" title="Permanent link">&para;</a></h1>
<p><img alt="Lecture board" src="../../assets/images/remote/8991dfc8-9e11-4011-a9e6-84f1507556da-ed64b1d80a.jpg" /></p>
<p>This lecture is TA-led. In the past several sessions, Prof. Erwin Frey has built a powerful theoretical framework for understanding and describing stochastic processes. Starting from the basics of Markov processes, we derived the Chapman-Kolmogorov equation, and then obtained the master equation and the Fokker-Planck equation. We also discussed steady states, the detailed-balance condition, and the Perron-Frobenius theorem, which provide deep insight into how systems reach and maintain equilibrium.</p>
<p>So far our perspective has been analytical: given a stochastic process (defined by its transition rates), we analyze its behavior, e.g., what the steady-state distribution is. In this lecture, we shift from analysis to synthesis and application. We show how the Markov-process framework - especially Markov chains - can be turned into a practical computational tool to solve a fundamental problem across the sciences: statistical inference, i.e., learning model parameters from data.</p>
<p>By cleverly designing a Markov process whose stationary distribution is exactly a target distribution, we can generate samples from that distribution and thereby solve otherwise intractable integrals. This approach is called Markov chain Monte Carlo (MCMC). It has transformed Bayesian statistics and many scientific fields that rely on computational modeling.</p>
<h1 id="1-problem-statement-inferring-models-from-real-world-data">1. Problem Statement: Inferring Models from Real-World Data<a class="headerlink" href="#1-problem-statement-inferring-models-from-real-world-data" title="Permanent link">&para;</a></h1>
<p>A core task in science is to build and validate mathematical models from observations. A good model not only explains existing data but also predicts the future. The predictive power of a model depends entirely on its parameters. How do we determine unknown parameters from experimental or observational data?</p>
<h2 id="11-a-classic-ecosystem-lynx-and-hare">1.1 A Classic Ecosystem: Lynx and Hare<a class="headerlink" href="#11-a-classic-ecosystem-lynx-and-hare" title="Permanent link">&para;</a></h2>
<p>To make it concrete, consider a classic ecological example: the predator-prey dynamics of Canadian lynx (predator) and snowshoe hare (prey). The Hudson's Bay Company recorded pelts from 1900 to 1920; these counts are regarded as reliable proxies for population sizes.</p>
<p><img alt="Lecture slide" src="../../assets/images/remote/d8a6f6e7-4ac0-4fd3-8c00-720a1ca45ea7-a946bb2c01.jpg" /></p>
<p><img alt="Lecture slide" src="../../assets/images/remote/bbd18f78-ebf7-462a-923a-e58b7d4eda23-ea96baa5f4.jpg" /></p>
<p>Plotting the data reveals periodic oscillations in both species, with the predator peak lagging behind the prey peak.</p>
<p><img alt="Lecture slide" src="../../assets/images/remote/510942e3-5a73-482e-8509-9ffe66e18509-55827117d3.png" /></p>
<p>A natural question is: can we find a mathematical model that explains and predicts this periodic behavior? More specifically, can we infer the "laws" (parameters) that govern the dynamics from the data?</p>
<h2 id="12-lotka-volterra-model-a-mathematical-description">1.2 Lotka-Volterra Model: A Mathematical Description<a class="headerlink" href="#12-lotka-volterra-model-a-mathematical-description" title="Permanent link">&para;</a></h2>
<p>A famous model for predator-prey systems is the Lotka-Volterra equations, a pair of coupled ODEs describing changes in two populations. Let <span class="arithmatex">\(x\)</span> be the hare (prey) population and <span class="arithmatex">\(y\)</span> the lynx (predator) population:</p>
<div class="arithmatex">\[
\frac{dx}{dt} = \alpha x - \beta xy \quad \text{(hares)}
\]</div>
<div class="arithmatex">\[
\frac{dy}{dt} = -\gamma y + \delta xy \quad \text{(lynx)}
\]</div>
<p>Interpretation of each term:</p>
<ul>
<li><span class="arithmatex">\(\alpha x\)</span>: natural exponential growth of hares in the absence of predators (<span class="arithmatex">\(y=0\)</span>); <span class="arithmatex">\(\alpha\)</span> is the hare birth rate.</li>
<li><span class="arithmatex">\(-\beta xy\)</span>: loss of hares due to predation; encounter frequency <span class="arithmatex">\(\propto xy\)</span>; <span class="arithmatex">\(\beta\)</span> is predation efficiency.</li>
<li><span class="arithmatex">\(-\gamma y\)</span>: natural death of lynx in the absence of food (<span class="arithmatex">\(x=0\)</span>); <span class="arithmatex">\(\gamma\)</span> is the lynx death rate.</li>
<li><span class="arithmatex">\(+\delta xy\)</span>: lynx reproduction thanks to predation; proportional to <span class="arithmatex">\(xy\)</span>; <span class="arithmatex">\(\delta\)</span> is the conversion efficiency from prey to predator growth.</li>
</ul>
<p>The "laws" are encoded in <span class="arithmatex">\(\theta=\{\alpha,\beta,\gamma,\delta\}\)</span>. Given observations <span class="arithmatex">\(D\)</span> (the time series), parameter inference asks for the most plausible <span class="arithmatex">\(\theta\)</span>.</p>
<h1 id="2-bayesian-framework-a-systematic-approach">2. Bayesian Framework: A Systematic Approach<a class="headerlink" href="#2-bayesian-framework-a-systematic-approach" title="Permanent link">&para;</a></h1>
<p>How can we systematically learn parameters <span class="arithmatex">\(\theta\)</span> from data <span class="arithmatex">\(D\)</span>? Bayesian inference provides a probability-based, logically coherent framework: it is fundamentally a rule for updating degrees of belief in light of new evidence.</p>
<h2 id="21-introducing-bayes-theorem">2.1 Introducing Bayes' Theorem<a class="headerlink" href="#21-introducing-bayes-theorem" title="Permanent link">&para;</a></h2>
<p>Bayesian inference formalizes learning from data via</p>
<div class="arithmatex">\[
\underbrace{p(\theta\mid D)}_{\text{posterior}} = \frac{\underbrace{p(D\mid\theta)}_{\text{likelihood}}\, \underbrace{p(\theta)}_{\text{prior}}}{\underbrace{p(D)}_{\text{evidence}}}.
\]</div>
<h2 id="22-decomposing-bayes-theorem">2.2 Decomposing Bayes' Theorem<a class="headerlink" href="#22-decomposing-bayes-theorem" title="Permanent link">&para;</a></h2>
<ul>
<li>Prior <span class="arithmatex">\(p(\theta)\)</span>: knowledge/belief before seeing data.</li>
<li>Likelihood <span class="arithmatex">\(p(D\mid\theta)\)</span>: plausibility of data under parameters.</li>
<li>Evidence <span class="arithmatex">\(p(D)\)</span>: normalization; often intractable.</li>
<li>Posterior <span class="arithmatex">\(p(\theta\mid D)\)</span>: what we want to characterize/sample.</li>
</ul>
<p>Bayesian thinking differs from traditional "best-fit" approaches (e.g., least squares). Classical methods may return a single best parameter set. In contrast, Bayesian methods say: there is no single "correct" <span class="arithmatex">\(\theta\)</span> - instead there is a landscape of plausibilities over parameter space. One region may be very plausible while another is unlikely.</p>
<p>This probabilistic perspective is powerful. It lets us ask deeper questions such as: "What is the probability that the hare birth rate <span class="arithmatex">\(\alpha\)</span> lies between 0.5 and 0.6?" or "Are the predation rate <span class="arithmatex">\(\beta\)</span> and the lynx death rate <span class="arithmatex">\(\gamma\)</span> correlated?" This represents a shift from deterministic to probabilistic thinking that honestly reflects our uncertainty given finite data.</p>
<h1 id="3-computational-bottleneck-high-dimensional-integrals">3. Computational Bottleneck: High-Dimensional Integrals<a class="headerlink" href="#3-computational-bottleneck-high-dimensional-integrals" title="Permanent link">&para;</a></h1>
<p>Having a posterior <span class="arithmatex">\(p(\theta\mid D)\)</span> solves inference in principle, but in practice we often need summaries such as expectations and variances.</p>
<h2 id="31-from-distributions-to-expectations">3.1 From Distributions to Expectations<a class="headerlink" href="#31-from-distributions-to-expectations" title="Permanent link">&para;</a></h2>
<p>Model comparison, prediction, and uncertainty quantification are often expectations under the posterior. For a function <span class="arithmatex">\(f(\theta)\)</span> (e.g., <span class="arithmatex">\(f(\theta)=\alpha\)</span> to compute the mean of <span class="arithmatex">\(\alpha\)</span>), we need to evaluate</p>
<div class="arithmatex">\[
\langle f(\theta) \rangle = \int f(\theta)\, p(\theta\mid D)\, d\theta^n,
\]</div>
<p>an integral over the full <span class="arithmatex">\(n\)</span>-dimensional parameter space (here <span class="arithmatex">\(n=4\)</span>). We also encounter the evidence (normalization) itself,</p>
<div class="arithmatex">\[
p(D) = \int p(D\mid\theta)\, p(\theta)\, d\theta,
\]</div>
<p>which is frequently the hardest quantity in Bayesian inference.</p>
<h2 id="32-the-curse-of-dimensionality">3.2 The Curse of Dimensionality<a class="headerlink" href="#32-the-curse-of-dimensionality" title="Permanent link">&para;</a></h2>
<p>Why are these integrals so hard? Direct gridding explodes with dimension. Suppose we take 10 grid points per parameter:</p>
<ul>
<li>1D: <span class="arithmatex">\(10^1=10\)</span> evaluations.</li>
<li>2D: <span class="arithmatex">\(10^2=100\)</span> evaluations.</li>
<li>4D (our Lotka-Volterra case): <span class="arithmatex">\(10^4=10{,}000\)</span> evaluations.</li>
<li>20D: <span class="arithmatex">\(10^{20}\)</span> evaluations - utterly infeasible.</li>
</ul>
<p>Worse, high-dimensional geometry defeats low-dimensional intuition: the posterior mass typically concentrates in a tiny, irregular region, while most of the space has near-zero density.</p>
<p><img alt="Lecture board" src="../../assets/images/remote/3d4c0c96-092b-4d24-838f-fca8fa077a21-25de69215c.png" /></p>
<p>Uniform grids are blind; they waste almost all effort evaluating points where <span class="arithmatex">\(p(\theta\mid D)\approx 0\)</span>. The "curse of dimensionality" is not just slowness, but a fundamental scaling barrier. The problem is search efficiency: in an exponentially large space, we must find a small, unknown "important" region. We need a different strategy that focuses effort where it matters.</p>
<h1 id="4-a-new-strategy-monte-carlo-integration">4. A New Strategy: Monte Carlo Integration<a class="headerlink" href="#4-a-new-strategy-monte-carlo-integration" title="Permanent link">&para;</a></h1>
<p>Facing high-dimensional integrals, we turn to a smarter approach: Monte Carlo integration replaces deterministic grids with random sampling.</p>
<h2 id="41-power-of-the-law-of-large-numbers">4.1 Power of the Law of Large Numbers<a class="headerlink" href="#41-power-of-the-law-of-large-numbers" title="Permanent link">&para;</a></h2>
<p>Monte Carlo integration uses the law of large numbers to approximate integrals by sample averages:</p>
<div class="arithmatex">\[
\langle f(\theta) \rangle = \int f(\theta)\, p(\theta\mid D)\, d\theta \;\approx\; \frac{1}{N} \sum_{i=1}^{N} f\big(\theta^{(i)}\big).
\]</div>
<p>The "magic" lies in how we generate the samples <span class="arithmatex">\(\{\theta^{(i)}\}\)</span>.</p>
<h2 id="42-importance-sampling-the-key-insight">4.2 Importance Sampling: The Key Insight<a class="headerlink" href="#42-importance-sampling-the-key-insight" title="Permanent link">&para;</a></h2>
<p>To make the approximation accurate and efficient, the samples should be drawn from the target itself, <span class="arithmatex">\(p(\theta\mid D)\)</span>. This is the essence of importance sampling: by drawing from the target, computation automatically focuses on high-probability regions - the very regions that dominate the integral - rather than wasting effort in probability "deserts".</p>
<p>This reframes the problem: instead of integrating, we "just" need to sample from a complex, high-dimensional, and even unnormalized distribution <span class="arithmatex">\(p(\theta\mid D)\)</span> (since <span class="arithmatex">\(p(D)\)</span> is unknown). Embracing randomness becomes the way to overcome the curse of dimensionality. What we need is not an integrator, but a sampler.</p>
<h1 id="5-generating-samples-via-stochastic-processes-mcmc">5. Generating Samples via Stochastic Processes: MCMC<a class="headerlink" href="#5-generating-samples-via-stochastic-processes-mcmc" title="Permanent link">&para;</a></h1>
<p>How do we build a machine that samples from an arbitrary <span class="arithmatex">\(p(\theta\mid D)\)</span>? The answer returns to Markov chains.</p>
<h2 id="51-toolbox-recap-markov-chains-and-stationary-distributions">5.1 Toolbox Recap: Markov Chains and Stationary Distributions<a class="headerlink" href="#51-toolbox-recap-markov-chains-and-stationary-distributions" title="Permanent link">&para;</a></h2>
<p>Recall key ideas (Lectures 6-8):</p>
<ul>
<li>Markov chain: a memoryless stochastic process; the future depends only on the present.</li>
<li>Stationary distribution <span class="arithmatex">\(\pi\)</span>: under conditions such as ergodicity, the chain converges to a limiting distribution <span class="arithmatex">\(\pi\)</span>.</li>
<li>Perron-Frobenius theorem: provides existence/uniqueness guarantees for broad classes.</li>
<li>Detailed balance (sufficient condition): <span class="arithmatex">\(\pi(\theta)\, W(\theta'\mid\theta) = \pi(\theta')\, W(\theta\mid\theta')\)</span>, where <span class="arithmatex">\(W\)</span> is the transition rule.</li>
</ul>
<h2 id="52-core-idea-of-mcmc">5.2 Core Idea of MCMC<a class="headerlink" href="#52-core-idea-of-mcmc" title="Permanent link">&para;</a></h2>
<p>Design a Markov chain whose unique stationary distribution equals the target posterior <span class="arithmatex">\(\pi(\theta)=p(\theta\mid D)\)</span>. Then:</p>
<p>1) Pick any initial point <span class="arithmatex">\(\theta^{(0)}\)</span>.
2) Evolve the chain according to its transition rule.
3) Run long enough to "forget" the initial condition (burn-in).
4) Record the subsequent states <span class="arithmatex">\(\{\theta^{(i)}\}\)</span>.</p>
<p>By the definition of stationarity, <span class="arithmatex">\(\{\theta^{(i)}\}\)</span> are samples from <span class="arithmatex">\(p(\theta\mid D)\)</span>. This inverts the usual direction of analysis: earlier we learned "given <span class="arithmatex">\(W\)</span>, find <span class="arithmatex">\(\pi\)</span>"; now we ask "given desired <span class="arithmatex">\(\pi\)</span>, construct <span class="arithmatex">\(W\)</span>" - and detailed balance provides the blueprint.</p>
<h1 id="6-metropolis-hastings-algorithm-a-practical-recipe">6. Metropolis-Hastings Algorithm: A Practical Recipe<a class="headerlink" href="#6-metropolis-hastings-algorithm-a-practical-recipe" title="Permanent link">&para;</a></h1>
<p>How do we construct a suitable <span class="arithmatex">\(W\)</span> in practice? The Metropolis-Hastings (MH) algorithm provides a general and powerful recipe for building a Markov chain with any target distribution.</p>
<p>Historically, Metropolis et al. (1953) introduced the symmetric-proposal version to tackle high-dimensional problems in physics; Hastings (1970) generalized it to asymmetric proposals. Today MH is central across Bayesian computation and many other fields.</p>
<h2 id="61-algorithm-metropolis-hastings-mh">6.1 Algorithm: Metropolis-Hastings (MH)<a class="headerlink" href="#61-algorithm-metropolis-hastings-mh" title="Permanent link">&para;</a></h2>
<p>The Metropolis-Hastings algorithm is one of the most important algorithms in modern computational statistics and physics, with its development spanning two key innovations in the mid-20th century. The original version of this algorithm was proposed by Nicholas Metropolis and his collaborators (including Arianna Rosenbluth, Marshall Rosenbluth, Augusta Teller, and Edward Teller) in 1953, primarily to solve state equation calculations for high-dimensional systems in physics. The core idea was to construct a Markov chain whose final stationary distribution would be our desired target distribution for sampling, with the original version limited to symmetric proposal distributions. Subsequently, in 1970, statistician W. K. Hastings generalized the algorithm to asymmetric proposal distributions, greatly expanding its scope of application and forming what we now know as the Metropolis-Hastings algorithm.</p>
<p>The algorithm has extremely wide applications, playing a central role especially in Bayesian statistics. When a model's posterior probability distribution is complex in form and high-dimensional, making direct analytical computation or sampling impossible, the Metropolis-Hastings algorithm provides a powerful numerical simulation tool. Specific applications include but are not limited to: Bayesian inference in machine learning for estimating parameters of complex models; phylogenetic tree construction in computational biology; simulating multi-particle system behavior in physics; risk modeling and option pricing in finance. It can be said that any scientific and engineering field that requires sampling from probability distributions that are difficult to handle directly can see the presence of the Metropolis-Hastings algorithm.</p>
<p>Steps:</p>
<p>1) Initialize with any <span class="arithmatex">\(\theta^{(0)}\)</span>.
2) For <span class="arithmatex">\(i=1,2,\dots,N\)</span>:
- Propose <span class="arithmatex">\(\theta' \sim q(\theta'\mid \theta^{(i-1)})\)</span> (e.g., Gaussian random walk).
- Compute acceptance probability
  $$
  A(\theta'\mid\theta) = \min\Bigl(1, \frac{p(\theta')\, q(\theta\mid\theta')}{p(\theta)\, q(\theta'\mid\theta)}\Bigr),
  $$
  where <span class="arithmatex">\(p(\theta)\)</span> denotes the (unnormalized) target <span class="arithmatex">\(p(\theta\mid D)\)</span>.
- Draw <span class="arithmatex">\(u\sim\mathrm{Unif}(0,1)\)</span>. If <span class="arithmatex">\(u&lt;A\)</span>, accept (<span class="arithmatex">\(\theta^{(i)}=\theta'\)</span>); else reject (<span class="arithmatex">\(\theta^{(i)}=\theta^{(i-1)}\)</span>).</p>
<h2 id="62-why-it-works-enforcing-detailed-balance">6.2 Why It Works: Enforcing Detailed Balance<a class="headerlink" href="#62-why-it-works-enforcing-detailed-balance" title="Permanent link">&para;</a></h2>
<p>The MH acceptance rule ensures detailed balance and thus the target stationary distribution. Two key ratios appear in <span class="arithmatex">\(A(\theta'\mid\theta)\)</span>:</p>
<ul>
<li>Target ratio <span class="arithmatex">\(\dfrac{p(\theta')}{p(\theta)}\)</span>: if the proposal moves to a higher-probability region, this ratio exceeds 1 and the move is always accepted; if lower, the move is accepted with some probability, enabling exploration beyond just the peaks.</li>
<li>Proposal correction <span class="arithmatex">\(\dfrac{q(\theta\mid\theta')}{q(\theta'\mid\theta)}\)</span>: compensates for any asymmetry or bias in proposals. With a symmetric proposal (e.g., Gaussian random walk), this factor is 1 and we recover the original Metropolis rule <span class="arithmatex">\(A=\min\bigl(1, p(\theta')/p(\theta)\bigr)\)</span>.</li>
</ul>
<p>Crucially, the evidence <span class="arithmatex">\(p(D)\)</span> cancels in ratios:</p>
<div class="arithmatex">\[
\frac{p(\theta\mid D)}{p(\theta'\mid D)} = \frac{p(D\mid\theta)\,p(\theta)}{p(D\mid\theta')\,p(\theta')}.
\]</div>
<p>Hence we only need likelihood and prior up to constants. This neatly sidesteps the hardest normalization in Bayesian inference while retaining correctness via detailed balance.</p>
<h1 id="7-using-mcmc-for-lotka-volterra-parameter-inference">7. Using MCMC for Lotka-Volterra Parameter Inference<a class="headerlink" href="#7-using-mcmc-for-lotka-volterra-parameter-inference" title="Permanent link">&para;</a></h1>
<p>We now apply MH to infer <span class="arithmatex">\((\alpha,\beta,\gamma,\delta)\)</span> from the Hudson's Bay data. The ODE model lacks a simple closed-form solution; for each parameter set we integrate numerically, making the posterior highly nontrivial - an ideal use case for MCMC. This case illustrates an end-to-end workflow: start from data, posit a mechanistic model, define a Bayesian posterior, and sample it via a carefully designed stochastic process.</p>
<h2 id="71-modeling-plan">7.1 Modeling Plan<a class="headerlink" href="#71-modeling-plan" title="Permanent link">&para;</a></h2>
<p>1) <strong>Model</strong>: Lotka-Volterra differential equation system.
2) <strong>Data</strong>: 1900-1920 hare (H) and lynx (L) population counts.
3) <strong>Target</strong>: Solve the posterior probability distribution <span class="arithmatex">\(p(\alpha, \beta, \gamma, \delta \mid \text{data})\)</span>.
4) <strong>Method</strong>: Construct a Metropolis-Hastings sampler.
    * <strong>State space</strong>: Four-dimensional parameter space <span class="arithmatex">\((\alpha, \beta, \gamma, \delta)\)</span>.
    * <strong>Target distribution</strong>: Posterior probability <span class="arithmatex">\(p(\theta\mid D) \propto p(D\mid\theta)p(\theta)\)</span>.
        * <strong>Likelihood function <span class="arithmatex">\(p(D\mid\theta)\)</span></strong>: We assume that the errors between observed data and model predictions follow a log-normal distribution. This means we calculate the population numbers predicted by the model under given parameters <span class="arithmatex">\(\theta\)</span> and compare them with real data to compute their probability.
        * <strong>Prior distribution <span class="arithmatex">\(p(\theta)\)</span></strong>: Since we have little prior knowledge about the parameters, we choose a non-informative, broad uniform or normal distribution as the prior.
    * <strong>Proposal distribution <span class="arithmatex">\(q(\theta'\mid\theta)\)</span></strong>: We adopt a simple random walk strategy. Near the current parameter point <span class="arithmatex">\(\theta\)</span>, we generate a new proposal point <span class="arithmatex">\(\theta'\)</span> by adding a small random perturbation (e.g., sampling from a multivariate normal distribution).</p>
<h2 id="72-python-implementation">7.2 Python Implementation<a class="headerlink" href="#72-python-implementation" title="Permanent link">&para;</a></h2>
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">scipy.integrate</span><span class="w"> </span><span class="kn">import</span> <span class="n">odeint</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">scipy.stats</span><span class="w"> </span><span class="kn">import</span> <span class="n">norm</span>

<span class="c1"># 1. Load data</span>
<span class="c1"># Data source: https://github.com/stan-dev/example-models</span>
<span class="c1"># Year, Lynx (x1000), Hare (x1000)</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span>
    <span class="p">[</span><span class="mi">1900</span><span class="p">,</span> <span class="mf">4.0</span><span class="p">,</span> <span class="mf">30.0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1901</span><span class="p">,</span> <span class="mf">6.1</span><span class="p">,</span> <span class="mf">47.2</span><span class="p">],</span> <span class="p">[</span><span class="mi">1902</span><span class="p">,</span> <span class="mf">9.8</span><span class="p">,</span> <span class="mf">70.2</span><span class="p">],</span>
    <span class="p">[</span><span class="mi">1903</span><span class="p">,</span> <span class="mf">35.2</span><span class="p">,</span> <span class="mf">77.4</span><span class="p">],</span> <span class="p">[</span><span class="mi">1904</span><span class="p">,</span> <span class="mf">59.4</span><span class="p">,</span> <span class="mf">36.3</span><span class="p">],</span> <span class="p">[</span><span class="mi">1905</span><span class="p">,</span> <span class="mf">41.7</span><span class="p">,</span> <span class="mf">20.6</span><span class="p">],</span>
    <span class="p">[</span><span class="mi">1906</span><span class="p">,</span> <span class="mf">19.0</span><span class="p">,</span> <span class="mf">18.1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1907</span><span class="p">,</span> <span class="mf">13.0</span><span class="p">,</span> <span class="mf">21.4</span><span class="p">],</span> <span class="p">[</span><span class="mi">1908</span><span class="p">,</span> <span class="mf">8.3</span><span class="p">,</span> <span class="mf">22.0</span><span class="p">],</span>
    <span class="p">[</span><span class="mi">1909</span><span class="p">,</span> <span class="mf">9.1</span><span class="p">,</span> <span class="mf">25.4</span><span class="p">],</span> <span class="p">[</span><span class="mi">1910</span><span class="p">,</span> <span class="mf">7.4</span><span class="p">,</span> <span class="mf">27.1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1911</span><span class="p">,</span> <span class="mf">8.0</span><span class="p">,</span> <span class="mf">40.3</span><span class="p">],</span>
    <span class="p">[</span><span class="mi">1912</span><span class="p">,</span> <span class="mf">12.3</span><span class="p">,</span> <span class="mf">57.0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1913</span><span class="p">,</span> <span class="mf">19.5</span><span class="p">,</span> <span class="mf">76.6</span><span class="p">],</span> <span class="p">[</span><span class="mi">1914</span><span class="p">,</span> <span class="mf">45.7</span><span class="p">,</span> <span class="mf">52.3</span><span class="p">],</span>
    <span class="p">[</span><span class="mi">1915</span><span class="p">,</span> <span class="mf">51.1</span><span class="p">,</span> <span class="mf">19.5</span><span class="p">],</span> <span class="p">[</span><span class="mi">1916</span><span class="p">,</span> <span class="mf">29.7</span><span class="p">,</span> <span class="mf">11.2</span><span class="p">],</span> <span class="p">[</span><span class="mi">1917</span><span class="p">,</span> <span class="mf">15.8</span><span class="p">,</span> <span class="mf">7.6</span><span class="p">],</span>
    <span class="p">[</span><span class="mi">1918</span><span class="p">,</span> <span class="mf">9.7</span><span class="p">,</span> <span class="mf">14.6</span><span class="p">],</span> <span class="p">[</span><span class="mi">1919</span><span class="p">,</span> <span class="mf">10.1</span><span class="p">,</span> <span class="mf">16.2</span><span class="p">],</span> <span class="p">[</span><span class="mi">1920</span><span class="p">,</span> <span class="mf">8.6</span><span class="p">,</span> <span class="mf">24.7</span><span class="p">]</span>
<span class="p">])</span>
<span class="n">years</span> <span class="o">=</span> <span class="n">data</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span>
<span class="n">lynx_data</span> <span class="o">=</span> <span class="n">data</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span>
<span class="n">hare_data</span> <span class="o">=</span> <span class="n">data</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">]</span>
<span class="n">y_obs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">((</span><span class="n">hare_data</span><span class="p">,</span> <span class="n">lynx_data</span><span class="p">))</span><span class="o">.</span><span class="n">T</span> <span class="c1"># Observed data [H, L]</span>

<span class="c1"># 2. Define Lotka-Volterra model</span>
<span class="k">def</span><span class="w"> </span><span class="nf">lotka_volterra</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">gamma</span><span class="p">,</span> <span class="n">delta</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Lotka-Volterra differential equations</span>
<span class="sd">    y: [H, L] population array</span>
<span class="sd">    t: time</span>
<span class="sd">    alpha, beta, gamma, delta: model parameters</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">H</span><span class="p">,</span> <span class="n">L</span> <span class="o">=</span> <span class="n">y</span>
    <span class="n">dH_dt</span> <span class="o">=</span> <span class="n">alpha</span> <span class="o">*</span> <span class="n">H</span> <span class="o">-</span> <span class="n">beta</span> <span class="o">*</span> <span class="n">H</span> <span class="o">*</span> <span class="n">L</span>
    <span class="n">dL_dt</span> <span class="o">=</span> <span class="n">delta</span> <span class="o">*</span> <span class="n">H</span> <span class="o">*</span> <span class="n">L</span> <span class="o">-</span> <span class="n">gamma</span> <span class="o">*</span> <span class="n">L</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">dH_dt</span><span class="p">,</span> <span class="n">dL_dt</span><span class="p">]</span>

<span class="c1"># 3. Define log posterior probability function</span>
<span class="k">def</span><span class="w"> </span><span class="nf">log_posterior</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">y_obs</span><span class="p">,</span> <span class="n">t_obs</span><span class="p">):</span>
    <span class="n">alpha</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">gamma</span><span class="p">,</span> <span class="n">delta</span> <span class="o">=</span> <span class="n">theta</span>

    <span class="c1"># a. Log-Prior</span>
    <span class="c1"># Assume parameters follow wide normal distributions, and must be positive</span>
    <span class="k">if</span> <span class="nb">any</span><span class="p">(</span><span class="n">p</span> <span class="o">&lt;=</span> <span class="mi">0</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">theta</span><span class="p">):</span>
        <span class="k">return</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span>
    <span class="n">log_prior_alpha</span> <span class="o">=</span> <span class="n">norm</span><span class="o">.</span><span class="n">logpdf</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">log_prior_beta</span> <span class="o">=</span> <span class="n">norm</span><span class="o">.</span><span class="n">logpdf</span><span class="p">(</span><span class="n">beta</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mf">0.05</span><span class="p">)</span>
    <span class="n">log_prior_gamma</span> <span class="o">=</span> <span class="n">norm</span><span class="o">.</span><span class="n">logpdf</span><span class="p">(</span><span class="n">gamma</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">log_prior_delta</span> <span class="o">=</span> <span class="n">norm</span><span class="o">.</span><span class="n">logpdf</span><span class="p">(</span><span class="n">delta</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="mf">0.02</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mf">0.02</span><span class="p">)</span>
    <span class="n">log_p</span> <span class="o">=</span> <span class="n">log_prior_alpha</span> <span class="o">+</span> <span class="n">log_prior_beta</span> <span class="o">+</span> <span class="n">log_prior_gamma</span> <span class="o">+</span> <span class="n">log_prior_delta</span>

    <span class="c1"># b. Log-Likelihood</span>
    <span class="c1"># Initial conditions use the first point of data</span>
    <span class="n">y0</span> <span class="o">=</span> <span class="n">y_obs</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:]</span>
    <span class="c1"># Numerically solve differential equations using odeint</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">odeint</span><span class="p">(</span><span class="n">lotka_volterra</span><span class="p">,</span> <span class="n">y0</span><span class="p">,</span> <span class="n">t_obs</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">gamma</span><span class="p">,</span> <span class="n">delta</span><span class="p">))</span>

    <span class="c1"># Assume errors follow a log-normal distribution, equivalent to log-transformed data following a normal distribution</span>
    <span class="c1"># We also need to estimate a standard deviation sigma for the error</span>
    <span class="c1"># For simplicity, we fix a reasonable sigma value here</span>
    <span class="n">sigma</span> <span class="o">=</span> <span class="mf">0.5</span> 
    <span class="n">log_likelihood</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">norm</span><span class="o">.</span><span class="n">logpdf</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">y_obs</span><span class="p">),</span> <span class="n">loc</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">y_pred</span><span class="p">),</span> <span class="n">scale</span><span class="o">=</span><span class="n">sigma</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">log_p</span> <span class="o">+</span> <span class="n">log_likelihood</span>

<span class="c1"># 4. Implement Metropolis-Hastings MCMC</span>
<span class="k">def</span><span class="w"> </span><span class="nf">metropolis_hastings</span><span class="p">(</span><span class="n">log_posterior_func</span><span class="p">,</span> <span class="n">n_iter</span><span class="p">,</span> <span class="n">initial_theta</span><span class="p">,</span> <span class="n">proposal_std</span><span class="p">,</span> <span class="n">y_obs</span><span class="p">,</span> <span class="n">t_obs</span><span class="p">):</span>
    <span class="c1"># Initialization</span>
    <span class="n">n_params</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">initial_theta</span><span class="p">)</span>
    <span class="n">chain</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n_iter</span><span class="p">,</span> <span class="n">n_params</span><span class="p">))</span>
    <span class="n">chain</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">initial_theta</span>

    <span class="n">current_log_post</span> <span class="o">=</span> <span class="n">log_posterior_func</span><span class="p">(</span><span class="n">initial_theta</span><span class="p">,</span> <span class="n">y_obs</span><span class="p">,</span> <span class="n">t_obs</span><span class="p">)</span>

    <span class="n">accepted_count</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_iter</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">i</span> <span class="o">%</span> <span class="mi">1000</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Iteration </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">n_iter</span><span class="si">}</span><span class="s2">...&quot;</span><span class="p">)</span>

        <span class="c1"># a. Propose new point</span>
        <span class="n">proposal_theta</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="n">chain</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:],</span> <span class="n">scale</span><span class="o">=</span><span class="n">proposal_std</span><span class="p">)</span>

        <span class="c1"># b. Calculate acceptance probability</span>
        <span class="n">proposal_log_post</span> <span class="o">=</span> <span class="n">log_posterior_func</span><span class="p">(</span><span class="n">proposal_theta</span><span class="p">,</span> <span class="n">y_obs</span><span class="p">,</span> <span class="n">t_obs</span><span class="p">)</span>

        <span class="n">log_alpha</span> <span class="o">=</span> <span class="n">proposal_log_post</span> <span class="o">-</span> <span class="n">current_log_post</span>

        <span class="c1"># c. Accept or reject</span>
        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">())</span> <span class="o">&lt;</span> <span class="n">log_alpha</span><span class="p">:</span>
            <span class="n">chain</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">proposal_theta</span>
            <span class="n">current_log_post</span> <span class="o">=</span> <span class="n">proposal_log_post</span>
            <span class="n">accepted_count</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">chain</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">chain</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Acceptance rate: </span><span class="si">{</span><span class="n">accepted_count</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">n_iter</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">chain</span>

<span class="c1"># 5. Run MCMC</span>
<span class="n">n_iterations</span> <span class="o">=</span> <span class="mi">50000</span>
<span class="n">burn_in</span> <span class="o">=</span> <span class="mi">10000</span> <span class="c1"># Discard early unstable samples</span>
<span class="n">initial_params</span> <span class="o">=</span> <span class="p">[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.02</span><span class="p">]</span> <span class="c1"># Initial guess</span>
<span class="n">proposal_widths</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.001</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.001</span><span class="p">]</span> <span class="c1"># Proposal distribution standard deviation, needs tuning</span>
<span class="n">t_span</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">years</span><span class="p">))</span> <span class="c1"># Time points (0, 1, 2, ...)</span>

<span class="n">chain</span> <span class="o">=</span> <span class="n">metropolis_hastings</span><span class="p">(</span><span class="n">log_posterior</span><span class="p">,</span> <span class="n">n_iterations</span><span class="p">,</span> <span class="n">initial_params</span><span class="p">,</span> <span class="n">proposal_widths</span><span class="p">,</span> <span class="n">y_obs</span><span class="p">,</span> <span class="n">t_span</span><span class="p">)</span>

<span class="c1"># Discard burn-in and thin if desired</span>
<span class="n">posterior_samples</span> <span class="o">=</span> <span class="n">chain</span><span class="p">[</span><span class="n">burn_in</span><span class="p">:,</span> <span class="p">:]</span>

<span class="c1"># 6. Diagnostics and visualization</span>
<span class="n">param_names</span> <span class="o">=</span> <span class="p">[</span><span class="sa">r</span><span class="s2">&quot;alpha (hares)&quot;</span><span class="p">,</span> <span class="sa">r</span><span class="s2">&quot;beta (predation)&quot;</span><span class="p">,</span> <span class="sa">r</span><span class="s2">&quot;gamma (lynx)&quot;</span><span class="p">,</span> <span class="sa">r</span><span class="s2">&quot;delta (conversion)&quot;</span><span class="p">]</span>

<span class="c1"># a. Trace plots</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">4</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">posterior_samples</span><span class="p">[:,</span> <span class="n">i</span><span class="p">])</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Trace of </span><span class="si">{</span><span class="n">param_names</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Iteration&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Parameter Value&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># b. Plot posterior distributions</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">4</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">posterior_samples</span><span class="p">[:,</span> <span class="n">i</span><span class="p">],</span> <span class="n">bins</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">density</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Posterior of </span><span class="si">{</span><span class="n">param_names</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Parameter Value&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Density&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># c. Plot model predictions vs. real data</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="c1"># Randomly sample some parameter combinations from the posterior distribution for simulation</span>
<span class="n">n_samples_plot</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">sample_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">posterior_samples</span><span class="p">),</span> <span class="n">n_samples_plot</span><span class="p">)</span>

<span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">sample_indices</span><span class="p">:</span>
    <span class="n">params</span> <span class="o">=</span> <span class="n">posterior_samples</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="p">:]</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">odeint</span><span class="p">(</span><span class="n">lotka_volterra</span><span class="p">,</span> <span class="n">y_obs</span><span class="p">[</span><span class="mi">0</span><span class="p">,:],</span> <span class="n">t_span</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="nb">tuple</span><span class="p">(</span><span class="n">params</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">years</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;skyblue&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span> <span class="c1"># Predicted hares</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">years</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;lightcoral&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span> <span class="c1"># Predicted lynx</span>

<span class="c1"># Plot original data points</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">years</span><span class="p">,</span> <span class="n">hare_data</span><span class="p">,</span> <span class="s1">&#39;o-&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;blue&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Observed Hares&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">years</span><span class="p">,</span> <span class="n">lynx_data</span><span class="p">,</span> <span class="s1">&#39;o-&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Observed Lynx&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Year&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Population (x1000)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Lotka-Volterra Model Fit to Hudson Bay Data&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div>
<p><img alt="Run output" src="../../assets/images/remote/92bf7793-2723-4dd5-b016-7005ec48e792-28a1133f5b.png" /></p>
<p><strong>Trace plots</strong>: These plots show how the sampled values for each parameter change during the MCMC iteration process. Ideally, we want to see these trajectories fluctuating randomly around a stable value like a "caterpillar," with no obvious upward or downward trends. This indicates that the Markov chain has "forgotten" its initial position and has begun exploring the typical region of the target posterior distribution. If the trace plots show obvious trends, it usually means the "burn-in" phase is not long enough, or the proposal distribution is inappropriate, resulting in low mixing efficiency of the chain.</p>
<p><img alt="Run output" src="../../assets/images/remote/763ed380-ac8b-4e8c-a26c-a71f1bddf16d-1203017672.png" /></p>
<p><strong>Posterior distributions</strong>: These are the core results of our Bayesian inference. These histograms approximately depict our understanding of uncertainty for each parameter after being given the data. The peaks of the distributions represent the most likely values of the parameters (i.e., maximum a posteriori estimates), while the width of the distributions quantifies our uncertainty about these values. For example, a tall and narrow distribution means the data very strongly constrains that parameter to a small range; while a short and wide distribution indicates that the data provides limited information, and we remain quite uncertain about the true value of that parameter.</p>
<p><img alt="Run output" src="../../assets/images/remote/75e9b1b2-4ff7-4b3f-aa6c-7a7c1988bb4d-43bd03f19f.png" /></p>
<p><strong>Model predictions vs. data comparison</strong>: This plot provides an intuitive comparison between our inference results and real-world data. The thin translucent lines in the figure represent model evolution trajectories generated from 100 different parameter sets randomly sampled from the posterior distribution. These curves form a "credible band" showing the prediction range of the model after considering parameter uncertainty. We can see that the real data points (blue and red dots) mostly fall within this credible band, indicating that our Lotka-Volterra model with inferred parameters can well capture and reproduce the historical periodic fluctuations of lynx and hare populations. This provides strong visual evidence for the validity of the model.</p>
<p>Through this case study, we have completed the entire workflow of using advanced sampling methods to solve real scientific problems: <strong>starting from a real-world dataset, building a mathematical model, using the Bayesian inference framework to define the target (posterior distribution), and finally successfully sampling from this complex target distribution by constructing a clever stochastic process (MCMC), completing the quantitative learning of model parameters. This is exactly the embodiment of the powerful force of Monte Carlo methods as stochastic processes in modern scientific research.</strong></p>
<h1 id="conclusion">Conclusion<a class="headerlink" href="#conclusion" title="Permanent link">&para;</a></h1>
<p>This lecture turns stochastic-process theory from a purely analytical tool into a practical computational engine. Starting from a real scientific problem - inferring model parameters from data - we saw how the Bayesian framework defines the target posterior, but direct computation is blocked by the curse of dimensionality.</p>
<p>MCMC, especially Metropolis-Hastings, provides an elegant way out: by reframing sampling as the steady state of a constructed Markov chain and enforcing detailed balance, we both avoid the evidence and gain an efficient exploration strategy for complex high-dimensional spaces.</p>
<p>This bridges the theoretical first half of the course with applied methods, showing how deep theory becomes an immediately useful tool. MCMC and its variants are cornerstones of modern computational statistics, machine learning, and many quantitative sciences; mastering their core ideas opens the door to much more complex models.</p>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      
      <script id="__config" type="application/json">{"annotate": null, "base": "../..", "features": ["content.code.copy", "navigation.sections", "navigation.expand", "navigation.top", "toc.integrate", "search.highlight"], "search": "../../assets/javascripts/workers/search.7a47a382.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../../assets/javascripts/bundle.e71a0d61.min.js"></script>
      
        <script src="../../assets/javascripts/mathjax.js"></script>
      
        <script src="../../assets/javascripts/language-nav.js"></script>
      
        <script src="../../assets/javascripts/video-init.js"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
      
    
  </body>
</html>