# Introduction: From Microscopic Particles to Continuous Fields

This lecture marks a **pivotal turning point** in our study of stochastic dynamics. In earlier lectures (especially Lectures 17–22), we have built a powerful toolkit including the Langevin equation, the Fokker-Planck equation, and the path-integral formulation. Now, we will use these tools to address a core question in physics: **how does the collective behavior of a many-body system emerge from the stochastic dynamics of its constituent particles?**

**Therefore, the central question this lecture answers is: how do we describe the fluctuations of a system composed of many interacting particles (e.g., colloids in a solution, proteins in a cell) in the vicinity of thermal equilibrium?**

To answer this question, Prof. Erwin Frey introduces two complementary powerful perspectives that will be thoroughly explored in this lecture and their connections established:

- **(A) Microscopic "Bottom-Up" approach:** We start from the known physical laws for individual particles (the Langevin equation) and, through a step called **coarse-graining**, derive the macroscopic system's dynamical equations. We transform this discrete, particle-based description into a continuous field theory description, ultimately obtaining a stochastic partial differential equation describing the evolution of the particle density field. The advantage of this method is its clear physical picture, allowing us to intuitively see how macroscopic behavior emerges from microscopic rules.

- **(B) Macroscopic "Top-Down" approach:** We start directly from the macroscopic level, using fundamental principles of thermodynamics and symmetry (pioneered by Onsager and others) to constrain the possible forms of macroscopic dynamical equations. We use fundamental principles of thermodynamics and symmetry to construct a universal theory of fluctuations, whose power lies in its independence from any specific microscopic model details. As long as the system is close to a stable thermal equilibrium state, its fluctuation behavior must follow certain universal laws.

First, the professor will demonstrate how method (A) naturally transitions from the particle picture to a continuous field theory description. Then, we will develop the universal framework of method (B) for describing fluctuations of any system near equilibrium. Finally, we will use this framework, through the perspective of time correlation functions and fundamental symmetries, to understand the dynamical characteristics of these fluctuations. From microscopic particles to continuous fields, we describe the connection between the microscopic stochastic dynamics of individual particle motion and the macroscopic thermodynamic properties of the system. **We will see that the collective behavior of the system, such as density fluctuations, can emerge from the underlying particle interactions and is ultimately governed by universal thermodynamic principles.**

# 1. From Interacting Particles to a Continuous Field Theory

The passage from discrete-particle equations to continuous-field equations is not just mathematical convenience; it embodies a deep physical idea: coarse-graining. We deliberately ignore high-frequency, short-wavelength microscopic details (e.g., each particle’s exact position) and focus on slowly varying, long-wavelength collective variables that control macroscopic behavior (e.g., local particle density). In this process, a free-energy functional $F[\rho]$ naturally appears; it plays the role of an effective “Hamiltonian” or “action” for the coarse-grained field theory and governs equilibrium and dynamics.

For a Langevin system with $N$ particles, large $N$ makes direct solution intractable. Yet for many phenomena (e.g., diffusion, phase separation) we do not care about the exact coordinate of particle #1,304,567. We care about the average density in small volumes. Averaging particle coordinates in small volumes defines a continuous density field $\rho(\mathbf{x}, t)$ — the core idea of coarse-graining.

Once we have $\rho$, the interparticle forces driven by pair potentials are replaced by an effective driving force acting on the field. In the Langevin equation, the drift $-\mu\,\nabla V$ is driven by a potential gradient. For $\rho$, what is the analogue? Thermodynamics tells us the system evolves to minimize its free energy. Therefore the dynamics of $\rho$ is driven by “downhill” motion on a free-energy landscape — not an ordinary function but a functional $F[\rho]$ assigning a scalar (total free energy) to each density profile. The functional derivative $\delta F / \delta \rho$ acts as a generalized force (a chemical potential) that drives the system toward the minimizer of $F$. Thus microscopic interparticle interactions give rise to macroscopic thermodynamic driving.

## 1.1 Microscopic View: A System of Interacting Brownian Particles

We start with a concrete model of $N$ Brownian particles. These particles are suspended in a viscous fluid (heat bath) at constant temperature $T$. We consider the **overdamped limit**, which means the viscous resistance of the fluid is so large that the particle's inertia ($m\mathbf{a}$) can be completely ignored. In this case, the particle's velocity $d\mathbf{x}/dt$ is instantaneously proportional to the total force it experiences, rather than being described by Newton's second law.

The trajectory $\mathbf{x}_i(t)$ of each particle $i$ is described by a set of coupled Langevin equations:

$$
\frac{d\mathbf{x}_i}{dt} = \mu \sum_{j \neq i} \mathbf{F}_{ij} + \boldsymbol{\xi}_i(t)
$$

where:

$$
\mathbf{F}_{ij} = -\nabla_i V(\mathbf{x}_i - \mathbf{x}_j)
$$

This equation precisely describes the balance of two fundamental physical processes:

**Deterministic Drift:** The first term $\mu \sum \mathbf{F}_{ij}$ represents deterministic motion driven by conservative forces within the system.

* $\mathbf{F}_{ij} = -\nabla_i V(\ldots)$ is the force exerted by particle $j$ on particle $i$, given by the negative gradient of a pairwise interaction potential $V(r)$. This potential can be a Lennard-Jones potential, Coulomb force, or simple hard-sphere repulsion.

* $\sum_{j \neq i}$ represents the vector sum of forces from all other particles acting on particle $i$. It is this term that couples the motion of all particles, making the system a complex many-body problem.

* $\mu$ is the **mobility**, which quantifies the velocity of a particle under unit force, i.e., $\mathbf{v} = \mu \mathbf{F}$. It is inversely proportional to the fluid's viscous (friction) coefficient $\gamma$, $\mu = 1/\gamma$, entirely determined by the solvent's properties.

**Stochastic Force:** $\boldsymbol{\xi}_i(t)$, also called the Langevin force, is a random term. It represents the collective effect of countless rapid and random collisions from surrounding solvent molecules. We cannot track every microscopic collision, so we model it as a random process.

![Blackboard Screenshot](../assets/images/remote/3675f539-3d3d-42b4-97bc-5d1bd996a64f-9531c67f44.png)

### Statistics of the Noise

We typically assume that the random force $\boldsymbol{\xi}_i(t)$ is a Gaussian white noise, whose statistical properties are completely defined by its first and second moments (correlation functions):

1. **Zero mean**: $\langle \xi_{i\alpha}(t) \rangle = 0$

   * Physically, this means that the collisions from the heat bath have no preference in any direction, and the long-time average of the net force is zero. Otherwise, the system would have a net driving force, which would violate the second law of thermodynamics.

2. **Spatiotemporal correlation**: $\langle \xi_i^\alpha(t) \xi_j^\beta(t') \rangle = 2 \mu k_B T \, \delta_{ij} \, \delta^{\alpha\beta} \, \delta(t - t')$

* $\delta(t - t')$ embodies the **"white"** nature of the noise in time: random forces at any two different moments are completely uncorrelated. This is an effective approximation that assumes the time scale of solvent molecular collisions is much smaller than the time scale for significant changes in Brownian particle positions.

* $\delta_{ij}$ and $\delta^{\alpha\beta}$ respectively indicate that random forces between different particles and between different spatial components (such as x, y, z) of the same particle are independent. This reflects that the heat bath collisions are local and isotropic.

### Physical Core: Fluctuation-Dissipation Theorem

The coefficient $2\mu k_B T$ in the noise correlation function is not arbitrarily chosen; it is a direct manifestation of the **Fluctuation-Dissipation Theorem (FDT)**, which is the bridge connecting microscopic randomness with macroscopic thermodynamics.

This theorem states that the solvent has two seemingly opposing effects on Brownian particles:

1. **Dissipation:** When particles move, the solvent produces viscous resistance, causing the particle's kinetic energy to dissipate into heat. The strength of this effect is quantified by the friction coefficient $\gamma$ or its inverse, the mobility $\mu$.

2. **Fluctuation:** Since the solvent molecules themselves are in thermal motion (manifestation of temperature $T$), they continuously perform random collisions on the particles, causing the particles to perform random Brownian motion. The strength of this effect is quantified by the magnitude of the noise correlation function.

**The profound implication of FDT is: these two processes originate from the same microscopic physical mechanism (interaction with solvent molecules), so their strengths must be strictly correlated.** A system with strong dissipation (high viscosity) must also experience intense thermal fluctuations.

This theorem ensures that the system, in the absence of external forces, will spontaneously evolve to a thermodynamic equilibrium state. The random "kicks" of the stochastic force continuously inject energy into the system, while the viscous resistance continuously dissipates energy. At equilibrium, these two processes reach dynamic balance, keeping the system's average kinetic energy consistent with temperature $T$, and ultimately the particle's spatial distribution follows the Boltzmann distribution. If this relationship does not hold, the system would either heat up infinitely or "freeze" to absolute zero.

### From Particles to Field Evolution Equations

Coarse-graining the particle picture to a density field $\rho(\mathbf{x},t)$ yields a stochastic conservation law. The deterministic part is driven by gradients of a chemical potential (the functional derivative of a free energy), and the stochastic part becomes a conserved noise consistent with FDT. Thus we obtain a stochastic PDE for $\rho$ that captures diffusion, drift from interactions, and thermal fluctuations.

## 1.2 Free-Energy Functional: A Deeper Organizing Principle

The central organizing quantity for the field description is the free-energy functional $F[\rho]$. It maps each admissible density profile to a scalar free energy and encodes both ideal contributions (entropy) and interaction contributions (e.g., mean-field interactions, gradient penalties for inhomogeneities). The nonequilibrium dynamics “rolls downhill” in $F$ while being perturbed by thermal noise with strength fixed by FDT.

## 1.3 Rewriting the Dynamics with Free Energy

Casting the dynamics in terms of $F[\rho]$ makes the structure transparent. The chemical potential $\mu(\mathbf{x}) = \delta F / \delta \rho(\mathbf{x})$ plays the role of a generalized force; the deterministic current is proportional to $-\nabla \mu$, and the stochastic current is a divergence of a noise field with covariance set by mobility and temperature. This connects microscopic interactions (through $F$) to macroscopic transport and noise.

# 2. A Universal Framework for Near-Equilibrium Fluctuations

In the previous section, we have completed the "bottom-up" journey: starting from the Langevin equations for $N$ interacting Brownian particles, through the somewhat complex mathematical derivation of "coarse-graining," we finally obtained a stochastic partial differential equation (SPDE) describing the evolution of the density field $\rho$. While this equation is exact, its form is complex, and its derivation depends on our knowledge of the microscopic interaction potential $V$. The core question is: **assuming we know nothing about microscopic details, can we construct a theory to describe the fluctuation behavior of any system near a stable equilibrium state based solely on fundamental thermodynamic principles?**

This section we turn to a more universal perspective — the **"top-down"** approach. The core idea of this part lies in its **universality**. By abstracting away from the specific details of interacting particles, we focus on a set of general, slowly evolving **"mesoscopic variables" $\{\phi_a\}$**.

## 2.1 From the Density Field to Universal Mesoscopic Variables $\{\phi_a\}$

In Part 1, the macroscopic variable of interest was the density field $\rho(\mathbf{x},t)$. Think of space partitioned into small cells; the density in each cell is a macroscopic variable. In this way, a field is a collection of many macroscopic variables.

We now generalize beyond density. Consider any set of slowly evolving macroscopic variables that characterize the mesoscopic state, denoted $\{\phi_a\}$. These variables represent deviations from equilibrium means; in equilibrium $\langle \phi_a \rangle_{\rm eq}=0$. Examples include local magnetization in a magnet, concentration differences in a binary mixture, and order parameters near a phase transition.

The core assumption is local thermodynamic equilibrium: although the system may be slightly out of global equilibrium ($\phi_a\neq 0$), each small region is approximately in equilibrium and can be described by standard thermodynamic variables.

## 2.2 Entropy as Organizing Principle: Building the “Potential Landscape” of Fluctuations

In Sec. 1 we saw that $F[\rho]$ acts as a driving potential. For an isolated macroscopic system, the universal thermodynamic quantity playing this role is entropy $S$.

### Einstein–Boltzmann Relation

At equilibrium, the probability to observe a particular set of fluctuations $\{\phi_a\}$ is given by Einstein’s generalization of the Boltzmann distribution:

$$
P_{\rm eq}(\{\phi_a\}) \propto \exp\!\left( \frac{S(\{\phi_a\})}{k_B} \right).
$$

Physical meaning: this bridges macroscopic thermodynamics (entropy $S$) and statistical mechanics (probabilities $P$). Macrostates with larger entropy are more probable; equilibrium is the macrostate of maximal entropy.

### Gaussian Approximation of Entropy

For an isolated system, $S$ is maximal at equilibrium. Expand around the maximum at $\phi=0$:

$$
S(\{\phi_a\}) = S_0 + \left.\frac{\partial S}{\partial \phi_a}\right|_{\phi=0} \phi_a + \frac{1}{2} \left.\frac{\partial^2 S}{\partial \phi_a\,\partial \phi_b}\right|_{\phi=0} \phi_a\phi_b + \cdots.
$$

Because $\phi=0$ is a maximum, the linear term vanishes. For small fluctuations we neglect $\phi^3$ and higher, yielding a quadratic form:

$$
S(\{\phi_a\}) \approx S_0 - \tfrac{1}{2}\, \Gamma_{ab}\, \phi_a \phi_b,
$$

with the stability matrix

$$
\Gamma_{ab} = -\left.\frac{\partial^2 S}{\partial \phi_a\,\partial \phi_b}\right|_{\phi=0}.
$$

Here $S_0$ is the maximal entropy at equilibrium. We use Einstein’s summation convention. Physical meaning: near any stable equilibrium point, the entropy “landscape” is locally an inverted paraboloid (quadratic form). This universality is the strength of the framework.

### Stability Matrix $\Gamma_{ab}$

The matrix $\Gamma_{ab}$ is symmetric ($\Gamma_{ab}=\Gamma_{ba}$) and positive definite, ensuring $\phi=0$ is a true maximum of $S$ (not a saddle) and hence a stable equilibrium. Its eigenvalues measure the curvature of the entropy peak; a steeper peak (larger $\Gamma$) implies stronger restoring forces.

## 2.3 Thermodynamic Forces, Susceptibilities, and Equilibrium Correlations: From Landscape to Response

With the entropy landscape in hand, we define the “forces” driving relaxation to equilibrium and quantify the system’s response, leading to fluctuation properties.

### Generalized Restoring Force $\mu_a$

The thermodynamic force conjugate to $\phi_a$ is the entropy gradient:

$$
\mu_a = \frac{\partial S}{\partial \phi_a}.
$$

In the quadratic approximation, this yields a linear restoring force

$$
\mu_a = -\Gamma_{ab}\, \phi_b.
$$

Physical meaning: a generalized Hooke’s law. The further the system is from equilibrium, the stronger the restoring force; $\Gamma$ sets the stiffness of the “spring”.

### Susceptibility Matrix $\chi_{ab}$

Define the susceptibility as the inverse of $\Gamma$:

$$
\chi = \Gamma^{-1}, \qquad \phi = -\chi\, \mu.
$$

Physical meaning: $\chi$ measures responsiveness to perturbations (the softness of the spring).

### Equilibrium Correlation Functions

Using the Gaussian equilibrium distribution $P_{\rm eq} \propto \exp[ -\tfrac{1}{2} \Gamma_{ab}\, \phi_a\phi_b ]$ gives immediately

$$
\langle \phi_a \phi_b \rangle_{\rm eq} = (\Gamma^{-1})_{ab} \equiv \chi_{ab}.
$$

Physical meaning: this is a central form of the fluctuation–dissipation theorem (FDT). The susceptibility $\chi$ (deterministic response to a probe) equals the variance of spontaneous fluctuations in equilibrium.

Other useful correlators follow:

$$
\langle \phi_a \mu_b \rangle_{\rm eq} = -\delta_{ab},
\qquad
\langle \mu_a \mu_b \rangle_{\rm eq} = \Gamma_{ab}.
$$

Thus, near a stable equilibrium, the entropy landscape (curvature $\Gamma$) fixes both the restoring forces and the fluctuation amplitudes, and $P_{\rm eq}(\{\phi_a\})$ is multivariate Gaussian — a universal conclusion.

# 3. Dynamics of Fluctuations: Time Correlation Functions

So far, through entropy $S$, we have constructed a universal static framework describing equilibrium fluctuations, obtaining a powerful conclusion: the fluctuation correlation at a certain moment $\langle \phi_a(0)\phi_b(0) \rangle$ equals the system's response to external perturbations (susceptibility $\chi_{ab}$). However, the statistical laws obtained so far cannot answer the following questions:

**If a fluctuation occurs now, how will it evolve over time and eventually disappear?**

**How long can the system's "memory" last? What is the correlation between the fluctuation now and the fluctuation one second later?**

To answer these questions about **dynamics**, we need to introduce a powerful new tool — time correlation functions. The properties of these functions are not arbitrary; they are deeply imprinted with the most fundamental **symmetries** of the microscopic world, especially **time-reversal symmetry**.

## 3.1 Time Correlation Functions: Measuring Memory

### Definition

Define the equilibrium time-correlation function

$$
 C_{ab}(t-t') := \langle \phi_a(t)\, \phi_b(t') \rangle.
$$

It measures the statistical correlation between $\phi_b$ at time $t'$ and $\phi_a$ at a later time $t$.

### Stationarity

In equilibrium the process is stationary, so $C_{ab}$ depends only on the time difference: $C_{ab}(t-t')$. In particular, $C_{ab}(t)=C_{ba}(-t)$ when variables are even under time reversal; more generally see Sec. 3.2.

## 3.2 The Stamp of Time Symmetry: Microscopic Reversibility

### Principle of Microscopic Reversibility

Microscopic equations of motion are invariant under time reversal (for systems without magnetic fields or other time-reversal breaking sources). This symmetry places constraints on macroscopic correlations.

### Parity of Variables ($\epsilon_a$)

Each variable has a time-reversal parity $\epsilon_a=\pm 1$ depending on whether it is even ($+1$) or odd ($-1$) under $t\to -t$ (e.g., position even, velocity odd).

### Onsager–Casimir Reciprocal Relations

Time-reversal symmetry implies a generalized reciprocity for correlation functions:

$$
 C_{ab}(t) = \epsilon_a\, \epsilon_b\, C_{ba}(t).
$$

Physical meaning: this connects the macroscopic “arrow of time” seen in decaying correlations with the microscopic time-reversal symmetry through the parities $\epsilon$. As an example, for position $\mathbf{r}$ (even) and velocity $\mathbf{v}$ (odd):

$$
 C_{\mathbf{r}\mathbf{v}}(t) = -\, C_{\mathbf{v}\mathbf{r}}(t),
\qquad
 \langle \mathbf{r}(t)\, \mathbf{v}(0) \rangle = - \langle \mathbf{v}(t)\, \mathbf{r}(0) \rangle.
$$

![Blackboard Screenshot](../assets/images/remote/b74ec1e3-a00f-40f1-a9e3-69236a0fdc6d-0cb5106cc6.png)

Table: Time-Reversal Parity of Common Physical Quantities

| Quantity | Symbol | Time Reversal $(t\to -t)$ | Parity $(\epsilon)$ |
| :--- | :--- | :--- | :--- |
| Position | $\vec{r}$ | $\vec{r}(-t)=\vec{r}(t)$ | $+1$ (even) |
| Velocity | $\vec{v}$ | $\vec{v}(-t)=-\vec{v}(t)$ | $-1$ (odd) |
| Momentum | $\vec{p}$ | $\vec{p}(-t)=-\vec{p}(t)$ | $-1$ (odd) |
| Acceleration | $\vec{a}$ | $\vec{a}(-t)=\vec{a}(t)$ | $+1$ (even) |
| Force | $\vec{F}$ | $\vec{F}(-t)=\vec{F}(t)$ | $+1$ (even) |
| Energy | $E$ | $E(-t)=E(t)$ | $+1$ (even) |
| Number density | $\rho$ | $\rho(-t)=\rho(t)$ | $+1$ (even) |
| Angular momentum | $\vec{L}$ | $\vec{L}(-t)=-\vec{L}(t)$ | $-1$ (odd) |
| Electric field | $\vec{E}$ | $\vec{E}(-t)=\vec{E}(t)$ | $+1$ (even) |
| Magnetic field | $\vec{B}$ | $\vec{B}(-t)=-\vec{B}(t)$ | $-1$ (odd) |

# 4. Dynamic Simulation of Coarse-Graining

We will now simulate a system composed of $N$ interacting Brownian particles in the overdamped limit. The numerical discretization is performed using the **"Euler-Maruyama method"**.

In each small time step $dt$, a particle's movement is composed of two superimposed parts:

**Deterministic Drift:** It comes from the forces exerted by all other surrounding particles. We will use a simple repulsive potential to calculate this force, preventing particles from "passing through" each other.

**Stochastic Kick:** It simulates the continuous random collisions from the constant-temperature heat bath. We will use a Gaussian-distributed random number to generate this kick, with its strength determined by the temperature $T$ we set.

### Code Implementation

```python
"""
Python script to simulate interacting Brownian particles (Langevin dynamics)
and visualize their microscopic motion alongside the coarse-grained macroscopic density field.
The final output is a GIF animation.
"""

import numpy as np
import matplotlib.pyplot as plt
from matplotlib.animation import FuncAnimation
from scipy.ndimage import gaussian_filter

# --- 1. Simulation Parameters ---

# System parameters
N = 100          # Number of particles
L = 20.0         # Size of the simulation box (2D)
T = 1.0          # Temperature (we set Boltzmann constant k_B=1)
mu = 1.0         # Mobility
D = mu * T       # Diffusion coefficient, from Einstein relation

# Simulation parameters
dt = 0.02        # Timestep length
n_steps = 1000   # Total simulation steps
save_interval = 10 # Save trajectory every 'save_interval' steps for animation

# Interaction parameters (Weeks-Chandler-Andersen potential, a purely repulsive force)
sigma = 1.0      # Characteristic size of a particle
epsilon = 1.0    # Interaction strength
rcut = sigma * (2**(1/6)) # Cutoff distance for the force

# Visualization parameters
grid_bins = 50   # Number of bins for the density grid
blur_sigma = 1.5 # Sigma for the Gaussian filter to smooth the density field


# --- 2. Core Functions ---

def calculate_forces(positions, box_size, eps, sig, r_cut):
    """
    Calculates the total force on each particle using the WCA potential
    and applies periodic boundary conditions (minimum image convention).
    """
    forces = np.zeros_like(positions)
    r_cut2 = r_cut**2
    
    for i in range(N):
        for j in range(i + 1, N):
            # Displacement vector between particle i and j
            dr = positions[i] - positions[j]
            
            # Apply periodic boundary conditions
            dr = dr - box_size * np.round(dr / box_size)
            
            r_sq = np.sum(dr**2)
            
            # Calculate force only if particles are closer than the cutoff distance
            if r_sq < r_cut2:
                r_sq_inv = 1.0 / r_sq
                sig_r6 = (sig**2 * r_sq_inv)**3
                
                # Force magnitude from the derivative of the WCA potential
                force_mag = 48 * eps * r_sq_inv * (sig_r6**2 - 0.5 * sig_r6)
                force_vec = force_mag * dr
                
                # Apply force according to Newton's third law
                forces[i] += force_vec
                forces[j] -= force_vec
                
    return forces

# --- 3. Initialization ---

# Set a random seed for reproducibility
np.random.seed(42)

# Initialize particle positions randomly within the box [0, L] x [0, L]
pos = np.random.rand(N, 2) * L

# --- 4. Run Simulation & Store Trajectory ---

print("Running simulation to generate trajectory...")
# Store the trajectory for the animation
# We pre-calculate the trajectory to make the animation rendering smoother
trajectory = [pos.copy()]
num_frames = n_steps // save_interval

for step in range(n_steps):
    # Calculate deterministic forces
    F = calculate_forces(pos, L, epsilon, sigma, rcut)
    
    # Calculate drift and random kick terms
    drift = mu * F * dt
    random_kick = np.sqrt(2 * D * dt) * np.random.randn(N, 2)
    
    # Update particle positions
    pos += drift + random_kick
    
    # Enforce periodic boundary conditions on positions
    pos = pos % L
    
    # Store the current frame in the trajectory
    if (step + 1) % save_interval == 0:
        trajectory.append(pos.copy())

trajectory = np.array(trajectory)
print(f"Simulation finished. Trajectory shape: {trajectory.shape}")


# --- 5. Animation Setup ---

print("Setting up animation...")
# Create the figure and subplots
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))

# Setup for the left subplot (Microscopic View)
ax1.set_title('Microscopic View: Particle Dynamics')
ax1.set_xlabel('X position')
ax1.set_ylabel('Y position')
ax1.set_xlim(0, L)
ax1.set_ylim(0, L)
ax1.set_aspect('equal', adjustable='box')
scatter = ax1.scatter(trajectory[0, :, 0], trajectory[0, :, 1], s=50, c='royalblue')

# Setup for the right subplot (Macroscopic View)
ax2.set_title('Macroscopic View: Coarse-Grained Density')
ax2.set_xlabel('X position')
ax2.set_ylabel('Y position')
ax2.set_aspect('equal', adjustable='box')

# Create the grid for the heatmap
grid_x = np.linspace(0, L, grid_bins)
grid_y = np.linspace(0, L, grid_bins)

# Initial density field
hist, _, _ = np.histogram2d(
    trajectory[0, :, 0], trajectory[0, :, 1],
    bins=[grid_x, grid_y]
)
density_field = gaussian_filter(hist.T, sigma=blur_sigma)
heatmap = ax2.imshow(density_field, origin='lower', extent=[0, L, 0, L], cmap='viridis')
fig.colorbar(heatmap, ax=ax2, label='Particle Density')

# Add a time display
time_text = ax1.text(0.05, 0.95, '', transform=ax1.transAxes, ha='left', va='top',
                     bbox=dict(boxstyle='round,pad=0.5', fc='wheat', alpha=0.7))


# --- 6. Animation Update Function ---

def update(frame):
    """
    This function is called for each frame of the animation.
    """
    # Get current positions from the pre-computed trajectory
    current_pos = trajectory[frame]
    
    # --- Update Microscopic View ---
    scatter.set_offsets(current_pos)
    
    # --- Update Macroscopic View ---
    # 1. Coarse-graining: create a histogram
    hist, _, _ = np.histogram2d(
        current_pos[:, 0], current_pos[:, 1],
        bins=[grid_x, grid_y]
    )
    # 2. Smoothing: apply Gaussian filter
    density_field = gaussian_filter(hist.T, sigma=blur_sigma)
    
    # 3. Update heatmap data
    heatmap.set_data(density_field)
    
    # Update time text
    t_now = frame * save_interval * dt
    time_text.set_text(f"t = {t_now:.2f}")
    
    return scatter, heatmap, time_text

# --- 7. Create and Save Animation ---

print("Rendering animation...")
anim = FuncAnimation(fig, update, frames=num_frames, interval=50, blit=True)

anim.save('particle_dynamics.gif', writer='pillow', fps=20)
print("Animation saved as 'particle_dynamics.gif'.")
```

![Run Output](../assets/images/remote/particle_dynamics.gif)

Left: overdamped Langevin dynamics of $N$ interacting Brownian particles in a heat bath. Each particle’s irregular motion combines thermal kicks (stochastic force) and deterministic repulsion from other particles (preventing overlap, producing liquid-like structure). The system explores its microstates near thermal equilibrium.

Right: coarse-grained macroscopic view — the evolving continuous density field $\rho(\mathbf{x},t)$. The bright “hot spots” that appear, change, and disappear are thermal density fluctuations: spontaneous, transient local departures from the uniform equilibrium density.

# Conclusion: Coarse-Graining and the Renormalization Group

This lecture started from a concrete Langevin model of $N$ interacting Brownian particles and, through coarse-graining methods, evolved it into a continuous field theory dominated by a free-energy functional. Subsequently, we distilled the core principles from this and constructed a universal fluctuation theory based on entropy, applicable to any near-equilibrium system. Finally, we used time correlation functions as a tool to analyze the dynamical behavior of these fluctuations and revealed how they are profoundly constrained by fundamental symmetries of the microscopic world (such as time-reversal symmetry).

The theoretical framework established in this lecture is one of the cornerstones of modern statistical physics. It clearly demonstrates how irreversible relaxation processes and colored (non-white noise) fluctuations in the macroscopic world emerge from time-symmetric microscopic dynamical laws.

Beginners might relate **coarse-graining** to an important theory in statistical physics: the **Renormalization Group (RG)**. These two have very close connections in thought, but one is a method and the other is a theoretical framework.

Essentially, they both follow a core idea: **by systematically ignoring (or integrating out) small-scale (high-energy) degrees of freedom, to obtain an effective theory that only describes large-scale (low-energy) physical behavior.**

### Connections: Shared Philosophy — Scale Separation

1. **Eliminating microscopic details:** Both aim to start from a complex theory containing all microscopic details and derive a simpler theory that only describes macroscopic or long-wavelength behavior. "Coarse-graining" replaces a large number of discrete particle coordinates $\mathbf{x}_i$ with a smooth continuous density field $\rho(\mathbf{x})$. This process "forgets" each particle's identity and precise position. The renormalization group does something similar in momentum space: it integrates out (averages out) high-momentum (short-wavelength) fluctuation modes.

2. **Emergence of effective theories:** After the operation, what is obtained is an "effective theory." In coarse-graining, you get a stochastic partial differential equation for the density field $\rho$, where the parameters (such as diffusion coefficient, mobility) and the form of the free-energy functional $F[\rho]$ "emerge" from the underlying particle interactions. In the renormalization group, after each transformation step, a new Hamiltonian (or action) is also obtained, whose coupling constants change (the so-called "renormalization"), and this new Hamiltonian is the effective theory describing the next larger scale.

### Differences: Goals and Methods

| Feature | Coarse-Graining | Renormalization Group |
| :--- | :--- | :--- |
| **Main goal** | Derive a **macroscopic dynamical equation** (e.g., SPDE for $\rho$) from a **specific microscopic model** (e.g., Langevin equation). Focus is on connecting microscopic and macroscopic. | Study system behavior **across different scales**, particularly finding laws for how physical quantities change with observation scale (scaling laws), and finding fixed points of the theory (usually corresponding to phase transition points). |
| **Operation method** | Usually a one-time, fixed spatial or temporal average. For example, divide the box into a $10 \times 10$ grid, then never change this grid size. | An **iterative and dynamic** process. It includes two key steps: 1. **Coarse-graining** (integrate out high-momentum modes); 2. **Scale rescaling** (enlarge the system back to original size for comparison). This process is repeated, forming a "flow" (RG flow). |
| **Core question** | "What is the macroscopic behavior of this many-particle system?" | "When the system approaches a critical point (phase transition point), how do its physical properties (such as specific heat, magnetic susceptibility) diverge with temperature? What universal laws govern this divergence behavior?" |
| **Applications** | Soft matter physics, fluid mechanics, chemical kinetics, etc., for deriving macroscopic continuum models. | Critical phenomena (phase transition theory), quantum field theory, high-energy physics. RG is a key tool for understanding **universality** — that different microscopic systems exhibit the same behavior near critical points. |

In summary, **coarse-graining** is like using a **fixed-resolution camera** to photograph a very high-definition painting, obtaining a lower-resolution image that still shows the contours clearly. This process is done only once.

**Renormalization group** is like using a **zoom lens**. First take a photo from far away (coarse-graining), then **take a step forward and adjust the focal length** so that objects in the photo appear the same size as in the first photo (scale rescaling). Then repeat this process: take another photo from farther away, then step closer and zoom... By observing which features remain unchanged and which become blurred or sharp during the repeated "zoom-approach" process, we can understand the internal structure and scale symmetry of this painting.

**Coarse-graining** is a concrete mathematical step used to derive field theory equations from known particle dynamics. **Renormalization group** is a more abstract and powerful theoretical framework that itself includes "coarse-graining" as one of its operational steps, but its ultimate purpose is to study the symmetries and universal laws of systems across multiple scales, especially near phase transition points.

