
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="Course Notes and Code (Erwin Frey, LMU Munich, 2025)">
      
      
        <meta name="author" content="Zhihang Liu">
      
      
        <link rel="canonical" href="https://liu-zhihang.github.io/Nonequilibrium-Field-Theories-and-Stochastic-Dynamics/zh/notes/13.%20%E4%BD%9C%E4%B8%BA%E9%9A%8F%E6%9C%BA%E8%BF%87%E7%A8%8B%E7%9A%84%E8%92%99%E7%89%B9%E5%8D%A1%E6%B4%9B%E9%87%87%E6%A0%B7/">
      
      
        <link rel="prev" href="../12.%20%E5%B8%83%E6%9C%97%E8%BF%90%E5%8A%A8%E4%B8%8E%E5%A5%A5%E6%81%A9%E6%96%AF%E5%9D%A6-%E4%B9%8C%E4%BC%A6%E8%B4%9D%E5%85%8B%E8%BF%87%E7%A8%8B/">
      
      
        <link rel="next" href="../14.%20%E5%93%88%E5%AF%86%E5%B0%94%E9%A1%BF%E8%92%99%E7%89%B9%E5%8D%A1%E6%B4%9B%E9%87%87%E6%A0%B7/">
      
      
      <link rel="icon" href="../../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.22">
    
    
      
        <title>13. 作为随机过程的蒙特卡洛采样 - Nonequilibrium Field Theories and Stochastic Dynamics</title>
      
    
    
      <link rel="stylesheet" href="../../../assets/stylesheets/main.84d31ad4.min.css">
      
        
        <link rel="stylesheet" href="../../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#_1" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../.." title="Nonequilibrium Field Theories and Stochastic Dynamics" class="md-header__button md-logo" aria-label="Nonequilibrium Field Theories and Stochastic Dynamics" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Nonequilibrium Field Theories and Stochastic Dynamics
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              13. 作为随机过程的蒙特卡洛采样
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m17.75 4.09-2.53 1.94.91 3.06-2.63-1.81-2.63 1.81.91-3.06-2.53-1.94L12.44 4l1.06-3 1.06 3zm3.5 6.91-1.64 1.25.59 1.98-1.7-1.17-1.7 1.17.59-1.98L15.75 11l2.06-.05L18.5 9l.69 1.95zm-2.28 4.95c.83-.08 1.72 1.1 1.19 1.85-.32.45-.66.87-1.08 1.27C15.17 23 8.84 23 4.94 19.07c-3.91-3.9-3.91-10.24 0-14.14.4-.4.82-.76 1.27-1.08.75-.53 1.93.36 1.85 1.19-.27 2.86.69 5.83 2.89 8.02a9.96 9.96 0 0 0 8.02 2.89m-1.64 2.02a12.08 12.08 0 0 1-7.8-3.47c-2.17-2.19-3.33-5-3.49-7.82-2.81 3.14-2.7 7.96.31 10.98 3.02 3.01 7.84 3.12 10.98.31"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 7a5 5 0 0 1 5 5 5 5 0 0 1-5 5 5 5 0 0 1-5-5 5 5 0 0 1 5-5m0 2a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0-7 2.39 3.42C13.65 5.15 12.84 5 12 5s-1.65.15-2.39.42zM3.34 7l4.16-.35A7.2 7.2 0 0 0 5.94 8.5c-.44.74-.69 1.5-.83 2.29zm.02 10 1.76-3.77a7.131 7.131 0 0 0 2.38 4.14zM20.65 7l-1.77 3.79a7.02 7.02 0 0 0-2.38-4.15zm-.01 10-4.14.36c.59-.51 1.12-1.14 1.54-1.86.42-.73.69-1.5.83-2.29zM12 22l-2.41-3.44c.74.27 1.55.44 2.41.44.82 0 1.63-.17 2.37-.44z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
      <div class="md-header__option">
  <div class="md-select">
    
    <button class="md-header__button md-icon" aria-label="Select language">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m12.87 15.07-2.54-2.51.03-.03A17.5 17.5 0 0 0 14.07 6H17V4h-7V2H8v2H1v2h11.17C11.5 7.92 10.44 9.75 9 11.35 8.07 10.32 7.3 9.19 6.69 8h-2c.73 1.63 1.73 3.17 2.98 4.56l-5.09 5.02L4 19l5-5 3.11 3.11zM18.5 10h-2L12 22h2l1.12-3h4.75L21 22h2zm-2.62 7 1.62-4.33L19.12 17z"/></svg>
    </button>
    <div class="md-select__inner">
      <ul class="md-select__list">
        
          <li class="md-select__item">
            <a href="/Nonequilibrium-Field-Theories-and-Stochastic-Dynamics/" hreflang="en" class="md-select__link">
              English
            </a>
          </li>
        
          <li class="md-select__item">
            <a href="/Nonequilibrium-Field-Theories-and-Stochastic-Dynamics/zh/" hreflang="zh" class="md-select__link">
              简体中文
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</div>
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
      <div class="md-header__source">
        <a href="https://github.com/Liu-Zhihang/Nonequilibrium-Field-Theories-and-Stochastic-Dynamics" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



  

<nav class="md-nav md-nav--primary md-nav--integrated" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../.." title="Nonequilibrium Field Theories and Stochastic Dynamics" class="md-nav__button md-logo" aria-label="Nonequilibrium Field Theories and Stochastic Dynamics" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    Nonequilibrium Field Theories and Stochastic Dynamics
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/Liu-Zhihang/Nonequilibrium-Field-Theories-and-Stochastic-Dynamics" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../.." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Home
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
      
        
        
      
    
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2" >
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    Course Notes
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            Course Notes
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../notes/1.%20Course%20Introduction/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    1. Course Introduction
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../notes/2.%20Simple%20Random%20Walk/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    2. Simple Random Walk
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../notes/3.%20Gaussian%20Random%20Walk%20and%20Poisson%20Process/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    3. Gaussian Random Walk and Poisson Process
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../notes/4.%20Gillespie%20Algorithm%2C%20Master%20Equation%2C%20Generating%20Functions%20and%20Population%20Dynamics/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    4. Gillespie Algorithm, Master Equation, Generating Functions and Population Dynamics
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../notes/5.%20Population%20Dynamics%20-%20Linear%20Death%20Process%20and%20Lotka-Volterra%20System/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    5. Population Dynamics - Linear Death Process and Lotka-Volterra System
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../notes/6.%20Fundamental%20Equations%20of%20Markov%20Processes%20%E2%80%94%20Chapman%E2%80%93Kolmogorov%20Equation/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    6. Fundamental Equations of Markov Processes — Chapman–Kolmogorov Equation
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../notes/7.%20Forward%20Master%20Equation%20and%20the%20Q%20Matrix/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    7. Forward Master Equation and the Q Matrix
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../notes/8.%20Perron%E2%80%93Frobenius%20Theorem%2C%20Steady%20States%2C%20and%20Detailed%20Balance/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    8. Perron–Frobenius Theorem, Steady States, and Detailed Balance
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../notes/9.%20Nonequilibrium%20States%20%E2%80%94%20Irreversibility%20and%20Entropy%20Production/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    9. Nonequilibrium States — Irreversibility and Entropy Production
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../notes/10.%20Ehrenfest%20Model%2C%20Entropy%2C%20and%20KL%20Divergence/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    10. Ehrenfest Model, Entropy, and KL Divergence
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../notes/11.%20Continuous%20Markov%20Processes%20and%20the%20Fokker%E2%80%93Planck%20Equation/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    11. Continuous Markov Processes and the Fokker–Planck Equation
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../notes/12.%20Brownian%20Motion%20and%20the%20Ornstein%E2%80%93Uhlenbeck%20Process/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    12. Brownian Motion and the Ornstein–Uhlenbeck Process
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../notes/13.%20Monte%20Carlo%20Sampling%20as%20a%20Stochastic%20Process/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    13. Monte Carlo Sampling as a Stochastic Process
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../notes/14.%20Hamiltonian%20Monte%20Carlo%20Sampling/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    14. Hamiltonian Monte Carlo Sampling
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../notes/15.%20Chemotaxis%2C%20Run-and-Tumble%20Motion%2C%20and%20the%20Keller%E2%80%93Segel%20Model/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    15. Chemotaxis, Run-and-Tumble Motion, and the Keller–Segel Model
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../notes/16.%20The%20Schnitzer%20Model%2C%20Anomalous%20Diffusion%2C%20and%20Motility%E2%80%91Induced%20Phase%20Separation/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    16. The Schnitzer Model, Anomalous Diffusion, and Motility‑Induced Phase Separation
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../notes/17.%20Langevin%20Equation%2C%20Brownian%20Particle%2C%20and%20the%20Fluctuation%E2%80%93Dissipation%20Theorem/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    17. Langevin Equation, Brownian Particle, and the Fluctuation–Dissipation Theorem
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../notes/18.%20Fokker%E2%80%93Planck%20Equation%20and%20the%20Smoluchowski%20Equation%20%E2%80%94%20From%20Random%20Trajectories%20to%20Probability%20Dynamics/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    18. Fokker–Planck Equation and the Smoluchowski Equation — From Random Trajectories to Probability Dynamics
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../notes/19.%20Path%20Integral%20Formulation%20of%20Stochastic%20Processes/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    19. Path Integral Formulation of Stochastic Processes
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../notes/20.%20Stochastic%20Differential%20Equations/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    20. Stochastic Differential Equations
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
    
      
        
        
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" checked>
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    中文笔记
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            中文笔记
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    首页
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../1.%20%E8%AF%BE%E7%A8%8B%E5%AF%BC%E8%AE%BA/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    1. 课程导论
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../2.%20%E7%AE%80%E5%8D%95%E9%9A%8F%E6%9C%BA%E6%B8%B8%E8%B5%B0/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    2. 简单随机游走
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../3.%20%E9%AB%98%E6%96%AF%E9%9A%8F%E6%9C%BA%E6%B8%B8%E8%B5%B0%E4%B8%8E%E6%B3%8A%E6%9D%BE%E8%BF%87%E7%A8%8B/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    3. 高斯随机游走与泊松过程
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../4.%20Gillespie%20%E7%AE%97%E6%B3%95%E3%80%81%E4%B8%BB%E6%96%B9%E7%A8%8B%E3%80%81%E7%94%9F%E6%88%90%E5%87%BD%E6%95%B0%E4%B8%8E%E7%A7%8D%E7%BE%A4%E5%8A%A8%E5%8A%9B%E5%AD%A6/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    4. Gillespie 算法、主方程、生成函数与种群动力学
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../5.%20%E7%A7%8D%E7%BE%A4%E5%8A%A8%E6%80%81%E5%AD%A6%EF%BC%9A%E7%BA%BF%E6%80%A7%E6%AD%BB%E4%BA%A1%E8%BF%87%E7%A8%8B%E4%B8%8ELotka-Volterra%20%E7%B3%BB%E7%BB%9F/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    5. 种群动态学：线性死亡过程与Lotka-Volterra 系统
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../6.%20%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E8%BF%87%E7%A8%8B%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%96%B9%E7%A8%8B%EF%BC%9A%E6%9F%A5%E6%99%AE%E6%9B%BC-%E7%A7%91%E5%B0%94%E8%8E%AB%E6%88%88%E7%BD%97%E5%A4%AB%E6%96%B9%E7%A8%8B/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    6. 马尔可夫过程的基本方程：查普曼-科尔莫戈罗夫方程
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../7.%20%E5%89%8D%E5%90%91%E4%B8%BB%E6%96%B9%E7%A8%8B%E4%B8%8EQ%E7%9F%A9%E9%98%B5/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    7. 前向主方程与Q矩阵
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../8.%20%E4%BD%A9%E9%BE%99-%E5%BC%97%E7%BD%97%E8%B4%9D%E5%B0%BC%E4%B9%8C%E6%96%AF%E5%AE%9A%E7%90%86%E3%80%81%E7%A8%B3%E6%80%81%E4%B8%8E%E7%BB%86%E8%87%B4%E5%B9%B3%E8%A1%A1/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    8. 佩龙-弗罗贝尼乌斯定理、稳态与细致平衡
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../9.%20%E9%9D%9E%E5%B9%B3%E8%A1%A1%E6%80%81%EF%BC%9A%E4%B8%8D%E5%8F%AF%E9%80%86%E6%80%A7%E4%B8%8E%E7%86%B5%E4%BA%A7%E7%94%9F%E7%9A%84%E6%8E%A8%E8%AE%BA/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    9. 非平衡态：不可逆性与熵产生的推论
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../10.%20%E5%9F%83%E4%BC%A6%E8%B4%B9%E6%96%AF%E7%89%B9%E6%A8%A1%E5%9E%8B%E3%80%81%E7%86%B5%E4%B8%8EKL%E6%95%A3%E5%BA%A6/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    10. 埃伦费斯特模型、熵与KL散度
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../11.%20%E8%BF%9E%E7%BB%AD%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E8%BF%87%E7%A8%8B%E4%B8%8E%E7%A6%8F%E5%85%8B-%E6%99%AE%E6%9C%97%E5%85%8B%E6%96%B9%E7%A8%8B/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    11. 连续马尔可夫过程与福克-普朗克方程
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../12.%20%E5%B8%83%E6%9C%97%E8%BF%90%E5%8A%A8%E4%B8%8E%E5%A5%A5%E6%81%A9%E6%96%AF%E5%9D%A6-%E4%B9%8C%E4%BC%A6%E8%B4%9D%E5%85%8B%E8%BF%87%E7%A8%8B/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    12. 布朗运动与奥恩斯坦-乌伦贝克过程
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    13. 作为随机过程的蒙特卡洛采样
    
  </span>
  

      </a>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../14.%20%E5%93%88%E5%AF%86%E5%B0%94%E9%A1%BF%E8%92%99%E7%89%B9%E5%8D%A1%E6%B4%9B%E9%87%87%E6%A0%B7/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    14. 哈密尔顿蒙特卡洛采样
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../15.%20%E8%B6%8B%E5%8C%96%E6%80%A7%E3%80%81%E8%B7%91%E5%8A%A8-%E7%BF%BB%E6%BB%9A%E8%BF%90%E5%8A%A8%E4%B8%8EKeller-Segel%E6%A8%A1%E5%9E%8B/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    15. 趋化性、跑动-翻滚运动与Keller-Segel模型
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../16.%20Schnitzer%E6%A8%A1%E5%9E%8B%E3%80%81%E5%8F%8D%E5%B8%B8%E6%89%A9%E6%95%A3%E4%B8%8E%E8%BF%90%E5%8A%A8%E8%AF%B1%E5%AF%BC%E7%9B%B8%E5%88%86%E7%A6%BB/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    16. Schnitzer模型、反常扩散与运动诱导相分离
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../17.%20%E6%9C%97%E4%B9%8B%E4%B8%87%E6%96%B9%E7%A8%8B%E3%80%81%E5%B8%83%E6%9C%97%E7%B2%92%E5%AD%90%E4%B8%8E%E6%B6%A8%E8%90%BD-%E8%80%97%E6%95%A3%E5%AE%9A%E7%90%86/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    17. 朗之万方程、布朗粒子与涨落-耗散定理
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../18.%20%E7%A6%8F%E5%85%8B-%E6%99%AE%E6%9C%97%E5%85%8B%E6%96%B9%E7%A8%8B%E4%B8%8E%E6%96%AF%E6%91%A9%E6%A3%B1%E9%9C%8D%E5%A4%AB%E6%96%AF%E5%9F%BA%E6%96%B9%E7%A8%8B%EF%BC%9A%E4%BB%8E%E9%9A%8F%E6%9C%BA%E8%BD%A8%E8%BF%B9%E5%88%B0%E6%A6%82%E7%8E%87%E5%8A%A8%E5%8A%9B%E5%AD%A6/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    18. 福克-普朗克方程与斯摩棱霍夫斯基方程：从随机轨迹到概率动力学
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../19.%20%E9%9A%8F%E6%9C%BA%E8%BF%87%E7%A8%8B%E7%9A%84%E8%B7%AF%E5%BE%84%E7%A7%AF%E5%88%86%E8%A1%A8%E8%BF%B0/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    19. 随机过程的路径积分表述
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../20.%20%E9%9A%8F%E6%9C%BA%E5%BE%AE%E5%88%86%E6%96%B9%E7%A8%8B/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    20. 随机微分方程
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../21.%20%E4%BC%8A%E8%97%A4%E7%A7%AF%E5%88%86%E4%B8%8E%E7%BB%9F%E4%B8%80%E7%9A%84%E9%9A%8F%E6%9C%BA%E8%BF%87%E7%A8%8B%E6%A1%86%E6%9E%B6/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    21. 伊藤积分与统一的随机过程框架
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../22.%20%E5%90%AB%E4%B9%98%E6%80%A7%E5%99%AA%E5%A3%B0%E7%B3%BB%E7%BB%9F%E7%9A%84%E8%B7%AF%E5%BE%84%E7%A7%AF%E5%88%86/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    22. 含乘性噪声系统的路径积分
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../23.%20%E4%BB%8E%E7%B2%97%E7%B2%92%E5%8C%96%E5%88%B0%E8%BF%9E%E7%BB%AD%E5%9C%BA%E8%AE%BA%E6%B6%A8%E8%90%BD%E5%8A%A8%E5%8A%9B%E5%AD%A6/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    23. 从粗粒化到连续场论涨落动力学
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../24.%20%E6%98%82%E8%90%A8%E6%A0%BC%E7%B3%BB%E6%95%B0%E3%80%81%E5%80%92%E6%98%93%E5%85%B3%E7%B3%BB%E4%B8%8E%E5%8A%A8%E6%80%81%E6%B6%A8%E8%90%BD-%E8%80%97%E6%95%A3%E5%AE%9A%E7%90%86/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    24. 昂萨格系数、倒易关系与动态涨落-耗散定理
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../25.%20%E6%A2%AF%E5%BA%A6%E5%8A%A8%E5%8A%9B%E5%AD%A6%E3%80%81%E7%9B%B8%E5%8F%98%E4%B8%8E%E5%BC%9B%E8%B1%AB/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    25. 梯度动力学、相变与弛豫
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../26.%20%E4%B8%B4%E7%95%8C%E6%85%A2%E5%8C%96%E3%80%81%E5%8A%A8%E6%80%81%E5%93%8D%E5%BA%94%E4%B8%8E%E5%AE%88%E6%81%92%E5%BE%8B/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    26. 临界慢化、动态响应与守恒律
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../27.%20%E7%AE%80%E5%8D%95%E6%B5%81%E4%BD%93%E3%80%81%E6%97%A0%E6%91%A9%E6%93%A6%E6%B5%81%E4%BD%93%E4%B8%8E%E6%AC%A7%E6%8B%89%E6%96%B9%E7%A8%8B%E7%9A%84%E6%B5%81%E4%BD%93%E5%8A%A8%E5%8A%9B%E5%AD%A6/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    27. 简单流体、无摩擦流体与欧拉方程的流体动力学
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../28.%20%E7%B2%98%E6%80%A7%E6%B5%81%E4%BD%93%E3%80%81%E7%BA%B3%E7%BB%B4-%E6%96%AF%E6%89%98%E5%85%8B%E6%96%AF%E6%96%B9%E7%A8%8B%E3%80%81%E7%86%B5%E5%B9%B3%E8%A1%A1%E4%B8%8E%E7%83%AD%E4%BC%A0%E5%AF%BC/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    28. 粘性流体、纳维-斯托克斯方程、熵平衡与热传导
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../29.%20%E4%B8%8D%E5%8F%AF%E9%80%86%E7%BA%BF%E6%80%A7%E7%83%AD%E5%8A%9B%E5%AD%A6%E4%B8%8E%E5%B9%B2%E6%80%A7%E6%89%A9%E6%95%A3%E7%B2%92%E5%AD%90%E7%B3%BB%E7%BB%9F/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    29. 不可逆线性热力学与干性扩散粒子系统
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../30.%20%E6%82%AC%E6%B5%AE%E5%9C%A8%E6%B5%81%E4%BD%93%E4%B8%AD%E7%9A%84%E5%B8%83%E6%9C%97%E7%B2%92%E5%AD%90%20%E2%80%94%20H%E6%A8%A1%E5%9E%8B/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    30. 悬浮在流体中的布朗粒子 — H模型
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../31.%20%E5%8A%A8%E6%80%81%E6%B3%9B%E5%87%BD%E3%80%81%E5%8A%A0%E6%80%A7%E5%99%AA%E5%A3%B0%E5%9C%BA%E8%AE%BA%E4%B8%8EOnsager-Machlup%E6%B3%9B%E5%87%BD/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    31. 动态泛函、加性噪声场论与Onsager-Machlup泛函
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../32.%20Janssen-De%20Dominicis%20%E5%93%8D%E5%BA%94%E6%B3%9B%E5%87%BD%E4%B8%8E%E6%B6%A8%E8%90%BD-%E8%80%97%E6%95%A3%E5%85%B3%E7%B3%BB/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    32. Janssen-De Dominicis 响应泛函与涨落-耗散关系
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../33.%20%E9%9D%9E%E5%B9%B3%E8%A1%A1%E5%8A%9F%E4%B8%8E%E6%B6%A8%E8%90%BD%E5%AE%9A%E7%90%86/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    33. 非平衡功与涨落定理
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../34.%20%E6%9C%89%E5%90%91%E6%B8%97%E6%B5%81%E3%80%81%E5%90%B8%E6%94%B6%E6%80%81%E4%B8%8E%E8%B0%B1%E6%96%B9%E6%B3%95/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    34. 有向渗流、吸收态与谱方法
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../35.%20%E4%B8%BB%E6%96%B9%E7%A8%8B%E7%9A%84%E8%B7%AF%E5%BE%84%E7%A7%AF%E5%88%86%E8%A1%A8%E7%A4%BA/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    35. 主方程的路径积分表示
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../36.%20%E7%9B%B8%E5%B9%B2%E6%80%81%E8%B7%AF%E5%BE%84%E7%A7%AF%E5%88%86%E3%80%81%E7%AE%97%E7%AC%A6%E4%BB%A3%E6%95%B0%E4%B8%8E%E8%99%9A%E5%99%AA%E5%A3%B0/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    36. 相干态路径积分、算符代数与虚噪声
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../37.%20Kramers-Moyal%20%E5%B1%95%E5%BC%80%E4%B8%8E%E8%B7%AF%E5%BE%84%E7%A7%AF%E5%88%86%E7%9A%84%E4%BD%8E%E5%99%AA%E5%A3%B0%E6%9E%81%E9%99%90/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    37. Kramers-Moyal 展开与路径积分的低噪声极限
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../38.%20%E5%A4%9A%E7%89%A9%E7%A7%8D%E8%B7%AF%E5%BE%84%E7%A7%AF%E5%88%86%E4%B8%8E%E5%BE%AA%E7%8E%AF%E7%AB%9E%E4%BA%89%E5%8A%A8%E5%8A%9B%E5%AD%A6/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    38. 多物种路径积分与循环竞争动力学
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../39.%20%E4%BB%8E%E7%B2%92%E5%AD%90%E8%B7%B3%E8%B7%83%E5%88%B0%E8%BF%9E%E7%BB%AD%E5%9C%BA%E8%AE%BA/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    39. 从粒子跳跃到连续场论
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../40.%20%E7%BB%9F%E4%B8%80%E7%9A%84%E5%9C%BA%E8%AE%BA%E6%A1%86%E6%9E%B6/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    40. 统一的场论框架
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


  
  


<h1 id="_1">引言:从理论分析到计算工具<a class="headerlink" href="#_1" title="Permanent link">&para;</a></h1>
<p>这节课由助教讲授。在过去的几讲中，Erwin Frey 教授已经帮我们建立了一个强大的理论框架来理解和描述随机过程。我们从马尔可夫过程的基本概念出发，推导了查普曼-科尔莫戈罗夫方程（Chapman-Kolmogorov equation），并进一步得到了主方程（Master Equation）和福克-普朗克方程（Fokker-Planck equation）。我们还深入探讨了系统的稳态、细致平衡（detailed balance）条件以及佩龙-弗罗贝尼乌斯定理（Perron-Frobenius theorem），这些都为我们理解系统如何达到并维持其平衡态提供了深刻的见解。</p>
<p><img alt="课堂板书截图" src="../../../assets/images/remote/8991dfc8-9e11-4011-a9e6-84f1507556da-ed64b1d80a.jpg" /></p>
<p>到目前为止,我们的视角主要是<strong>分析性</strong>的:给定一个随机过程(由其转移速率定义),我们分析它的行为,比如它的稳态分布是什么。在这节课中,我们将进行转变,将视角从分析转向<strong>综合</strong>与<strong>应用</strong>。我们将展示如何将整个随机过程的理论框架,特别是马尔可夫链的概念,转变为一种强大的计算工具,用于解决一个在所有科学领域都至关重要的问题:<strong>统计推断(statistical inference)</strong>,即如何从数据中学习模型的参数。</p>
<p>通过巧妙地"设计"一个马尔可夫过程,使其稳态恰好是我们想要的目标概率分布,我们就可以生成该分布的样本,从而解决那些在解析上无法处理的复杂积分问题。这个方法被称为马尔可夫链蒙特卡洛(Markov Chain Monte Carlo, MCMC),它彻底改变了贝叶斯统计学和许多依赖于计算建模的科学领域。</p>
<h1 id="1">1. 问题的提出:从真实世界数据中推断模型<a class="headerlink" href="#1" title="Permanent link">&para;</a></h1>
<p>科学研究的核心任务之一是从观测数据中构建和验证数学模型。一个好的模型不仅能解释现有数据,还能对未来做出预测。然而,一个模型的预测能力完全取决于其参数的取值。那么,我们如何利用实验或观测数据来确定这些未知参数呢?</p>
<h2 id="11">1.1  一个经典的生态系统:猞猁与雪兔<a class="headerlink" href="#11" title="Permanent link">&para;</a></h2>
<p>为了让问题具体化,让我们来看一个生态学中非常经典的例子:加拿大猞猁(lynx,捕食者)和雪兔(hare,猎物)的种群动态。哈德逊湾公司(Hudson Bay Company)在1900年至1920年间记录了收集到的这两种动物的毛皮数量,这些数据被认为是它们各自种群数量的可靠指标。</p>
<p><img alt="课堂PPT截图" src="../../../assets/images/remote/d8a6f6e7-4ac0-4fd3-8c00-720a1ca45ea7-a946bb2c01.jpg" /></p>
<p><img alt="课堂PPT截图" src="../../../assets/images/remote/bbd18f78-ebf7-462a-923a-e58b7d4eda23-ea96baa5f4.jpg" /></p>
<p>将这些数据绘制成图表,我们可以清晰地看到两个种群数量随时间的周期性振荡,并且捕食者(猞猁)的种群高峰总是略微滞后于猎物(雪兔)的种群高峰。</p>
<p><img alt="课堂PPT截图" src="../../../assets/images/remote/510942e3-5a73-482e-8509-9ffe66e18509-55827117d3.png" /></p>
<p>面对这样的数据,一个自然而然的科学问题是:<strong>我们能否找到一个数学模型来描述并预测这种周期性行为?</strong> 更进一步,我们能否从这些具体的数据点中,推断出控制这个生态系统动态的"法则"?</p>
<h2 id="12-">1.2 洛特卡-沃尔泰拉模型:一个数学描述<a class="headerlink" href="#12-" title="Permanent link">&para;</a></h2>
<p>为了描述这种捕食者-猎物系统,一个著名的数学模型是<strong>洛特卡-沃尔泰拉(Lotka-Volterra)方程。</strong>该模型用一组耦合的常微分方程(ODEs)来描述两个种群数量的变化。</p>
<p>设 <span class="arithmatex">\(x\)</span> 为雪兔(猎物)的种群数量, <span class="arithmatex">\(y\)</span> 为猞猁(捕食者)的种群数量。该模型可以写为:</p>
<div class="arithmatex">\[
\frac{dx}{dt} = \alpha x - \beta xy \quad \text{(雪兔)}
\]</div>
<div class="arithmatex">\[
\frac{dy}{dt} = -\gamma y + \delta xy \quad \text{(猞猁)}
\]</div>
<p>让我们剖析这个模型中的每一项,理解其背后的生物学意义:</p>
<ul>
<li>
<p><span class="arithmatex">\(\alpha x\)</span>: 这一项代表雪兔的自然增长。在没有捕食者的情况下(<span class="arithmatex">\(y=0\)</span>),雪兔种群会以速率 <span class="arithmatex">\(\alpha\)</span> 进行指数增长。因此,<span class="arithmatex">\(\alpha\)</span> 可以被看作是雪兔的"出生率"。</p>
</li>
<li>
<p><span class="arithmatex">\(-\beta xy\)</span>: 这一项描述了雪兔因被猞猁捕食而导致的数量减少。捕食事件发生的频率正比于雪兔和猞猁相遇的频率,而相遇频率又可以近似为它们种群数量的乘积 <span class="arithmatex">\(xy\)</span>。参数 <span class="arithmatex">\(\beta\)</span> 代表了捕食的"成功率"或"捕食效率"。</p>
</li>
<li>
<p><span class="arithmatex">\(-\gamma y\)</span>: 这一项代表猞猁的自然死亡。在没有食物(雪兔)的情况下(<span class="arithmatex">\(x=0\)</span>),猞猁种群会因为饥饿、疾病或种内竞争而以速率 <span class="arithmatex">\(\gamma\)</span> 指数衰减。因此,<span class="arithmatex">\(\gamma\)</span> 可以被看作是猞猁的"死亡率"。</p>
</li>
<li>
<p><span class="arithmatex">\(+\delta xy\)</span>: 这一项描述了猞猁种群因捕食雪兔而获得的增长。同样,这个增长率也正比于相遇频率 <span class="arithmatex">\(xy\)</span>。参数 <span class="arithmatex">\(\delta\)</span> 代表了猞猁将捕食到的雪兔转化为自身繁殖的"转化效率"。</p>
</li>
</ul>
<p>现在,我们的问题变得更加精确了。描述这个系统动态的"法则"被封装在了这四个参数 <span class="arithmatex">\(\theta=\{\alpha,\beta,\gamma,\delta\}\)</span> 中。我们的任务就是,给定观测数据 <span class="arithmatex">\(D\)</span>(即那张时间序列图表),如何推断出这组参数 <span class="arithmatex">\(\theta\)</span> 最可能的值?这便是<strong>参数推断(parameter inference)</strong>的核心问题。</p>
<p>这个过程是从混乱的真实世界观测(毛皮数据)到抽象的数学模型(微分方程)的飞跃。洛特卡-沃尔泰拉模型无疑是对复杂生态系统的简化,但它抓住了捕食者与猎物之间相互作用的核心反馈循环。<strong>挑战不仅在于求解这组方程,更在于找到方程的特定"版本"(即最合适的参数值),</strong>使其能够最好地代表我们所观测到的真实世界。这为我们接下来引入概率方法奠定了基础。</p>
<h1 id="2">2. 贝叶斯框架:系统性的推断方法<a class="headerlink" href="#2" title="Permanent link">&para;</a></h1>
<p>如何系统地从数据中学习参数 <span class="arithmatex">\(\theta\)</span>?贝叶斯推断(Bayesian inference)为我们提供了一个基于概率论的、逻辑严谨的框架来解决这个问题。它本质上是一种在获得新证据后更新我们对事物信念程度的方法。</p>
<h2 id="21">2.1 贝叶斯定理的引入<a class="headerlink" href="#21" title="Permanent link">&para;</a></h2>
<p>贝叶斯推断的核心工具是贝叶斯定理(Bayes' Theorem)。它将我们关心的量联系在一起,其形式如下:</p>
<div class="arithmatex">\[
p(\theta|D) = \frac{p(D|\theta)p(\theta)}{p(D)}
\]</div>
<p>这个公式看起来很简单,但它蕴含了深刻的逻辑。它告诉我们如何将关于参数的先验知识与数据中包含的信息结合起来,从而得到更新后的知识。</p>
<h2 id="22">2.2 解构贝叶斯定理<a class="headerlink" href="#22" title="Permanent link">&para;</a></h2>
<p>为了在我们的猞猁-雪兔问题中应用这个定理,我们需要理解公式中的每一个组成部分。</p>
<p>贝叶斯推断的视角与传统的"最佳拟合"方法(如最小二乘法)有着根本性的不同。传统方法可能会给我们一组唯一的"最佳"参数值。而贝叶斯方法则告诉我们:"不存在唯一正确的 <span class="arithmatex">\(\theta\)</span>。相反,这里有一幅可能性的图景。参数空间中的这个区域非常可能,而另一个区域则非常不可能。"</p>
<p>这种概率性的视角非常强大。它允许我们回答更深入的问题,例如:"雪兔出生率 <span class="arithmatex">\(\alpha\)</span> 介于0.5到0.6之间的概率是多少?"或者"捕食率 <span class="arithmatex">\(\beta\)</span> 和猞猁死亡率 <span class="arithmatex">\(\gamma\)</span> 是否相关?"。<strong>这是一种从确定性思维到概率性思维的深刻转变,它更诚实地反映了我们在面对有限数据时的不确定性。</strong></p>
<h1 id="3">3. 计算瓶颈:高维积分的挑战<a class="headerlink" href="#3" title="Permanent link">&para;</a></h1>
<p>拥有后验分布 <span class="arithmatex">\(p(\theta|D)\)</span> 理论上解决了推断问题,但在实践中,我们通常需要从这个分布中提取一些摘要信息,比如参数的期望值(平均值)或方差(不确定性的大小)。</p>
<h2 id="31">3.1 从分布到期望值<a class="headerlink" href="#31" title="Permanent link">&para;</a></h2>
<p>要计算某个关于参数的函数 <span class="arithmatex">\(f(\theta)\)</span> 的期望值(例如,<span class="arithmatex">\(f(\theta)=\alpha\)</span> 就是为了计算参数 <span class="arithmatex">\(\alpha\)</span> 的平均值),我们需要求解如下积分:</p>
<div class="arithmatex">\[
\langle f(\theta) \rangle = \int f(\theta) p(\theta|D) d\theta^n
\]</div>
<p>这里的 <span class="arithmatex">\(n\)</span> 是参数的数量(在我们的例子中,<span class="arithmatex">\(n=4\)</span>)。这个积分是在整个 <span class="arithmatex">\(n\)</span> 维参数空间上进行的。</p>
<p>此外,我们还需要计算归一化常数,即证据 <span class="arithmatex">\(p(D)\)</span>,它本身也是一个同样形式的积分:</p>
<div class="arithmatex">\[
p(D) = \int p(D|\theta)p(\theta) d\theta
\]</div>
<p>这个积分通常是贝叶斯推断中最困难的部分。</p>
<h2 id="32">3.2 维度灾难<a class="headerlink" href="#32" title="Permanent link">&para;</a></h2>
<p>为什么这些积分如此难以计算?原因在于所谓的<strong>维度灾难(Curse of Dimensionality)。</strong></p>
<p>一种最直观的数值积分方法是"网格法":我们将每个参数维度划分成若干个离散的格点,然后在这些格点上计算被积函数的值,最后加权求和。</p>
<p>让我们看看为什么这种方法会迅速失效。假设我们对每个参数维度只取10个格点。</p>
<ul>
<li>
<p>对于1个参数(1D),我们需要计算 <span class="arithmatex">\(10^1=10\)</span> 次。</p>
</li>
<li>
<p>对于2个参数(2D),我们需要计算 <span class="arithmatex">\(10^2=100\)</span> 次。</p>
</li>
<li>
<p>对于我们的4参数洛特卡-沃尔泰拉模型(4D),我们需要计算 <span class="arithmatex">\(10^4=10,000\)</span> 次。</p>
</li>
<li>
<p>对于一个有20个参数的更复杂的模型,我们需要计算 <span class="arithmatex">\(10^{20}\)</span> 次!这个数字已经远远超出了任何现代计算机的处理能力。</p>
</li>
</ul>
<p>计算量随维度指数增长,这使得网格法在高维空间中完全不可行。</p>
<p>更深层次的问题在于,高维空间的行为与我们的低维直觉相悖。正如助教在黑板上的草图所示,后验概率分布 <span class="arithmatex">\(p(\theta|D)\)</span> 的"质量"通常集中在参数空间中一个非常微小的、形状不规则的区域内。而广阔的参数空间中的绝大部分区域,其概率密度几乎为零。</p>
<p><img alt="课堂板书截图" src="../../../assets/images/remote/3d4c0c96-092b-4d24-838f-fca8fa077a21-25de69215c.png" /></p>
<p>网格法是"盲目"的,它会均匀地探索整个参数空间。这意味着它会花费绝大部分的计算资源去评估那些 <span class="arithmatex">\(p(\theta|D) \approx 0\)</span> 的点。这些点的函数值对最终积分的贡献几乎为零,因此这些计算完全是浪费。</p>
<p>"维度灾难"不仅仅是计算速度变慢的问题,它是一个根本性的尺度问题,使得一整类简单直观的算法变得毫无用处。问题归结为<strong>搜索效率</strong>:我们正在一个指数级增长的巨大空间中,寻找一个微小的、我们事先不知道其位置的"重要"区域。这迫使我们必须彻底改变策略。如果我们无法探索整个空间,那么我们是否能被某种方法<strong>引导</strong>,只去探索那些重要的区域呢?</p>
<h1 id="4">4. 新策略:蒙特卡洛积分<a class="headerlink" href="#4" title="Permanent link">&para;</a></h1>
<p>面对高维积分的挑战,我们需要一种更智能的方法。<strong>蒙特卡洛积分(Monte Carlo Integration)</strong>提供了一个绝妙的解决方案。它用随机采样代替了确定性的网格划分。</p>
<h2 id="41">4.1 大数定律的威力<a class="headerlink" href="#41" title="Permanent link">&para;</a></h2>
<p>蒙特卡洛积分的核心思想基于大数定律。它将积分的计算近似为一个样本均值的计算:</p>
<div class="arithmatex">\[
\langle f(\theta) \rangle = \int f(\theta) p(\theta|D) d\theta \approx \frac{1}{N} \sum_{i=1}^{N} f(\theta^{(i)})
\]</div>
<p>这个公式看起来非常简单,就像是计算 <span class="arithmatex">\(f(\theta)\)</span> 的普通平均值。但它的魔力在于这些样本 <span class="arithmatex">\(\theta^{(i)}\)</span> 是如何生成的。</p>
<h2 id="42">4.2 重要性采样:关键的洞见<a class="headerlink" href="#42" title="Permanent link">&para;</a></h2>
<p>为了使这个近似有效且高效,这些样本 <span class="arithmatex">\(\theta^{(i)}\)</span> 必须是<strong>从目标概率分布 <span class="arithmatex">\(p(\theta|D)\)</span> 本身中抽取出来的</strong>。</p>
<p>这便是"重要性采样"(Importance Sampling)的核心思想。通过直接从 <span class="arithmatex">\(p(\theta|D)\)</span> 中抽样,我们自然而然地将计算精力集中在了概率密度高的区域——也就是对积分贡献最大的区域。我们不再浪费时间在参数空间中那些概率为零的"荒漠"里。样本点会以与其概率成正比的频率出现,这正是我们所需要的。</p>
<p>这个转变是革命性的。我们已经成功地将一个棘手的积分问题,转化为了一个同样具有挑战性但可以解决的采样问题:</p>
<p>我们如何从一个我们甚至无法归一化(因为不知道 <span class="arithmatex">\(p(D)\)</span>)的、复杂的、高维的概率分布 <span class="arithmatex">\(p(\theta|D)\)</span> 中生成随机样本?</p>
<p>蒙特卡洛积分代表了一种从确定性、穷举式计算到近似性、随机性模拟的范式转变。它拥抱随机性,并将其作为克服维度灾难的有力工具。它解决了效率问题,因为我们不再需要预先知道重要区域在哪里,采样过程会自动发现它。现在,我们需要的不再是一个积分器,而是一个<strong>采样器</strong>。这为我们引入整个随机过程理论体系提供了最终的动机。</p>
<h1 id="5-mcmc">5. 通过随机过程生成样本:马尔可夫链蒙特卡洛(MCMC)<a class="headerlink" href="#5-mcmc" title="Permanent link">&para;</a></h1>
<p>如何构建一个能够从任意复杂分布 <span class="arithmatex">\(p(\theta|D)\)</span> 中采样的机器呢?这就回到了这节课的核心——马尔可夫链。</p>
<h2 id="51">5.1 回顾我们的工具箱:马尔可夫链与稳态分布<a class="headerlink" href="#51" title="Permanent link">&para;</a></h2>
<p>让我们回顾一下前几讲(特别是第6-8讲)的核心概念:</p>
<ul>
<li>
<p><strong>马尔可夫链</strong>:一个"无记忆"的随机过程,其未来的状态只依赖于当前状态,而与过去无关。</p>
</li>
<li>
<p><strong>稳态分布(Stationary Distribution)</strong> <span class="arithmatex">\(\pi\)</span>:在某些条件下(遍历性),一个马尔可夫链在运行足够长时间后,其状态的概率分布会收敛到一个不再变化的极限分布,即稳态分布。</p>
</li>
<li>
<p><strong>佩龙-弗罗贝尼乌斯定理</strong>:为一大类系统的稳态的存在性和唯一性提供了数学保证。</p>
</li>
<li>
<p><strong>细致平衡条件(Detailed Balance)</strong>:这是一个确保系统能够收敛到稳态 <span class="arithmatex">\(\pi\)</span> 的<strong>充分条件</strong>。其数学表达式为:<span class="arithmatex">\(\pi(\theta)W(\theta'|\theta) = \pi(\theta')W(\theta|\theta')\)</span>,其中 <span class="arithmatex">\(W(\theta'|\theta)\)</span> 是从状态 <span class="arithmatex">\(\theta\)</span> 转移到状态 <span class="arithmatex">\(\theta'\)</span> 的转移概率。</p>
</li>
</ul>
<h2 id="52-mcmc">5.2 MCMC的核心思想<a class="headerlink" href="#52-mcmc" title="Permanent link">&para;</a></h2>
<p>现在,我们揭示MCMC方法的核心思想:<strong>如果我们能够设计一个马尔可夫链,使其唯一的稳态分布 <span class="arithmatex">\(\pi\)</span> 恰好就是我们想要采样的目标后验分布 <span class="arithmatex">\(p(\theta|D)\)</span>,那会怎么样?</strong></p>
<p>如果能做到这一点,那么采样过程将变得异常简单:</p>
<ol>
<li>
<p>在参数空间中随机选择一个初始点 <span class="arithmatex">\(\theta^{(0)}\)</span>。</p>
</li>
<li>
<p>让这个马尔可夫链根据其转移规则不断进行状态转移(随机游走)。</p>
</li>
<li>
<p>运行足够长的时间,让链"忘记"其初始状态,收敛到其稳态分布。这个初始阶段被称为"<strong>燃烧期</strong>"(burn-in)。</p>
</li>
<li>
<p>在燃烧期结束后,我们开始记录链所访问的状态序列 <span class="arithmatex">\(\{\theta^{(i)}\}\)</span>。</p>
</li>
</ol>
<p><strong>根据稳态分布的定义,这个序列 <span class="arithmatex">\(\{\theta^{(i)}\}\)</span> 就是我们梦寐以求的、从目标分布 <span class="arithmatex">\(p(\theta|D)\)</span> 中抽取的一系列样本!我们成功地构建了一个采样器。</strong></p>
<p>这是本讲座概念上的核心。MCMC将描述性的随机过程理论转变为一个指令性的、可操作的计算引擎。我们不再仅仅是分析一个给定物理系统的平衡态;我们是在<strong>工程化地设计</strong>一个计算"系统"(马尔可夫链),使其平衡态成为对我们有用的工具(后验分布)。</p>
<p>以前的讲座教会我们:"如果你有一个转移矩阵 <span class="arithmatex">\(W\)</span>,这里是如何找到它的稳态分布 <span class="arithmatex">\(\pi\)</span>。" 而MCMC将这个问题完全颠倒过来:<strong>"我们有一个想要的目标稳态分布 <span class="arithmatex">\(\pi=p(\theta|D)\)</span>,我们如何能找到一个可以产生它的转移矩阵 <span class="arithmatex">\(W\)</span>?" </strong>这是一次从分析到综合的飞跃。马尔可夫链理论(特别是细致平衡条件)为我们构建这样的 <span class="arithmatex">\(W\)</span> 提供了蓝图。</p>
<h1 id="6-metropolis-hastings">6. Metropolis-Hastings算法:一个实用的配方<a class="headerlink" href="#6-metropolis-hastings" title="Permanent link">&para;</a></h1>
<p>那么,具体该如何构建满足条件的转移规则 <span class="arithmatex">\(W\)</span> 呢?<strong>Metropolis-Hastings算法</strong>提供了一个通用且强大的配方,可以为任意目标分布构建马尔可夫链。</p>
<p>Metropolis-Hastings 算法是现代计算统计学和物理学中最重要的算法之一,其发展横跨了二十世纪中叶的两次关键创新。这个算法最初的版本由 Nicholas Metropolis 及其合作者(包括 Arianna Rosenbluth, Marshall Rosenbluth, Augusta Teller, 和 Edward Teller)在1953年提出,当时主要用于解决物理学中高维系统的状态方程计算问题,其核心思想是构建一个马尔可夫链,使其最终的稳定分布是我们想要抽样的目标分布,最初的版本仅限于对称的提议分布。随后,在1970年,统计学家 W. K. Hastings 将该算法推广到了非对称提议分布的情况,极大地扩展了其适用范围,形成了我们今天所知的 Metropolis-Hastings 算法。</p>
<p>该算法的应用极为广泛,尤其在贝叶斯统计中扮演着核心角色。当一个模型的后验概率分布形式复杂、维度很高,以至于无法直接进行解析计算或抽样时,Metropolis-Hastings 算法便提供了一个强大的数值模拟工具。具体应用包括但不限于:在机器学习中进行贝叶斯推断,估计复杂模型的参数;在计算生物学中用于系统发育树的构建;在物理学中模拟多粒子系统的行为;在金融领域用于风险建模和期权定价。可以说,任何需要从一个难以直接处理的概率分布中进行抽样的科学和工程领域,都能看到 Metropolis-Hastings 算法的身影。</p>
<h2 id="61">6.1 算法步骤<a class="headerlink" href="#61" title="Permanent link">&para;</a></h2>
<p>该算法的流程非常清晰,可以分为两个阶段:<strong>提议</strong>和<strong>接受/拒绝</strong>。</p>
<p><strong>1. 初始化:</strong>在参数空间中任意选择一个初始状态 <span class="arithmatex">\(\theta^{(0)}\)</span>。</p>
<p><strong>2. 迭代:对于 <span class="arithmatex">\(i=1,2,...,N\)</span>:</strong></p>
<p>a. <strong>提议 (Propose):</strong>根据一个提议分布(proposal distribution) <span class="arithmatex">\(q(\theta'|\theta^{(i-1)})\)</span>,从当前状态 <span class="arithmatex">\(\theta^{(i-1)}\)</span> 出发,生成一个候选状态 <span class="arithmatex">\(\theta'\)</span>。这个提议分布可以很简单,例如一个以当前状态为中心的正态分布。</p>
<p>b. <strong>计算接受率 (Accept/Reject):</strong>计算接受这个提议的概率 <span class="arithmatex">\(A(\theta'|\theta^{(i-1)})\)</span>。Metropolis-Hastings算法给出的接受率为:</p>
<div class="arithmatex">\[
A(\theta' | \theta) = \min\left(1, \frac{p(\theta')q(\theta|\theta')}{p(\theta)q(\theta'|\theta)}\right)
\]</div>
<p>注意,我们在这里用 <span class="arithmatex">\(p(\theta)\)</span> 来代表我们的目标分布 <span class="arithmatex">\(p(\theta|D)\)</span>。</p>
<p>c. <strong>决策:</strong>从 <span class="arithmatex">\([0,1]\)</span> 的均匀分布中抽取一个随机数 <span class="arithmatex">\(u\)</span>。</p>
<p>如果 $u&lt;A $,则接受这个提议,令新状态 <span class="arithmatex">\(\theta^{(i)}=\theta'\)</span>。</p>
<p>否则,拒绝这个提议,令新状态 <span class="arithmatex">\(\theta^{(i)}=\theta^{(i-1)}\)</span>(即停留在原地)。</p>
<p>通过重复这个过程,我们就得到了一个马尔可夫链样本序列 <span class="arithmatex">\(\{\theta^{(0)},\theta^{(1)},...,\theta^{(N)}\}\)</span>。</p>
<h2 id="62">6.2 为什么它有效:强制满足细致平衡<a class="headerlink" href="#62" title="Permanent link">&para;</a></h2>
<p>这个算法的精妙之处在于,上述定义的接受率 <span class="arithmatex">\(A\)</span> 恰好能保证整个过程满足细致平衡条件,从而确保链的稳态分布就是我们的目标分布 <span class="arithmatex">\(p(\theta)\)</span>。</p>
<p>让我们来理解接受率公式中的两个关键比率:</p>
<ul>
<li>
<p><span class="arithmatex">\(\frac{p(\theta')}{p(\theta)}\)</span>:这是目标分布在提议点和当前点的概率密度之比。如果提议的新点 <span class="arithmatex">\(\theta'\)</span> 位于一个概率更高的区域(<span class="arithmatex">\(p(\theta')&gt;p(\theta)\)</span>),那么这个比率大于1,接受率 <span class="arithmatex">\(A\)</span> 将为1,我们总是会接受这个移动。这保证了链倾向于向高概率区域移动。如果提议点概率更低,我们则以一定的概率接受它,这使得链能够探索整个分布,而不仅仅是停留在概率的最高峰。</p>
</li>
<li>
<p><span class="arithmatex">\(\frac{q(\theta|\theta')}{q(\theta'|\theta)}\)</span>:这是提议分布的修正因子。它用于修正任何可能存在的"提议偏见"。如果从 <span class="arithmatex">\(\theta\)</span> 提议 <span class="arithmatex">\(\theta'\)</span> 比从 <span class="arithmatex">\(\theta'\)</span> 提议 <span class="arithmatex">\(\theta\)</span> 更容易,这个比率就会对此进行补偿,确保探索是公平的。在许多实际应用中,我们会选择一个<strong>对称的提议分布</strong>,例如正态分布,此时 <span class="arithmatex">\(q(\theta|\theta')=q(\theta'|\theta)\)</span>,这个修正因子就等于1。算法简化为原始的<strong>Metropolis算法</strong>,其接受率为 <span class="arithmatex">\(A=\min(1,\frac{p(\theta')}{p(\theta)})\)</span>。</p>
</li>
</ul>
<p>这个算法还有一个巨大的实践优势:请注意,在接受率的计算中,我们只需要目标分布的<strong>比率</strong> <span class="arithmatex">\(\frac{p(\theta')}{p(\theta)}\)</span>。这意味着,对于贝叶斯推断 <span class="arithmatex">\(p(\theta|D)=\frac{p(D|\theta)p(\theta)}{p(D)}\)</span>,那个极其难以计算的归一化常数(证据)<span class="arithmatex">\(p(D)\)</span> 在比率中被完美地消掉了!</p>
<div class="arithmatex">\[
\frac{p(\theta|D)}{p(\theta'|D)} = \frac{p(D|\theta)p(\theta)/p(D)}{p(D|\theta')p(\theta')/p(D)} = \frac{p(D|\theta)p(\theta)}{p(D|\theta')p(\theta')}
\]</div>
<p>我们只需要能够计算似然 <span class="arithmatex">\(p(D|\theta)\)</span> 和先验 <span class="arithmatex">\(p(\theta)\)</span> 即可,而这通常是可行的。这正是MCMC方法如此成功和普及的关键原因之一。它巧妙地绕过了贝叶斯推断中最大的计算障碍。</p>
<p>算法的结构可以看作一个"提议-修正"的智能系统。<strong>提议分布</strong> <span class="arithmatex">\(q\)</span> 负责探索,它可以是简单甚至是"盲目"的。而<strong>接受概率</strong> <span class="arithmatex">\(A\)</span> 则是智能的过滤器,它通过强制执行细致平衡这一物理法则,确保了无论探索过程如何,最终的结果都会收敛到正确的目标分布。</p>
<h1 id="7-mcmc-">7. 使用MCMC求解洛特卡-沃尔泰拉模型参数<a class="headerlink" href="#7-mcmc-" title="Permanent link">&para;</a></h1>
<p>现在,我们将理论付诸实践。我们回到讲座最初的例子:猞猁与雪兔的种群动态。我们将使用Metropolis-Hastings MCMC算法,根据哈德逊湾公司提供的数据,来推断出最可能描述这个生态系统的洛特卡-沃尔泰拉模型的四个参数 (<span class="arithmatex">\(\alpha, \beta, \gamma, \delta\)</span>)。</p>
<p>这个案例的挑战在于,洛特卡-沃尔泰拉模型是一组微分方程,没有简单的解析解。对于给定的参数,我们需要通过数值积分来得到种群数量的演化曲线。这使得后验概率分布 <span class="arithmatex">\(p(\theta|D)\)</span> 变得异常复杂,无法直接计算或采样。这正是MCMC大显身手的场景。</p>
<h2 id="71">7.1 建模思路<a class="headerlink" href="#71" title="Permanent link">&para;</a></h2>
<ol>
<li><strong>模型</strong>: 洛特卡-沃尔泰拉微分方程组。</li>
<li><strong>数据</strong>: 1900-1920年的雪兔(H)和猞猁(L)数量。</li>
<li><strong>目标</strong>: 求解后验概率分布 <span class="arithmatex">\(p(\alpha, \beta, \gamma, \delta | \text{数据})\)</span>。</li>
<li><strong>方法</strong>: 构建一个Metropolis-Hastings采样器。<ul>
<li><strong>状态空间</strong>: 四维参数空间 <span class="arithmatex">\((\alpha, \beta, \gamma, \delta)\)</span>。</li>
<li><strong>目标分布</strong>: 后验概率 <span class="arithmatex">\(p(\theta|D) \propto p(D|\theta)p(\theta)\)</span>。<ul>
<li><strong>似然函数 <span class="arithmatex">\(p(D|\theta)\)</span></strong>: 我们假设观测数据与模型预测之间的误差服从对数正态分布。这意味着我们会计算模型在给定参数<span class="arithmatex">\(\theta\)</span>下预测的种群数量,并将其与真实数据进行比较,计算其概率。</li>
<li><strong>先验分布 <span class="arithmatex">\(p(\theta)\)</span></strong>: 由于我们对参数没有太多先验知识,我们选择一个无信息的、宽泛的均匀分布或正态分布作为先验。</li>
</ul>
</li>
<li><strong>提议分布 <span class="arithmatex">\(q(\theta'|\theta)\)</span></strong>: 我们采用一个简单的随机游走策略。在当前参数点<span class="arithmatex">\(\theta\)</span>附近,通过添加一个小的随机扰动(例如,从一个多元正态分布中采样)来生成新的提议点<span class="arithmatex">\(\theta'\)</span>。</li>
</ul>
</li>
</ol>
<h2 id="72-python"><strong>7.2 Python 实现</strong><a class="headerlink" href="#72-python" title="Permanent link">&para;</a></h2>
<p>下面的代码将完整地展示如何实现这个MCMC过程。</p>
<p><div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">scipy.integrate</span><span class="w"> </span><span class="kn">import</span> <span class="n">odeint</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">scipy.stats</span><span class="w"> </span><span class="kn">import</span> <span class="n">norm</span>

<span class="c1"># 1. Load data</span>
<span class="c1"># Data source: https://github.com/stan-dev/example-models</span>
<span class="c1"># Year, Lynx (x1000), Hare (x1000)</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span>
    <span class="p">[</span><span class="mi">1900</span><span class="p">,</span> <span class="mf">4.0</span><span class="p">,</span> <span class="mf">30.0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1901</span><span class="p">,</span> <span class="mf">6.1</span><span class="p">,</span> <span class="mf">47.2</span><span class="p">],</span> <span class="p">[</span><span class="mi">1902</span><span class="p">,</span> <span class="mf">9.8</span><span class="p">,</span> <span class="mf">70.2</span><span class="p">],</span>
    <span class="p">[</span><span class="mi">1903</span><span class="p">,</span> <span class="mf">35.2</span><span class="p">,</span> <span class="mf">77.4</span><span class="p">],</span> <span class="p">[</span><span class="mi">1904</span><span class="p">,</span> <span class="mf">59.4</span><span class="p">,</span> <span class="mf">36.3</span><span class="p">],</span> <span class="p">[</span><span class="mi">1905</span><span class="p">,</span> <span class="mf">41.7</span><span class="p">,</span> <span class="mf">20.6</span><span class="p">],</span>
    <span class="p">[</span><span class="mi">1906</span><span class="p">,</span> <span class="mf">19.0</span><span class="p">,</span> <span class="mf">18.1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1907</span><span class="p">,</span> <span class="mf">13.0</span><span class="p">,</span> <span class="mf">21.4</span><span class="p">],</span> <span class="p">[</span><span class="mi">1908</span><span class="p">,</span> <span class="mf">8.3</span><span class="p">,</span> <span class="mf">22.0</span><span class="p">],</span>
    <span class="p">[</span><span class="mi">1909</span><span class="p">,</span> <span class="mf">9.1</span><span class="p">,</span> <span class="mf">25.4</span><span class="p">],</span> <span class="p">[</span><span class="mi">1910</span><span class="p">,</span> <span class="mf">7.4</span><span class="p">,</span> <span class="mf">27.1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1911</span><span class="p">,</span> <span class="mf">8.0</span><span class="p">,</span> <span class="mf">40.3</span><span class="p">],</span>
    <span class="p">[</span><span class="mi">1912</span><span class="p">,</span> <span class="mf">12.3</span><span class="p">,</span> <span class="mf">57.0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1913</span><span class="p">,</span> <span class="mf">19.5</span><span class="p">,</span> <span class="mf">76.6</span><span class="p">],</span> <span class="p">[</span><span class="mi">1914</span><span class="p">,</span> <span class="mf">45.7</span><span class="p">,</span> <span class="mf">52.3</span><span class="p">],</span>
    <span class="p">[</span><span class="mi">1915</span><span class="p">,</span> <span class="mf">51.1</span><span class="p">,</span> <span class="mf">19.5</span><span class="p">],</span> <span class="p">[</span><span class="mi">1916</span><span class="p">,</span> <span class="mf">29.7</span><span class="p">,</span> <span class="mf">11.2</span><span class="p">],</span> <span class="p">[</span><span class="mi">1917</span><span class="p">,</span> <span class="mf">15.8</span><span class="p">,</span> <span class="mf">7.6</span><span class="p">],</span>
    <span class="p">[</span><span class="mi">1918</span><span class="p">,</span> <span class="mf">9.7</span><span class="p">,</span> <span class="mf">14.6</span><span class="p">],</span> <span class="p">[</span><span class="mi">1919</span><span class="p">,</span> <span class="mf">10.1</span><span class="p">,</span> <span class="mf">16.2</span><span class="p">],</span> <span class="p">[</span><span class="mi">1920</span><span class="p">,</span> <span class="mf">8.6</span><span class="p">,</span> <span class="mf">24.7</span><span class="p">]</span>
<span class="p">])</span>
<span class="n">years</span> <span class="o">=</span> <span class="n">data</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span>
<span class="n">lynx_data</span> <span class="o">=</span> <span class="n">data</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span>
<span class="n">hare_data</span> <span class="o">=</span> <span class="n">data</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">]</span>
<span class="n">y_obs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">((</span><span class="n">hare_data</span><span class="p">,</span> <span class="n">lynx_data</span><span class="p">))</span><span class="o">.</span><span class="n">T</span> <span class="c1"># Observed data [H, L]</span>

<span class="c1"># 2. Define Lotka-Volterra model</span>
<span class="k">def</span><span class="w"> </span><span class="nf">lotka_volterra</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">gamma</span><span class="p">,</span> <span class="n">delta</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Lotka-Volterra differential equations</span>
<span class="sd">    y: [H, L] population array</span>
<span class="sd">    t: time</span>
<span class="sd">    alpha, beta, gamma, delta: model parameters</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">H</span><span class="p">,</span> <span class="n">L</span> <span class="o">=</span> <span class="n">y</span>
    <span class="n">dH_dt</span> <span class="o">=</span> <span class="n">alpha</span> <span class="o">*</span> <span class="n">H</span> <span class="o">-</span> <span class="n">beta</span> <span class="o">*</span> <span class="n">H</span> <span class="o">*</span> <span class="n">L</span>
    <span class="n">dL_dt</span> <span class="o">=</span> <span class="n">delta</span> <span class="o">*</span> <span class="n">H</span> <span class="o">*</span> <span class="n">L</span> <span class="o">-</span> <span class="n">gamma</span> <span class="o">*</span> <span class="n">L</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">dH_dt</span><span class="p">,</span> <span class="n">dL_dt</span><span class="p">]</span>

<span class="c1"># 3. Define log posterior probability function</span>
<span class="k">def</span><span class="w"> </span><span class="nf">log_posterior</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">y_obs</span><span class="p">,</span> <span class="n">t_obs</span><span class="p">):</span>
    <span class="n">alpha</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">gamma</span><span class="p">,</span> <span class="n">delta</span> <span class="o">=</span> <span class="n">theta</span>

    <span class="c1"># a. Log-Prior</span>
    <span class="c1"># Assume parameters follow wide normal distributions, and must be positive</span>
    <span class="k">if</span> <span class="nb">any</span><span class="p">(</span><span class="n">p</span> <span class="o">&lt;=</span> <span class="mi">0</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">theta</span><span class="p">):</span>
        <span class="k">return</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span>
    <span class="n">log_prior_alpha</span> <span class="o">=</span> <span class="n">norm</span><span class="o">.</span><span class="n">logpdf</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">log_prior_beta</span> <span class="o">=</span> <span class="n">norm</span><span class="o">.</span><span class="n">logpdf</span><span class="p">(</span><span class="n">beta</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mf">0.05</span><span class="p">)</span>
    <span class="n">log_prior_gamma</span> <span class="o">=</span> <span class="n">norm</span><span class="o">.</span><span class="n">logpdf</span><span class="p">(</span><span class="n">gamma</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">log_prior_delta</span> <span class="o">=</span> <span class="n">norm</span><span class="o">.</span><span class="n">logpdf</span><span class="p">(</span><span class="n">delta</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="mf">0.02</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mf">0.02</span><span class="p">)</span>
    <span class="n">log_p</span> <span class="o">=</span> <span class="n">log_prior_alpha</span> <span class="o">+</span> <span class="n">log_prior_beta</span> <span class="o">+</span> <span class="n">log_prior_gamma</span> <span class="o">+</span> <span class="n">log_prior_delta</span>

    <span class="c1"># b. Log-Likelihood</span>
    <span class="c1"># Initial conditions use the first point of data</span>
    <span class="n">y0</span> <span class="o">=</span> <span class="n">y_obs</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:]</span>
    <span class="c1"># Numerically solve differential equations using odeint</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">odeint</span><span class="p">(</span><span class="n">lotka_volterra</span><span class="p">,</span> <span class="n">y0</span><span class="p">,</span> <span class="n">t_obs</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">gamma</span><span class="p">,</span> <span class="n">delta</span><span class="p">))</span>

    <span class="c1"># Assume errors follow a log-normal distribution, equivalent to log-transformed data following a normal distribution</span>
    <span class="c1"># We also need to estimate a standard deviation sigma for the error</span>
    <span class="c1"># For simplicity, we fix a reasonable sigma value here</span>
    <span class="n">sigma</span> <span class="o">=</span> <span class="mf">0.5</span> 
    <span class="n">log_likelihood</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">norm</span><span class="o">.</span><span class="n">logpdf</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">y_obs</span><span class="p">),</span> <span class="n">loc</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">y_pred</span><span class="p">),</span> <span class="n">scale</span><span class="o">=</span><span class="n">sigma</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">log_p</span> <span class="o">+</span> <span class="n">log_likelihood</span>

<span class="c1"># 4. Implement Metropolis-Hastings MCMC</span>
<span class="k">def</span><span class="w"> </span><span class="nf">metropolis_hastings</span><span class="p">(</span><span class="n">log_posterior_func</span><span class="p">,</span> <span class="n">n_iter</span><span class="p">,</span> <span class="n">initial_theta</span><span class="p">,</span> <span class="n">proposal_std</span><span class="p">,</span> <span class="n">y_obs</span><span class="p">,</span> <span class="n">t_obs</span><span class="p">):</span>
    <span class="c1"># Initialization</span>
    <span class="n">n_params</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">initial_theta</span><span class="p">)</span>
    <span class="n">chain</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n_iter</span><span class="p">,</span> <span class="n">n_params</span><span class="p">))</span>
    <span class="n">chain</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">initial_theta</span>

    <span class="n">current_log_post</span> <span class="o">=</span> <span class="n">log_posterior_func</span><span class="p">(</span><span class="n">initial_theta</span><span class="p">,</span> <span class="n">y_obs</span><span class="p">,</span> <span class="n">t_obs</span><span class="p">)</span>

    <span class="n">accepted_count</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_iter</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">i</span> <span class="o">%</span> <span class="mi">1000</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Iteration </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">n_iter</span><span class="si">}</span><span class="s2">...&quot;</span><span class="p">)</span>

        <span class="c1"># a. Propose new point</span>
        <span class="n">proposal_theta</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="n">chain</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:],</span> <span class="n">scale</span><span class="o">=</span><span class="n">proposal_std</span><span class="p">)</span>

        <span class="c1"># b. Calculate acceptance probability</span>
        <span class="n">proposal_log_post</span> <span class="o">=</span> <span class="n">log_posterior_func</span><span class="p">(</span><span class="n">proposal_theta</span><span class="p">,</span> <span class="n">y_obs</span><span class="p">,</span> <span class="n">t_obs</span><span class="p">)</span>

        <span class="n">log_alpha</span> <span class="o">=</span> <span class="n">proposal_log_post</span> <span class="o">-</span> <span class="n">current_log_post</span>

        <span class="c1"># c. Accept or reject</span>
        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">())</span> <span class="o">&lt;</span> <span class="n">log_alpha</span><span class="p">:</span>
            <span class="n">chain</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">proposal_theta</span>
            <span class="n">current_log_post</span> <span class="o">=</span> <span class="n">proposal_log_post</span>
            <span class="n">accepted_count</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">chain</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">chain</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Acceptance rate: </span><span class="si">{</span><span class="n">accepted_count</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">n_iter</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">chain</span>

<span class="c1"># 5. Run MCMC</span>
<span class="n">n_iterations</span> <span class="o">=</span> <span class="mi">50000</span>
<span class="n">burn_in</span> <span class="o">=</span> <span class="mi">10000</span> <span class="c1"># Discard early unstable samples</span>
<span class="n">initial_params</span> <span class="o">=</span> <span class="p">[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.02</span><span class="p">]</span> <span class="c1"># Initial guess</span>
<span class="n">proposal_widths</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.001</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.001</span><span class="p">]</span> <span class="c1"># Proposal distribution standard deviation, needs tuning</span>
<span class="n">t_span</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">years</span><span class="p">))</span> <span class="c1"># Time points (0, 1, 2, ...)</span>

<span class="n">chain</span> <span class="o">=</span> <span class="n">metropolis_hastings</span><span class="p">(</span><span class="n">log_posterior</span><span class="p">,</span> <span class="n">n_iterations</span><span class="p">,</span> <span class="n">initial_params</span><span class="p">,</span> <span class="n">proposal_widths</span><span class="p">,</span> <span class="n">y_obs</span><span class="p">,</span> <span class="n">t_span</span><span class="p">)</span>

<span class="c1"># Discard burn-in phase</span>
<span class="n">posterior_samples</span> <span class="o">=</span> <span class="n">chain</span><span class="p">[</span><span class="n">burn_in</span><span class="p">:,</span> <span class="p">:]</span>

<span class="c1"># 6. Results visualization</span>
<span class="n">param_names</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;alpha&#39;</span><span class="p">,</span> <span class="s1">&#39;beta&#39;</span><span class="p">,</span> <span class="s1">&#39;gamma&#39;</span><span class="p">,</span> <span class="s1">&#39;delta&#39;</span><span class="p">]</span>

<span class="c1"># a. Plot trace plots of parameters</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">4</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">posterior_samples</span><span class="p">[:,</span> <span class="n">i</span><span class="p">])</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Trace of </span><span class="si">{</span><span class="n">param_names</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Iteration&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Parameter Value&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># b. Plot posterior distributions</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">4</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">posterior_samples</span><span class="p">[:,</span> <span class="n">i</span><span class="p">],</span> <span class="n">bins</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">density</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Posterior of </span><span class="si">{</span><span class="n">param_names</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Parameter Value&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Density&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># c. Plot model predictions vs. real data</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="c1"># Randomly sample some parameter combinations from the posterior distribution for simulation</span>
<span class="n">n_samples_plot</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">sample_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">posterior_samples</span><span class="p">),</span> <span class="n">n_samples_plot</span><span class="p">)</span>

<span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">sample_indices</span><span class="p">:</span>
    <span class="n">params</span> <span class="o">=</span> <span class="n">posterior_samples</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="p">:]</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">odeint</span><span class="p">(</span><span class="n">lotka_volterra</span><span class="p">,</span> <span class="n">y_obs</span><span class="p">[</span><span class="mi">0</span><span class="p">,:],</span> <span class="n">t_span</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="nb">tuple</span><span class="p">(</span><span class="n">params</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">years</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;skyblue&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span> <span class="c1"># Predicted hares</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">years</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;lightcoral&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span> <span class="c1"># Predicted lynx</span>

<span class="c1"># Plot original data points</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">years</span><span class="p">,</span> <span class="n">hare_data</span><span class="p">,</span> <span class="s1">&#39;o-&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;blue&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Observed Hares&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">years</span><span class="p">,</span> <span class="n">lynx_data</span><span class="p">,</span> <span class="s1">&#39;o-&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Observed Lynx&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Year&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Population (x1000)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Lotka-Volterra Model Fit to Hudson Bay Data&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div>
<img alt="运行代码输出" src="../../../assets/images/remote/92bf7793-2723-4dd5-b016-7005ec48e792-28a1133f5b.png" /></p>
<p><strong>轨迹图:</strong>这个图显示了在MCMC的迭代过程中,每个参数的采样值是如何变化的。理想情况下,我们希望看到这些轨迹像一条"毛毛虫"一样,在一个稳定的值附近随机波动,没有明显的上升或下降趋势。这表明马尔可夫链已经"忘记"了它的初始位置,并开始在目标后验分布的典型区域进行探索。如果轨迹图呈现出明显的趋势,通常意味着"burn-in"阶段不够长,或者提议分布不合适,链的混合效率低。</p>
<p><img alt="运行代码输出" src="../../../assets/images/remote/763ed380-ac8b-4e8c-a26c-a71f1bddf16d-1203017672.png" /></p>
<p><strong>后验分布图 (Posterior Distributions)</strong>:这是我们进行贝叶斯推断的核心结果。这些直方图近似地描绘了在给定数据之后,我们对每个参数不确定性的认知。分布的峰值代表了参数最可能的值(即最大后验估计),而分布的宽度则量化了我们对这个值的不确定性。例如,一个又高又窄的分布意味着数据非常有力地将该参数约束在了一个小范围内;而一个又矮又胖的分布则表明数据提供的信息有限,我们对该参数的真实值仍然不太确定。
<img alt="运行代码输出" src="../../../assets/images/remote/75e9b1b2-4ff7-4b3f-aa6c-7a7c1988bb4d-43bd03f19f.png" /></p>
<p><strong>模型预测与数据对比图</strong>:这张图将我们的推断结果与真实世界的数据进行了直观的比较。图中半透明的细线代表了从后验分布中随机抽取的100组不同参数所产生的模型演化轨迹。这些曲线构成的"置信带"展示了模型在考虑了参数不确定性后的预测范围。我们可以看到,真实的数据点(蓝色和红色的圆点)基本都落在了这个置信带内,这表明我们的洛特卡-沃尔泰拉模型和推断出的参数能够很好地捕捉并再现历史上猞猁和雪兔种群的周期性波动。这为模型的有效性提供了有力的视觉证据。</p>
<p>通过这个案例,我们完整地走了一遍使用高级采样方法解决实际科学问题的流程:<strong>从一个现实世界的数据集出发,建立一个数学模型,利用贝叶斯推断的框架定义目标(后验分布),最后通过构建一个巧妙的随机过程(MCMC),成功地从这个复杂的目标分布中抽取了样本,完成了对模型参数的量化学习。这正是蒙特卡洛方法作为随机过程在现代科学研究中强大威力的体现。</strong></p>
<h1 id="_2">结论<a class="headerlink" href="#_2" title="Permanent link">&para;</a></h1>
<p>这节课将随机过程的理论从一个纯粹的分析工具,转变为一个强大的计算引擎。我们从一个实际的科学问题——从数据中推断模型参数——出发,认识到贝叶斯框架为我们提供了理论上的解决方案,即后验概率分布。然而,这个方案被"维度灾难"所困,导致直接计算变得不可行。</p>
<p>MCMC方法,特别是Metropolis-Hastings算法,为我们提供了一条优雅的出路。通过将采样问题重新表述为寻找一个特定马尔可夫链的稳态分布问题,我们巧妙地利用了细致平衡等基本原理,构建了一个能够从任意目标分布中采样的通用"机器"。这个过程不仅绕过了计算归一化常数的难题,还为我们提供了一种在复杂高维空间中进行有效探索的策略。</p>
<p>这次讲座连接了课程的前半部分(随机过程理论)和后半部分(应用),展示了深刻的理论知识如何能够直接转化为解决现实世界问题的实用工具。MCMC及其变体是现代计算统计学、机器学习和许多定量科学领域的基石,掌握其核心思想,将为我们打开探索更复杂模型的大门。</p>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      <script id="__config" type="application/json">{"base": "../../..", "features": ["content.code.copy", "navigation.sections", "navigation.expand", "navigation.top", "toc.integrate", "search.highlight"], "search": "../../../assets/javascripts/workers/search.973d3a69.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../../../assets/javascripts/bundle.f55a23d4.min.js"></script>
      
        <script src="../../../assets/javascripts/mathjax.js"></script>
      
        <script src="../../../assets/javascripts/language-nav.js"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
      
    
  </body>
</html>